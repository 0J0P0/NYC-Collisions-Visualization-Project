{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Modules import preprocessing as pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './Data'\n",
    "temp_pre = './Data/tmp_pre'\n",
    "colission_exists = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather dataset preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the process of downloading the data, we selected all the attributes available. Now, we will explore the data and select the ones that are useful for our purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpniz\\AppData\\Local\\Temp\\ipykernel_7428\\1972467482.py:1: DtypeWarning: Columns (7,9,13,17,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  weather = pd.read_csv(f'{dir}/weather.csv')\n"
     ]
    }
   ],
   "source": [
    "weather = pd.read_csv(f'{dir}/weather.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90591, 66)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are only interested in the rows where the date is inside the timeranges of 01/06/2018 - 31/09/2018 and 01/06/2020 - 31/09/2020, we will filter the data to only include those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20536, 66)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = pre.time_filter(weather, 'DATE')\n",
    "weather.to_csv(f'{dir}/weather_2018-2020.csv', index=False)\n",
    "weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STATION', 'NAME', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'DATE', 'AWND',\n",
       "       'AWND_ATTRIBUTES', 'DAPR', 'DAPR_ATTRIBUTES', 'DASF', 'DASF_ATTRIBUTES',\n",
       "       'MDPR', 'MDPR_ATTRIBUTES', 'MDSF', 'MDSF_ATTRIBUTES', 'PGTM',\n",
       "       'PGTM_ATTRIBUTES', 'PRCP', 'PRCP_ATTRIBUTES', 'PSUN', 'PSUN_ATTRIBUTES',\n",
       "       'SNOW', 'SNOW_ATTRIBUTES', 'SNWD', 'SNWD_ATTRIBUTES', 'TAVG',\n",
       "       'TAVG_ATTRIBUTES', 'TMAX', 'TMAX_ATTRIBUTES', 'TMIN', 'TMIN_ATTRIBUTES',\n",
       "       'TOBS', 'TOBS_ATTRIBUTES', 'TSUN', 'TSUN_ATTRIBUTES', 'WDF2',\n",
       "       'WDF2_ATTRIBUTES', 'WDF5', 'WDF5_ATTRIBUTES', 'WESD', 'WESD_ATTRIBUTES',\n",
       "       'WESF', 'WESF_ATTRIBUTES', 'WSF2', 'WSF2_ATTRIBUTES', 'WSF5',\n",
       "       'WSF5_ATTRIBUTES', 'WT01', 'WT01_ATTRIBUTES', 'WT02', 'WT02_ATTRIBUTES',\n",
       "       'WT03', 'WT03_ATTRIBUTES', 'WT04', 'WT04_ATTRIBUTES', 'WT05',\n",
       "       'WT05_ATTRIBUTES', 'WT06', 'WT06_ATTRIBUTES', 'WT08', 'WT08_ATTRIBUTES',\n",
       "       'WT09', 'WT09_ATTRIBUTES', 'WT11', 'WT11_ATTRIBUTES'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the documentation of the weather datatset and the attributes present, each row represents some selected observations (values) available for a given **STATION** and **DATE**. Neither the **STATION** nor the **DATE** are unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 244)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weather['STATION'].unique()), len(weather['DATE'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from the first 6 columns (**SATTION**, **NAME**, **LATITUDE**, **LONGITUDE**, **ELEVATION** and **DATE**), the rest of the attributes correspond to optional flags and their respective attributes (definded by the weather documentation. *Note: The 4 flags listed [...] are optional on the Custom GHCN-Daily ASCII Form*) and therefore can contain several null values. That is the reason for the large quantity of sparse attributes detected. We will explore the data to see which attributes are useful for our purpose.\n",
    "\n",
    "All these atributes correspond to the Table 4. A brief description is collected in the following table:\n",
    "\n",
    "| Attribute | Description |\n",
    "| --- | --- |\n",
    "| *PRCP* | Precipitation (mm) |\n",
    "| *SNOW* | Snowfall (mm) |\n",
    "| *SNWD* | Snow depth (mm) |\n",
    "| *TSUN* | Daily total sunshine (minutes) |\n",
    "| *TMAX* | Maximum temperature (Celsius) |\n",
    "| *TMIN* | Minimum temperature (Celsius) |\n",
    "| *TAVG* | Average temperature (Celsius) |\n",
    "| *TOBS* | Temperature at the time of observation |\n",
    "| *AWND* | Average daily wind speed (meters per second) |\n",
    "| *WT** | Weather type * |\n",
    "\n",
    "\n",
    "The next table contains the attributes that we considered that are not useful for the visualization purpose:\n",
    "\n",
    "| Attribute | Description |\n",
    "| --- | --- |\n",
    "| *PGTM* | Peak gust time (hours and minutes, i.e., HHMM) |\n",
    "| *DARP* | Number of days included in the multiday precipitation total (MDPR) |\n",
    "| *DASF* | Number of days included in the multiday snowfall total (MDSF) |\n",
    "| *MDPR* | Multiday precipitation total (mm; use with DAPR and DWPR, if available) |\n",
    "| *MDSF* | Multiday snowfall total (mm; use with DASF and DWSF, if available) |\n",
    "| *PSUN* | Daily percent of possible sunshine (percent; use with TSUN, if available) |\n",
    "| *WSF** | Fastest *-minute wind speed (meters per second) |\n",
    "| *WDF** | Direction of fastest *-second wind (degrees) |\n",
    "| *WESD* | Water equivalent of snow on the ground (decimal mm) |\n",
    "| *WESF* | Water equivalent of snowfall (decimal mm) |\n",
    "\n",
    "\n",
    "Both **DARP** and **DASF** doesn't directly measure specific weather conditions. They are more of an aggregate measure of precipitation/snowfall over multiple days, which is not useful for our purpose. The same applies to **MDPR**, **MDSF** and **PSUN** that are also not useful for our purpose since they are not specific weather conditions.\n",
    "\n",
    "While weather conditions can impact accidents, these specific attributes about wind direction and speed (**WDF** and **WSF**) might not directly correlate with accident frequency or timing. They are more focused on detailed weather patterns, not necessarily directly tied to accident data. Similarly, these attributes detail aspects of snow, like its water equivalent or depth (**WESD** and **WESF**) are not relevant since we assume that sufficient information is gathered by the **SNOW** and **SBWD** attributes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ***_ATTRIBUTES** columns refer to the rest of the tables in the documentation (Table 1, 2, 3). These tables serve as flags for the measurement, quality and source of the data respectively.\n",
    "\n",
    "- Table 1 details measurement attributes and flags for specific weather data. It provides information on how certain measurements were taken or derived, such as multi-day totals, conversions from different units, missing or trace values, and other specific characteristics regarding the nature of the recorded data.\n",
    "\n",
    "- Table 2 presents quality flags indicating various quality assurance checks for the data. These flags denote whether the data passed or failed specific quality checks such as duplicate checks, consistency checks, outlier checks, and other verification processes. It's designed to inform users about the reliability and potential issues associated with the data.\n",
    "\n",
    "- Table 3 specifies the source of the weather data. It categorizes the origin or the institution from which the data was collected. This is crucial for understanding the diversity of sources, from different countries, organizations, or systems, providing a comprehensive picture of the data's origin and the network through which it was obtained.\n",
    "\n",
    "The values available for these attributes cover a wide range. In the data selection process we will analyze the subset of those values that are present in the data and discuss if they are useful for our purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geographical attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we will start by joining **LATITUDE** and **LONGITUDE** in a **LOCATION** attribute following the format of the *collision* dataset. Since both attributes have no missing values, the resulting column will not have any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20536, 66)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather[(weather['LATITUDE'].notnull()) & (weather['LONGITUDE'].notnull())].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['LOCATION'] = '(' + weather['LATITUDE'].astype(str) + ', ' + weather['LONGITUDE'].astype(str) + ')'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will delete the **ELEVATION** column since it can't be related in any way with the previous dataset and the information it gives is not useful for our visualization purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.drop(columns=['LATITUDE', 'LONGITUDE', 'ELEVATION'], inplace=True)\n",
    "\n",
    "cols = list(weather.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "weather = weather[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have *LOCATION*, we don't need *STATION* code or *NAME* given that we are not interested in knowing where the measurement was taken. We will delete both columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.drop(columns=['STATION', 'NAME'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observational attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are analyzing the summer periods of 2018 and 2020, it is unlikely to have observations of snow in the records. Under this assumption we can drop the **SNOW** and **SNWD** attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0., nan]), array([ 0., nan]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather['SNOW'].unique(), weather['SNWD'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we supposed, the only observations registred of **SNOW** and **SNWD** are null values or 0. Therefore, we can drop these columns and their respective flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.drop(columns=['SNOW', 'SNWD', 'SNOW_ATTRIBUTES', 'SNWD_ATTRIBUTES'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data exploration done in the previous section, we can remove the following attributes: **DARP**, **DASF**, **MDPR**, **MDSF**, **PSUN**, **WDF**, **WESD**, **WESF** and their respective flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LOCATION', 'DATE', 'AWND', 'AWND_ATTRIBUTES', 'PGTM_ATTRIBUTES',\n",
       "       'PRCP', 'PRCP_ATTRIBUTES', 'TAVG', 'TAVG_ATTRIBUTES', 'TMAX',\n",
       "       'TMAX_ATTRIBUTES', 'TMIN', 'TMIN_ATTRIBUTES', 'TOBS', 'TOBS_ATTRIBUTES',\n",
       "       'TSUN', 'TSUN_ATTRIBUTES', 'WT01', 'WT01_ATTRIBUTES', 'WT02',\n",
       "       'WT02_ATTRIBUTES', 'WT03', 'WT03_ATTRIBUTES', 'WT04', 'WT04_ATTRIBUTES',\n",
       "       'WT05', 'WT05_ATTRIBUTES', 'WT06', 'WT06_ATTRIBUTES', 'WT08',\n",
       "       'WT08_ATTRIBUTES', 'WT09', 'WT09_ATTRIBUTES', 'WT11',\n",
       "       'WT11_ATTRIBUTES'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.drop(columns=['DAPR',\n",
    "                        'DASF',\n",
    "                        'PGTM',\n",
    "                        'MDPR',\n",
    "                        'MDSF',\n",
    "                        'PSUN',\n",
    "                        'TAVG',\n",
    "                        'WDF2',\n",
    "                        'WDF5',\n",
    "                        'WESD',\n",
    "                        'WESF',\n",
    "                        'WSF2',\n",
    "                        'WSF5',\n",
    "                        'DAPR_ATTRIBUTES',\n",
    "                        'DASF_ATTRIBUTES',\n",
    "                        'MDPR_ATTRIBUTES',\n",
    "                        'MDSF_ATTRIBUTES',\n",
    "                        'PSUN_ATTRIBUTES',\n",
    "                        'WDF2_ATTRIBUTES',\n",
    "                        'WDF5_ATTRIBUTES',\n",
    "                        'WESD_ATTRIBUTES',\n",
    "                        'WESF_ATTRIBUTES',\n",
    "                        'WSF2_ATTRIBUTES',\n",
    "                        'WSF5_ATTRIBUTES'\n",
    "                        ], inplace=True)\n",
    "\n",
    "weather.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the **WT*** columns, they all describe a specific weather condition that could be referred as **ADVERSE CONDITION** given the descriptions from the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Attribute | Description |\n",
    "| --- | --- |\n",
    "| *WT02* | Heavy fog or heaving freezing fog (not always distinguished from fog) |\n",
    "| *WT03* | Thunder |\n",
    "| *WT04* | Ice pellets, sleet, snow pellets, or small hail\" |\n",
    "| *WT05* | Hail (may include small hail) |\n",
    "| *WT06* | Glaze or rime |\n",
    "| *WT08* | Smoke or haze |\n",
    "| *WT09* | Blowing or drifting snow |\n",
    "| *WT11* | High or damaging winds |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19894, 35)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather[weather['WT01'].isnull() & weather['WT02'].isnull() & weather['WT03'].isnull() & weather['WT04'].isnull() & weather['WT05'].isnull() & weather['WT06'].isnull() & weather['WT08'].isnull() & weather['WT09'].isnull() & weather['WT11'].isnull()].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As checked, they all have the null values in the same rows, which could indicate that the ``nan`` value could significate a ``False`` value for all the adverse type of weather conditions and meaning that the corresponding record refers to a *normal* weather day. Therefore, we will replace the ``nan`` values with ``0``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([nan,  1.]),\n",
       " array([nan,  1.]),\n",
       " array([nan,  1.]),\n",
       " array([nan]),\n",
       " array([nan,  1.]),\n",
       " array([nan]),\n",
       " array([nan,  1.]),\n",
       " array([nan]),\n",
       " array([nan,  1.]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather['WT01'].unique(), weather['WT02'].unique(), weather['WT03'].unique(), weather['WT04'].unique(), weather['WT05'].unique(), weather['WT06'].unique(), weather['WT08'].unique(), weather['WT09'].unique(), weather['WT11'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By knowing this, the final decision was to merge all the **WT*** columns into a single one called **ADVERSE CONDITION**, which would have boolean values (0 or 1) indicating if the day was normal or not in terms of weather conditions. This would loose some information regaring a more detailed description of the weather conditions, but it would be more useful for our purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADVERSE_CONDITIONS\n",
       "0    19894\n",
       "1      642\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_columns = ['WT01', 'WT02', 'WT03', 'WT04', 'WT05', 'WT06', 'WT08', 'WT09', 'WT11']\n",
    "\n",
    "weather['ADVERSE_CONDITIONS'] = weather[wt_columns].isnull().all(axis=1).astype(int)\n",
    "weather['ADVERSE_CONDITIONS'] = 1 - weather['ADVERSE_CONDITIONS']\n",
    "\n",
    "weather['ADVERSE_CONDITIONS'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The flag attributes of the **WT*** columns will be removed given that the weather conditions columns were aggregated into a single column and thus the flags are not meaningful anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LOCATION', 'DATE', 'AWND', 'AWND_ATTRIBUTES', 'PGTM_ATTRIBUTES',\n",
       "       'PRCP', 'PRCP_ATTRIBUTES', 'TAVG', 'TAVG_ATTRIBUTES', 'TMAX',\n",
       "       'TMAX_ATTRIBUTES', 'TMIN', 'TMIN_ATTRIBUTES', 'TOBS', 'TOBS_ATTRIBUTES',\n",
       "       'TSUN', 'TSUN_ATTRIBUTES', 'ADVERSE_CONDITIONS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_columns_att = [col + '_ATTRIBUTES' for col in wt_columns]\n",
    "\n",
    "weather.drop(columns=wt_columns, inplace=True)\n",
    "weather.drop(columns=wt_columns_att, inplace=True)\n",
    "\n",
    "weather.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flags attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ***_ATTRIBUTES** have not been commented so far. These values collectively offer a detailed understanding of the characteristics, quality, and origins of the weather data, empowering users to interpret and analyze the data within the context of its measurement methods, quality assurance, and diverse sources.\n",
    "\n",
    "For the visualization objective, these attributes do not provide any useful information and could be considered as metadata. Therefore, we will remove all the ***_ATTRIBUTES** columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWND_ATTRIBUTES:[nan ',,W']\n",
      "PGTM_ATTRIBUTES:[nan ',,W']\n",
      "PRCP_ATTRIBUTES:[',,7,0700' 'T,,7,0700' ',,N' 'T,,N' nan ',,W,2400' 'T,,W,2400' ',L,N'\n",
      " ',,7,0800' ',,W' 'T,,W' ',,N,' 'T,,N,' ',,7,' ',,7,0630' 'T,,7,0630'\n",
      " ',,Z,0700']\n",
      "TAVG_ATTRIBUTES:[nan 'H,,S']\n",
      "TMAX_ATTRIBUTES:[',,7' nan ',,W' ',,Z']\n",
      "TMIN_ATTRIBUTES:[',,7' nan ',,W']\n",
      "TOBS_ATTRIBUTES:[',,7,0700' nan ',,7,0800' ',,7,' ',,7,0630']\n",
      "TSUN_ATTRIBUTES:[nan]\n"
     ]
    }
   ],
   "source": [
    "cols = weather.columns.tolist()\n",
    "\n",
    "for col in cols:\n",
    "    if '_ATTRIBUTES' in col:\n",
    "        print(col, weather[col].unique(), sep=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_columns_att = [col for col in weather.columns if '_ATTRIBUTES' in col]\n",
    "weather.drop(columns=wt_columns_att, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the sparseness described in the data exploration, it is logical to check for columns with only missing values in order to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20536, 10)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coincidentally, the **TSUN** column has only missing values. Therefore, we will remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOCATION                  0\n",
       "DATE                      0\n",
       "AWND                  18608\n",
       "PRCP                    297\n",
       "TAVG                  19804\n",
       "TMAX                  17221\n",
       "TMIN                  17233\n",
       "TOBS                  19244\n",
       "TSUN                  20536\n",
       "ADVERSE_CONDITIONS        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.drop(columns=['TSUN'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For *PRCP*, we will assume that the null values are 0, that is if there's no record of precipitation (the value is null), it's because there were no precipitations. We make this assumption because the number of null values represents around 10% of the dataset so it's not such a risk to make this assumption (and even less risk taking into account that the data is from Summer, when it's less likely to rain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['PRCP'].fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding temperature, the great number of missing values is a problem. We will impute the missing values with the average temperature per day of each attribute (*TMAX*, *TMIN*, *TOBS*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['TMAX'] = weather.groupby('DATE')['TMAX'].transform(lambda x: x.fillna(x.mean()))\n",
    "weather['TMIN'] = weather.groupby('DATE')['TMIN'].transform(lambda x: x.fillna(x.mean()))\n",
    "weather['TOBS'] = weather.groupby('DATE')['TOBS'].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOCATION                  0\n",
       "DATE                      0\n",
       "AWND                  18608\n",
       "PRCP                      0\n",
       "TMAX                      0\n",
       "TMIN                      0\n",
       "TOBS                      0\n",
       "ADVERSE_CONDITIONS        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply the same strategy on AWND to get rid of the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['AWND'] = weather.groupby('DATE')['AWND'].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOCATION              0\n",
       "DATE                  0\n",
       "AWND                  0\n",
       "PRCP                  0\n",
       "TMAX                  0\n",
       "TMIN                  0\n",
       "TOBS                  0\n",
       "ADVERSE_CONDITIONS    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in daily measures, so we will group the data by **DATE** and aggregate the values of the rest of the columns by the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_aggregated = weather.copy()\n",
    "weather_aggregated.drop(columns=['LOCATION', 'ADVERSE_CONDITIONS'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>AWND</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>TOBS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>1.6250</td>\n",
       "      <td>4.354762</td>\n",
       "      <td>24.921429</td>\n",
       "      <td>17.371429</td>\n",
       "      <td>18.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-06-02</td>\n",
       "      <td>3.4875</td>\n",
       "      <td>5.296296</td>\n",
       "      <td>29.330769</td>\n",
       "      <td>18.800000</td>\n",
       "      <td>21.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-06-03</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>6.153165</td>\n",
       "      <td>23.800000</td>\n",
       "      <td>12.353846</td>\n",
       "      <td>15.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>2.8875</td>\n",
       "      <td>13.223256</td>\n",
       "      <td>20.700000</td>\n",
       "      <td>10.392308</td>\n",
       "      <td>10.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-06-05</td>\n",
       "      <td>3.4875</td>\n",
       "      <td>0.801266</td>\n",
       "      <td>23.092857</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>13.233333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE    AWND       PRCP       TMAX       TMIN       TOBS\n",
       "0  2018-06-01  1.6250   4.354762  24.921429  17.371429  18.683333\n",
       "1  2018-06-02  3.4875   5.296296  29.330769  18.800000  21.825000\n",
       "2  2018-06-03  5.0000   6.153165  23.800000  12.353846  15.125000\n",
       "3  2018-06-04  2.8875  13.223256  20.700000  10.392308  10.750000\n",
       "4  2018-06-05  3.4875   0.801266  23.092857  11.500000  13.233333"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_aggregated = weather_aggregated.groupby('DATE').mean().reset_index()\n",
    "weather_aggregated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorization of **AWND** can simplify its complex numerical data, making it easier to understand and interpret for further analysis. This categorization will follow the Beaufort scale. The [Beaufort Scale](https://en.wikipedia.org/wiki/Beaufort_scale) is a measure used to estimate wind speed based on observed conditions at sea or on land. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beaufort_scale(wind_speed_mps):\n",
    "    if wind_speed_mps < 0.3:\n",
    "        return \"Calm\"\n",
    "    elif wind_speed_mps < 1.5:\n",
    "        return \"Light Air\"\n",
    "    elif wind_speed_mps < 3.4:\n",
    "        return \"Light Breeze\"\n",
    "    elif wind_speed_mps < 5.5:\n",
    "        return \"Gentle Breeze\"\n",
    "    elif wind_speed_mps < 8.0:\n",
    "        return \"Moderate Breeze\"\n",
    "    elif wind_speed_mps < 10.8:\n",
    "        return \"Fresh Breeze\"\n",
    "    elif wind_speed_mps < 13.9:\n",
    "        return \"Strong Breeze\"\n",
    "    elif wind_speed_mps < 17.2:\n",
    "        return \"Near Gale\"\n",
    "    elif wind_speed_mps < 20.8:\n",
    "        return \"Gale\"\n",
    "    elif wind_speed_mps < 24.5:\n",
    "        return \"Strong Gale\"\n",
    "    elif wind_speed_mps < 28.5:\n",
    "        return \"Storm\"\n",
    "    else:\n",
    "        return \"Hurricane\"\n",
    "    \n",
    "\n",
    "weather_aggregated['BEAUFORT_SCALE'] = weather_aggregated['AWND'].apply(beaufort_scale)\n",
    "\n",
    "weather_aggregated['BEAUFORT_SCALE'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same was done for **PRCP**. The categorization will follow the [World Meteorological Organization, 2018](https://www.researchgate.net/figure/Rain-intensity-classifications-according-to-the-World-Meteorological-Organization-2018_tbl1_353769617) classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Slight'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rain_intensity_scale(prcp_mm):\n",
    "    if prcp_mm < 2.5*24:\n",
    "        return \"Slight\"\n",
    "    elif prcp_mm < 10*24:\n",
    "        return \"Moderate\"\n",
    "    elif prcp_mm < 50*24:\n",
    "        return \"Heavy\"\n",
    "    else:\n",
    "        return \"Violent\"\n",
    "    \n",
    "weather_aggregated['PRCP_SCALE'] = weather_aggregated['PRCP'].apply(rain_intensity_scale)\n",
    "\n",
    "weather_aggregated['PRCP_SCALE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_aggregated['MEAN_TEMP'] = weather_aggregated[['TMAX', 'TMIN', 'TOBS']].mean(axis=1)\n",
    "weather_aggregated.drop(columns=['TMAX', 'TMIN', 'TOBS'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessed data saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.to_csv(f'{dir}/weather_clean.csv', index=False)\n",
    "weather_aggregated.to_csv(f'{dir}/weather_aggregated.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
