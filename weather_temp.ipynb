{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import geopy as gp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import geopandas as gpd\n",
    "#from uszipcode import SearchEngine\n",
    "from Modules import collision_preprocessing as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './Data'\n",
    "temp_pre = './Data/tmp_pre'\n",
    "colission_exists = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather dataset preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the process of downloading the data, we selected all the attributes available. Now, we will explore the data and select the ones that are useful for our purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\USUARIOS\\Enric-UPC\\AppData\\Local\\Temp\\ipykernel_2408\\941678255.py:1: DtypeWarning: Columns (7,9,13,17,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  weather = pd.read_csv(f'{dir}/weather.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(90591, 66)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = pd.read_csv(f'{dir}/weather.csv')\n",
    "weather.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90591, 66)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are only interested in the rows where the date is inside the timeranges of 01/06/2018 - 31/09/2018 and 01/06/2020 - 31/09/2020, we will filter the data to only include those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = weather[((weather['DATE'] >= '2018-06-01') & (weather['DATE'] <= '2018-09-30')) | ((weather['DATE'] >= '2020-06-01') & (weather['DATE'] <= '2020-09-30'))]\n",
    "\n",
    "weather.to_csv(f'{dir}/weather_2018-2020.csv', index=False) # sobre el mismo archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20536, 66)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STATION', 'NAME', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'DATE', 'AWND',\n",
       "       'AWND_ATTRIBUTES', 'DAPR', 'DAPR_ATTRIBUTES', 'DASF', 'DASF_ATTRIBUTES',\n",
       "       'MDPR', 'MDPR_ATTRIBUTES', 'MDSF', 'MDSF_ATTRIBUTES', 'PGTM',\n",
       "       'PGTM_ATTRIBUTES', 'PRCP', 'PRCP_ATTRIBUTES', 'PSUN', 'PSUN_ATTRIBUTES',\n",
       "       'SNOW', 'SNOW_ATTRIBUTES', 'SNWD', 'SNWD_ATTRIBUTES', 'TAVG',\n",
       "       'TAVG_ATTRIBUTES', 'TMAX', 'TMAX_ATTRIBUTES', 'TMIN', 'TMIN_ATTRIBUTES',\n",
       "       'TOBS', 'TOBS_ATTRIBUTES', 'TSUN', 'TSUN_ATTRIBUTES', 'WDF2',\n",
       "       'WDF2_ATTRIBUTES', 'WDF5', 'WDF5_ATTRIBUTES', 'WESD', 'WESD_ATTRIBUTES',\n",
       "       'WESF', 'WESF_ATTRIBUTES', 'WSF2', 'WSF2_ATTRIBUTES', 'WSF5',\n",
       "       'WSF5_ATTRIBUTES', 'WT01', 'WT01_ATTRIBUTES', 'WT02', 'WT02_ATTRIBUTES',\n",
       "       'WT03', 'WT03_ATTRIBUTES', 'WT04', 'WT04_ATTRIBUTES', 'WT05',\n",
       "       'WT05_ATTRIBUTES', 'WT06', 'WT06_ATTRIBUTES', 'WT08', 'WT08_ATTRIBUTES',\n",
       "       'WT09', 'WT09_ATTRIBUTES', 'WT11', 'WT11_ATTRIBUTES'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the documentation of the weather datatset and the attributes present, each row represents some selected observations (values) available for a given **STATION** and **DATE**. Neither the **STATION** nor the **DATE** are unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 244)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weather['STATION'].unique()), len(weather['DATE'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from the first 6 columns listed avobe, the rest of the attributes correspond to optional flags and their respective attributes (definded by the weather documentation *Note: The 4 flags listed ... are optional on the Custom GHCN-Daily ASCII Form*) and therefore can contain several null values. That is the reason for the large quantity of sparse attributes detected. We will explore the data to see which attributes are useful for our purpose.\n",
    "\n",
    "All these atributes correspond to the Table 4. Some of the most relevant to understand the weather conditons are:\n",
    "\n",
    "AWND, DAPR, DASF, MDPR, MDSF, PGTM, PRCP, PSUN, SNOW, SNWD, TAVG, TMAX, TMIN, TOBS, TSUN, WDF2, WDF5, WESD, WESF, WSF2, WSF5, WT01, WT02, WT03, WT04, WT05, WT06, WT08, WT09, WT11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we will start by joining **LATITUDE** and **LONGITUDE** in a **LOCATION** attribute following the format of the *collision* dataset. Since both attributes ahave no missing values, the resulting column will not have any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20536, 66)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather[(weather['LATITUDE'].notnull()) & (weather['LONGITUDE'].notnull())].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['LOCATION'] = '(' + weather['LATITUDE'].astype(str) + ', ' + weather['LONGITUDE'].astype(str) + ')'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will delete the **ELEVATION** column since it can't be related in any way with the previous dataset and the information it gives is not useful for our visualization purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.drop(columns=['LATITUDE', 'LONGITUDE', 'ELEVATION'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have *LOCATION*, we don't need *STATION* code or *NAME*.\n",
    "\n",
    "-- yo no los quitaria aun, porque si queremos hacer un mapa de estaciones, necesitamos el codigo de estacion y el nombre de la estacion. Si no, no sabemos a que estacion corresponde cada punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather.drop(columns=['STATION', 'NAME'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with regard to the other columns, let's follow the proposed startegy. We are interested in **LOCATION** so we can know about the weather condtitions of the zone where the collision was produced. For the weather attributes, following the documentation of the weather dataset, provided by *NOAA* and available in the ``Documentation`` directory, we are interested in:\n",
    "\n",
    "- *PRCP* : Precipitation (mm)\n",
    "- *SNOW* : Snowfall (mm)\n",
    "- *SNWD* : Snow depth (mm)\n",
    "- *TMAX* : Maximum temperature (Celsius)\n",
    "- *TMIN* : Minimum temperature (Celsius)\n",
    "- *TOBS* : Temperature at the time of observation\n",
    "- *AWND* : Average daily wind speed (meters per second)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are analyzing the summer periods of 2018 and 2020, we could probably drop the *SNOW* attribute since probably all values will be 0. However, let's check it out before deleting the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SNOW\n",
       "0.0    9222\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather['SNOW'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we supposed, the not null values of *SNOW* are all 0, and we can assume that the null ones would be 0 too. So we can safely delete this column as it makes no sense to analize snow during summer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.drop(columns=['SNOW'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan], dtype=object)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather['WT09_ATTRIBUTES'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_col = ['DATE',\n",
    "              'PRCP',\n",
    "              'SNWD',\n",
    "              'TMAX',\n",
    "              'TMIN',\n",
    "              'TOBS',\n",
    "              'AWND',\n",
    "              'WT01',\n",
    "              'WT02',\n",
    "              'WT03',\n",
    "              'WT04',\n",
    "              'WT05',\n",
    "              'WT06',\n",
    "              'WT08',\n",
    "              'WT09',\n",
    "              'WT11',\n",
    "              'LOCATION']\n",
    "\n",
    "weather = weather[select_col]\n",
    "\n",
    "# change 'LOCATION' column to the second column\n",
    "cols = list(weather.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "weather = weather[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LOCATION', 'DATE', 'PRCP', 'SNWD', 'TMAX', 'TMIN', 'TOBS', 'AWND',\n",
       "       'WT01', 'WT02', 'WT03', 'WT04', 'WT05', 'WT06', 'WT08', 'WT09', 'WT11'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19894, 17)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather[weather['WT01'].isnull() & weather['WT02'].isnull() & weather['WT03'].isnull() & weather['WT04'].isnull() & weather['WT05'].isnull() & weather['WT06'].isnull() & weather['WT08'].isnull() & weather['WT09'].isnull() & weather['WT11'].isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todas las filas nulas pueden ser que el dia haya sido bonito\n",
    "# WT** son binarios, si es nulo es que no paso nada\n",
    "# si hay alguno de los WT que no es nulo, entonces el dia no fue bonito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([nan,  1.]),\n",
       " array([nan,  1.]),\n",
       " array([nan,  1.]),\n",
       " array([nan]),\n",
       " array([nan,  1.]),\n",
       " array([nan]),\n",
       " array([nan,  1.]),\n",
       " array([nan]),\n",
       " array([nan,  1.]))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather['WT01'].unique(), weather['WT02'].unique(), weather['WT03'].unique(), weather['WT04'].unique(), weather['WT05'].unique(), weather['WT06'].unique(), weather['WT08'].unique(), weather['WT09'].unique(), weather['WT11'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LOCATION', 'DATE', 'PRCP', 'SNWD', 'TMAX', 'TMIN', 'TOBS', 'AWND',\n",
       "       'WT01', 'WT02', 'WT03', 'WT04', 'WT05', 'WT06', 'WT08', 'WT09', 'WT11'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADVERSE_CONDITIONS\n",
       "0    19894\n",
       "1      642\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_columns = ['WT01', 'WT02', 'WT03', 'WT04', 'WT05', 'WT06', 'WT08', 'WT09', 'WT11']\n",
    "\n",
    "weather['ADVERSE_CONDITIONS'] = weather[wt_columns].isnull().all(axis=1).astype(int)\n",
    "weather['ADVERSE_CONDITIONS'] = 1 - weather['ADVERSE_CONDITIONS']\n",
    "\n",
    "weather['ADVERSE_CONDITIONS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>TOBS</th>\n",
       "      <th>AWND</th>\n",
       "      <th>ADVERSE_CONDITIONS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>(40.89174, -74.39635)</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>16.7</td>\n",
       "      <td>18.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>(40.89174, -74.39635)</td>\n",
       "      <td>2018-06-02</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.9</td>\n",
       "      <td>18.9</td>\n",
       "      <td>21.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>(40.89174, -74.39635)</td>\n",
       "      <td>2018-06-03</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.4</td>\n",
       "      <td>14.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>(40.89174, -74.39635)</td>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>16.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>10.6</td>\n",
       "      <td>11.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>(40.89174, -74.39635)</td>\n",
       "      <td>2018-06-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>11.1</td>\n",
       "      <td>12.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  LOCATION        DATE  PRCP  SNWD  TMAX  TMIN  TOBS  AWND  \\\n",
       "151  (40.89174, -74.39635)  2018-06-01   1.8   0.0  20.6  16.7  18.9   NaN   \n",
       "152  (40.89174, -74.39635)  2018-06-02   5.3   0.0  28.9  18.9  21.7   NaN   \n",
       "153  (40.89174, -74.39635)  2018-06-03  14.0   0.0  29.4  14.4  15.0   NaN   \n",
       "154  (40.89174, -74.39635)  2018-06-04  16.8   0.0  18.9  10.6  11.1   NaN   \n",
       "155  (40.89174, -74.39635)  2018-06-05   0.0   0.0  23.3  11.1  12.2   NaN   \n",
       "\n",
       "     ADVERSE_CONDITIONS  \n",
       "151                   0  \n",
       "152                   0  \n",
       "153                   0  \n",
       "154                   0  \n",
       "155                   0  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.drop(columns=wt_columns, inplace=True)\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOCATION                  0\n",
       "DATE                      0\n",
       "PRCP                    297\n",
       "SNWD                  16813\n",
       "TMAX                  17221\n",
       "TMIN                  17233\n",
       "TOBS                  19244\n",
       "AWND                  18608\n",
       "ADVERSE_CONDITIONS        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For *PRCP*, we will assume that the null values are 0, that is if there's no record of precipitation (the value is null), it's because there were no precipitations. We make this assumption because the number of null values represents around 10% of the dataset so it's not such a risk to make this assumption (and even less risk taking into account that the data is from Summer, when it's less likely to rain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['PRCP'].fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.drop(columns=['SNWD'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding temperature, the great number of missing values is a problem. We will impute the missing values with the avergae temperature per day of each attribute (*TMAX*, *TMIN*, *TOBS*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['TMAX'] = weather.groupby('DATE')['TMAX'].transform(lambda x: x.fillna(x.mean()))\n",
    "weather['TMIN'] = weather.groupby('DATE')['TMIN'].transform(lambda x: x.fillna(x.mean()))\n",
    "weather['TOBS'] = weather.groupby('DATE')['TOBS'].transform(lambda x: x.fillna(x.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOCATION                  0\n",
       "DATE                      0\n",
       "PRCP                      0\n",
       "TMAX                      0\n",
       "TMIN                      0\n",
       "TOBS                      0\n",
       "AWND                  18608\n",
       "ADVERSE_CONDITIONS        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply the same strategy on AWND to get rid of the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['AWND'] = weather.groupby('DATE')['AWND'].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOCATION              0\n",
       "DATE                  0\n",
       "PRCP                  0\n",
       "TMAX                  0\n",
       "TMIN                  0\n",
       "TOBS                  0\n",
       "AWND                  0\n",
       "ADVERSE_CONDITIONS    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos categorizar AWND con la Beaufort scale (https://en.wikipedia.org/wiki/Beaufort_scale)\n",
    "\n",
    "# Podemos categorizar PRCP con respecto a la World Meteorological Organization, 2018(https://www.researchgate.net/figure/Rain-intensity-classifications-according-to-the-World-Meteorological-Organization-2018_tbl1_353769617)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
