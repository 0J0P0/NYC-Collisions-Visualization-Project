{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import geopy as gp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import geopandas as gpd\n",
    "#from uszipcode import SearchEngine\n",
    "from Modules import collision_preprocessing as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './Data'\n",
    "temp_pre = './Data/tmp_pre'\n",
    "colission_exists = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather dataset preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the process of downloading the data, we selected all the attributes available. Now, we will explore the data and select the ones that are useful for our purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpniz\\AppData\\Local\\Temp\\ipykernel_15492\\941678255.py:1: DtypeWarning: Columns (7,9,13,17,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  weather = pd.read_csv(f'{dir}/weather.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(90591, 66)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = pd.read_csv(f'{dir}/weather.csv')\n",
    "weather.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90591, 66)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are only interested in the rows where the date is inside the timeranges of 01/06/2018 - 31/09/2018 and 01/06/2020 - 31/09/2020, we will filter the data to only include those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = weather[((weather['DATE'] >= '2018-06-01') & (weather['DATE'] <= '2018-09-30')) | ((weather['DATE'] >= '2020-06-01') & (weather['DATE'] <= '2020-09-30'))]\n",
    "\n",
    "weather.to_csv(f'{dir}/weather_2018-2020.csv', index=False) # sobre el mismo archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20536, 66)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STATION', 'NAME', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'DATE', 'AWND',\n",
       "       'AWND_ATTRIBUTES', 'DAPR', 'DAPR_ATTRIBUTES', 'DASF', 'DASF_ATTRIBUTES',\n",
       "       'MDPR', 'MDPR_ATTRIBUTES', 'MDSF', 'MDSF_ATTRIBUTES', 'PGTM',\n",
       "       'PGTM_ATTRIBUTES', 'PRCP', 'PRCP_ATTRIBUTES', 'PSUN', 'PSUN_ATTRIBUTES',\n",
       "       'SNOW', 'SNOW_ATTRIBUTES', 'SNWD', 'SNWD_ATTRIBUTES', 'TAVG',\n",
       "       'TAVG_ATTRIBUTES', 'TMAX', 'TMAX_ATTRIBUTES', 'TMIN', 'TMIN_ATTRIBUTES',\n",
       "       'TOBS', 'TOBS_ATTRIBUTES', 'TSUN', 'TSUN_ATTRIBUTES', 'WDF2',\n",
       "       'WDF2_ATTRIBUTES', 'WDF5', 'WDF5_ATTRIBUTES', 'WESD', 'WESD_ATTRIBUTES',\n",
       "       'WESF', 'WESF_ATTRIBUTES', 'WSF2', 'WSF2_ATTRIBUTES', 'WSF5',\n",
       "       'WSF5_ATTRIBUTES', 'WT01', 'WT01_ATTRIBUTES', 'WT02', 'WT02_ATTRIBUTES',\n",
       "       'WT03', 'WT03_ATTRIBUTES', 'WT04', 'WT04_ATTRIBUTES', 'WT05',\n",
       "       'WT05_ATTRIBUTES', 'WT06', 'WT06_ATTRIBUTES', 'WT08', 'WT08_ATTRIBUTES',\n",
       "       'WT09', 'WT09_ATTRIBUTES', 'WT11', 'WT11_ATTRIBUTES'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the documentation of the weather datatset and the attributes present, each row represents some selected observations (values) available for a given **STATION** and **DATE**. Neither the **STATION** nor the **DATE** are unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 244)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weather['STATION'].unique()), len(weather['DATE'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from the first 6 columns listed avobe, the rest of the attributes correspond to optional flags and their respective attributes (definded by the weather documentation *Note: The 4 flags listed [...] are optional on the Custom GHCN-Daily ASCII Form*) and therefore can contain several null values. That is the reason for the large quantity of sparse attributes detected. We will explore the data to see which attributes are useful for our purpose.\n",
    "\n",
    "All these atributes correspond to the Table 4. A brief description is collected in the following table:\n",
    "\n",
    "| Attribute | Description |\n",
    "| --- | --- |\n",
    "| *PRCP* | Precipitation (mm) |\n",
    "| *SNOW* | Snowfall (mm) |\n",
    "| *SNWD* | Snow depth (mm) |\n",
    "| *TMAX* | Maximum temperature (Celsius) |\n",
    "| *TMIN* | Minimum temperature (Celsius) |\n",
    "| *TOBS* | Temperature at the time of observation |\n",
    "| *AWND* | Average daily wind speed (meters per second) |\n",
    "\n",
    "| *TAVG* | Average temperature (Celsius) |\n",
    "| *TSUN* | Daily total sunshine (minutes) |\n",
    "| *WSF** | Fastest *-minute wind speed (meters per second) |\n",
    "| *WT** | Weather type * |\n",
    "\n",
    "The next table contains the attributes that we considered that are not udeful for the visualization purpose:\n",
    "\n",
    "| Attribute | Description |\n",
    "| --- | --- |\n",
    "| *DARP* | Number of days included in the multiday precipitation total (MDPR) |\n",
    "| *DASF* | Number of days included in the multiday snowfall total (MDSF) |\n",
    "| *MDPR* | Multiday precipitation total (mm; use with DAPR and DWPR, if available) |\n",
    "| *MDSF* | Multiday snowfall total (mm; use with DASF and DWSF, if available) |\n",
    "| *PSUN* | Daily percent of possible sunshine (percent; use with TSUN, if available) |\n",
    "| *WDF** | Direction of fastest *-second wind (degrees) |\n",
    "| *WESD* | Water equivalent of snow on the ground (decimal mm) |\n",
    "| *WESF* | Water equivalent of snowfall (decimal mm) |\n",
    "\n",
    "\n",
    "Both **DARP** and **DASF** doesn't directly measure specific weather conditions. They are more of an aggregate measure of precipitation/snowfall over multiple days, which is not useful for our purpose. The same applies to **MDPR**, **MDSF** and **PSUN** that are also not useful for our purpose since they are not specific weather conditions.\n",
    "\n",
    "-- justificar WDF, WESD, WESF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we will start by joining **LATITUDE** and **LONGITUDE** in a **LOCATION** attribute following the format of the *collision* dataset. Since both attributes ahave no missing values, the resulting column will not have any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20536, 66)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather[(weather['LATITUDE'].notnull()) & (weather['LONGITUDE'].notnull())].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['LOCATION'] = '(' + weather['LATITUDE'].astype(str) + ', ' + weather['LONGITUDE'].astype(str) + ')'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will delete the **ELEVATION** column since it can't be related in any way with the previous dataset and the information it gives is not useful for our visualization purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.drop(columns=['LATITUDE', 'LONGITUDE', 'ELEVATION'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have *LOCATION*, we don't need *STATION* code or *NAME*.\n",
    "\n",
    "-- yo no los quitaria aun, porque si queremos hacer un mapa de estaciones, necesitamos el codigo de estacion y el nombre de la estacion. Si no, no sabemos a que estacion corresponde cada punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather.drop(columns=['STATION', 'NAME'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are analyzing the summer periods of 2018 and 2020, it is unlikely to have observations of snow in the records. Under this assumption we can drop the **SNOW** and **SNWD** attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0., nan]), array([ 0., nan]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather['SNOW'].unique(), weather['SNWD'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we supposed, the only observations registred of **SNOW** and **SNWD** are null values or 0. Therefore, we can drop these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.drop(columns=['SNOW', 'SNWD'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWND_ATTRIBUTES [nan ',,W']\n",
      "DAPR_ATTRIBUTES [nan ',,N' ',L,N' ',,7']\n",
      "DASF_ATTRIBUTES [nan]\n",
      "MDPR_ATTRIBUTES [nan ',,N' ',L,N' 'T,,N' ',,7']\n",
      "MDSF_ATTRIBUTES [nan]\n",
      "PGTM_ATTRIBUTES [nan ',,W']\n",
      "PRCP_ATTRIBUTES [',,7,0700' 'T,,7,0700' ',,N' 'T,,N' nan ',,W,2400' 'T,,W,2400' ',L,N'\n",
      " ',,7,0800' ',,W' 'T,,W' ',,N,' 'T,,N,' ',,7,' ',,7,0630' 'T,,7,0630'\n",
      " ',,Z,0700']\n",
      "PSUN_ATTRIBUTES [nan]\n",
      "SNOW_ATTRIBUTES [',,7,0700' nan ',,N' ',,W,2400' ',,7,0800' ',,N,' ',,7,' ',,7,0630'\n",
      " 'T,,N' 'T,,7,0700']\n",
      "SNWD_ATTRIBUTES [',,7,0700' nan ',,W,2400' ',,N' ',,7,0800' ',,7,' ',,7,0630']\n",
      "TAVG_ATTRIBUTES [nan 'H,,S']\n",
      "TMAX_ATTRIBUTES [',,7' nan ',,W' ',,Z']\n",
      "TMIN_ATTRIBUTES [',,7' nan ',,W']\n",
      "TOBS_ATTRIBUTES [',,7,0700' nan ',,7,0800' ',,7,' ',,7,0630']\n",
      "TSUN_ATTRIBUTES [nan]\n",
      "WDF2_ATTRIBUTES [nan ',,W']\n",
      "WDF5_ATTRIBUTES [nan ',,W']\n",
      "WESD_ATTRIBUTES [nan ',,N']\n",
      "WESF_ATTRIBUTES [nan ',,N' ',,N,0630']\n",
      "WSF2_ATTRIBUTES [nan ',,W']\n",
      "WSF5_ATTRIBUTES [nan ',,W']\n",
      "WT01_ATTRIBUTES [nan ',,W' ',,7']\n",
      "WT02_ATTRIBUTES [nan ',,W']\n",
      "WT03_ATTRIBUTES [nan ',,W' ',,7']\n",
      "WT04_ATTRIBUTES [nan]\n",
      "WT05_ATTRIBUTES [nan ',,W' ',,7']\n",
      "WT06_ATTRIBUTES [nan]\n",
      "WT08_ATTRIBUTES [nan ',,W']\n",
      "WT09_ATTRIBUTES [nan]\n",
      "WT11_ATTRIBUTES [nan ',,7']\n"
     ]
    }
   ],
   "source": [
    "cols = weather.columns.tolist()\n",
    "\n",
    "for col in cols:\n",
    "    if '_ATTRIBUTES' in col:\n",
    "        print(col, weather[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan], dtype=object)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather['WT09_ATTRIBUTES'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data exploration done in the previous section, we can remove the following attributes: **DARP**, **DASF**, **MDPR**, **MDSF**, **PSUN**, **WDF**, **WESD**, **WESF**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_col = ['DATE',\n",
    "              'PRCP',\n",
    "              'TMAX',\n",
    "              'TMIN',\n",
    "              'TOBS',\n",
    "              'AWND',\n",
    "              'WT01',\n",
    "              'WT02',\n",
    "              'WT03',\n",
    "              'WT04',\n",
    "              'WT05',\n",
    "              'WT06',\n",
    "              'WT08',\n",
    "              'WT09',\n",
    "              'WT11',\n",
    "              'LOCATION']\n",
    "\n",
    "weather = weather[select_col]\n",
    "\n",
    "# change 'LOCATION' column to the second column\n",
    "cols = list(weather.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "weather = weather[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LOCATION', 'DATE', 'PRCP', 'SNWD', 'TMAX', 'TMIN', 'TOBS', 'AWND',\n",
       "       'WT01', 'WT02', 'WT03', 'WT04', 'WT05', 'WT06', 'WT08', 'WT09', 'WT11'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Attribute | Description |\n",
    "| --- | --- |\n",
    "| *WT02* | Heavy fog or heaving freezing fog (not always distinguished from fog) |\n",
    "| *WT03* | Thunder |\n",
    "| *WT04* | Ice pellets, sleet, snow pellets, or small hail\" |\n",
    "| *WT05* | Hail (may include small hail) |\n",
    "| *WT06* | Glaze or rime |\n",
    "| *WT08* | Smoke or haze |\n",
    "| *WT09* | Blowing or drifting snow |\n",
    "| *WT11* | High or damaging winds |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19894, 17)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather[weather['WT01'].isnull() & weather['WT02'].isnull() & weather['WT03'].isnull() & weather['WT04'].isnull() & weather['WT05'].isnull() & weather['WT06'].isnull() & weather['WT08'].isnull() & weather['WT09'].isnull() & weather['WT11'].isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todas las filas nulas pueden ser que el dia haya sido bonito\n",
    "# WT** son binarios, si es nulo es que no paso nada\n",
    "# si hay alguno de los WT que no es nulo, entonces el dia no fue bonito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([nan,  1.]),\n",
       " array([nan,  1.]),\n",
       " array([nan,  1.]),\n",
       " array([nan]),\n",
       " array([nan,  1.]),\n",
       " array([nan]),\n",
       " array([nan,  1.]),\n",
       " array([nan]),\n",
       " array([nan,  1.]))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather['WT01'].unique(), weather['WT02'].unique(), weather['WT03'].unique(), weather['WT04'].unique(), weather['WT05'].unique(), weather['WT06'].unique(), weather['WT08'].unique(), weather['WT09'].unique(), weather['WT11'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LOCATION', 'DATE', 'PRCP', 'SNWD', 'TMAX', 'TMIN', 'TOBS', 'AWND',\n",
       "       'WT01', 'WT02', 'WT03', 'WT04', 'WT05', 'WT06', 'WT08', 'WT09', 'WT11'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADVERSE_CONDITIONS\n",
       "0    19894\n",
       "1      642\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_columns = ['WT01', 'WT02', 'WT03', 'WT04', 'WT05', 'WT06', 'WT08', 'WT09', 'WT11']\n",
    "\n",
    "weather['ADVERSE_CONDITIONS'] = weather[wt_columns].isnull().all(axis=1).astype(int)\n",
    "weather['ADVERSE_CONDITIONS'] = 1 - weather['ADVERSE_CONDITIONS']\n",
    "\n",
    "weather['ADVERSE_CONDITIONS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>TOBS</th>\n",
       "      <th>AWND</th>\n",
       "      <th>ADVERSE_CONDITIONS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>(40.89174, -74.39635)</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>16.7</td>\n",
       "      <td>18.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>(40.89174, -74.39635)</td>\n",
       "      <td>2018-06-02</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.9</td>\n",
       "      <td>18.9</td>\n",
       "      <td>21.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>(40.89174, -74.39635)</td>\n",
       "      <td>2018-06-03</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.4</td>\n",
       "      <td>14.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>(40.89174, -74.39635)</td>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>16.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>10.6</td>\n",
       "      <td>11.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>(40.89174, -74.39635)</td>\n",
       "      <td>2018-06-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>11.1</td>\n",
       "      <td>12.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  LOCATION        DATE  PRCP  SNWD  TMAX  TMIN  TOBS  AWND  \\\n",
       "151  (40.89174, -74.39635)  2018-06-01   1.8   0.0  20.6  16.7  18.9   NaN   \n",
       "152  (40.89174, -74.39635)  2018-06-02   5.3   0.0  28.9  18.9  21.7   NaN   \n",
       "153  (40.89174, -74.39635)  2018-06-03  14.0   0.0  29.4  14.4  15.0   NaN   \n",
       "154  (40.89174, -74.39635)  2018-06-04  16.8   0.0  18.9  10.6  11.1   NaN   \n",
       "155  (40.89174, -74.39635)  2018-06-05   0.0   0.0  23.3  11.1  12.2   NaN   \n",
       "\n",
       "     ADVERSE_CONDITIONS  \n",
       "151                   0  \n",
       "152                   0  \n",
       "153                   0  \n",
       "154                   0  \n",
       "155                   0  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.drop(columns=wt_columns, inplace=True)\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOCATION                  0\n",
       "DATE                      0\n",
       "PRCP                    297\n",
       "SNWD                  16813\n",
       "TMAX                  17221\n",
       "TMIN                  17233\n",
       "TOBS                  19244\n",
       "AWND                  18608\n",
       "ADVERSE_CONDITIONS        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For *PRCP*, we will assume that the null values are 0, that is if there's no record of precipitation (the value is null), it's because there were no precipitations. We make this assumption because the number of null values represents around 10% of the dataset so it's not such a risk to make this assumption (and even less risk taking into account that the data is from Summer, when it's less likely to rain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['PRCP'].fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.drop(columns=['SNWD'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding temperature, the great number of missing values is a problem. We will impute the missing values with the avergae temperature per day of each attribute (*TMAX*, *TMIN*, *TOBS*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['TMAX'] = weather.groupby('DATE')['TMAX'].transform(lambda x: x.fillna(x.mean()))\n",
    "weather['TMIN'] = weather.groupby('DATE')['TMIN'].transform(lambda x: x.fillna(x.mean()))\n",
    "weather['TOBS'] = weather.groupby('DATE')['TOBS'].transform(lambda x: x.fillna(x.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOCATION                  0\n",
       "DATE                      0\n",
       "PRCP                      0\n",
       "TMAX                      0\n",
       "TMIN                      0\n",
       "TOBS                      0\n",
       "AWND                  18608\n",
       "ADVERSE_CONDITIONS        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply the same strategy on AWND to get rid of the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['AWND'] = weather.groupby('DATE')['AWND'].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOCATION              0\n",
       "DATE                  0\n",
       "PRCP                  0\n",
       "TMAX                  0\n",
       "TMIN                  0\n",
       "TOBS                  0\n",
       "AWND                  0\n",
       "ADVERSE_CONDITIONS    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos categorizar AWND con la Beaufort scale (https://en.wikipedia.org/wiki/Beaufort_scale)\n",
    "\n",
    "# Podemos categorizar PRCP con respecto a la World Meteorological Organization, 2018(https://www.researchgate.net/figure/Rain-intensity-classifications-according-to-the-World-Meteorological-Organization-2018_tbl1_353769617)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
