{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import geopy as gp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import geopandas as gpd\n",
    "from Modules import preprocessing as pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './Data'\n",
    "temp_pre = './Data/tmp_pre'\n",
    "colission_exists = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather dataset preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the process of downloading the data, we selected all the attributes available. Now, we will explore the data and select the ones that are useful for our purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpniz\\AppData\\Local\\Temp\\ipykernel_2932\\941678255.py:1: DtypeWarning: Columns (7,9,13,17,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  weather = pd.read_csv(f'{dir}/weather.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(90591, 66)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = pd.read_csv(f'{dir}/weather.csv')\n",
    "weather.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90591, 66)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are only interested in the rows where the date is inside the timeranges of 01/06/2018 - 31/09/2018 and 01/06/2020 - 31/09/2020, we will filter the data to only include those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pre.time_filter(weather, 'DATE')\n",
    "\n",
    "weather.to_csv(f'{dir}/weather_2018-2020.csv', index=False) # sobre el mismo archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90591, 66)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STATION', 'NAME', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'DATE', 'AWND',\n",
       "       'AWND_ATTRIBUTES', 'DAPR', 'DAPR_ATTRIBUTES', 'DASF', 'DASF_ATTRIBUTES',\n",
       "       'MDPR', 'MDPR_ATTRIBUTES', 'MDSF', 'MDSF_ATTRIBUTES', 'PGTM',\n",
       "       'PGTM_ATTRIBUTES', 'PRCP', 'PRCP_ATTRIBUTES', 'PSUN', 'PSUN_ATTRIBUTES',\n",
       "       'SNOW', 'SNOW_ATTRIBUTES', 'SNWD', 'SNWD_ATTRIBUTES', 'TAVG',\n",
       "       'TAVG_ATTRIBUTES', 'TMAX', 'TMAX_ATTRIBUTES', 'TMIN', 'TMIN_ATTRIBUTES',\n",
       "       'TOBS', 'TOBS_ATTRIBUTES', 'TSUN', 'TSUN_ATTRIBUTES', 'WDF2',\n",
       "       'WDF2_ATTRIBUTES', 'WDF5', 'WDF5_ATTRIBUTES', 'WESD', 'WESD_ATTRIBUTES',\n",
       "       'WESF', 'WESF_ATTRIBUTES', 'WSF2', 'WSF2_ATTRIBUTES', 'WSF5',\n",
       "       'WSF5_ATTRIBUTES', 'WT01', 'WT01_ATTRIBUTES', 'WT02', 'WT02_ATTRIBUTES',\n",
       "       'WT03', 'WT03_ATTRIBUTES', 'WT04', 'WT04_ATTRIBUTES', 'WT05',\n",
       "       'WT05_ATTRIBUTES', 'WT06', 'WT06_ATTRIBUTES', 'WT08', 'WT08_ATTRIBUTES',\n",
       "       'WT09', 'WT09_ATTRIBUTES', 'WT11', 'WT11_ATTRIBUTES'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the documentation of the weather datatset and the attributes present, each row represents some selected observations (values) available for a given **STATION** and **DATE**. Neither the **STATION** nor the **DATE** are unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 1096)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weather['STATION'].unique()), len(weather['DATE'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from the first 6 columns listed avobe, the rest of the attributes correspond to optional flags and their respective attributes (definded by the weather documentation *Note: The 4 flags listed [...] are optional on the Custom GHCN-Daily ASCII Form*) and therefore can contain several null values. That is the reason for the large quantity of sparse attributes detected. We will explore the data to see which attributes are useful for our purpose.\n",
    "\n",
    "All these atributes correspond to the Table 4. A brief description is collected in the following table:\n",
    "\n",
    "| Attribute | Description |\n",
    "| --- | --- |\n",
    "| *PGTM* | Peak gust time (hours and minutes, i.e., HHMM) |\n",
    "| *PRCP* | Precipitation (mm) |\n",
    "| *SNOW* | Snowfall (mm) |\n",
    "| *SNWD* | Snow depth (mm) |\n",
    "| *TMAX* | Maximum temperature (Celsius) |\n",
    "| *TMIN* | Minimum temperature (Celsius) |\n",
    "| *TOBS* | Temperature at the time of observation |\n",
    "| *AWND* | Average daily wind speed (meters per second) |\n",
    "\n",
    "| *TAVG* | Average temperature (Celsius) |\n",
    "| *TSUN* | Daily total sunshine (minutes) |\n",
    "| *WSF** | Fastest *-minute wind speed (meters per second) |\n",
    "| *WT** | Weather type * |\n",
    "\n",
    "The next table contains the attributes that we considered that are not udeful for the visualization purpose:\n",
    "\n",
    "| Attribute | Description |\n",
    "| --- | --- |\n",
    "| *DARP* | Number of days included in the multiday precipitation total (MDPR) |\n",
    "| *DASF* | Number of days included in the multiday snowfall total (MDSF) |\n",
    "| *MDPR* | Multiday precipitation total (mm; use with DAPR and DWPR, if available) |\n",
    "| *MDSF* | Multiday snowfall total (mm; use with DASF and DWSF, if available) |\n",
    "| *PSUN* | Daily percent of possible sunshine (percent; use with TSUN, if available) |\n",
    "| *WDF** | Direction of fastest *-second wind (degrees) |\n",
    "| *WESD* | Water equivalent of snow on the ground (decimal mm) |\n",
    "| *WESF* | Water equivalent of snowfall (decimal mm) |\n",
    "\n",
    "\n",
    "Both **DARP** and **DASF** doesn't directly measure specific weather conditions. They are more of an aggregate measure of precipitation/snowfall over multiple days, which is not useful for our purpose. The same applies to **MDPR**, **MDSF** and **PSUN** that are also not useful for our purpose since they are not specific weather conditions.\n",
    "\n",
    "-- justificar WDF, WESD, WESF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ***_ATTRIBUTES** columns refer to the rest of the tables in the documentation (Table 1, 2, 3). These tables serve as flags for the measurement, quality and source of the data respectively. The values available for these attributes cover a wide range. In the data selection process we will analyze the subset of those values that are present in the data and discuss if they are useful for our purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geographical attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we will start by joining **LATITUDE** and **LONGITUDE** in a **LOCATION** attribute following the format of the *collision* dataset. Since both attributes ahave no missing values, the resulting column will not have any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90591, 66)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather[(weather['LATITUDE'].notnull()) & (weather['LONGITUDE'].notnull())].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['LOCATION'] = '(' + weather['LATITUDE'].astype(str) + ', ' + weather['LONGITUDE'].astype(str) + ')'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will delete the **ELEVATION** column since it can't be related in any way with the previous dataset and the information it gives is not useful for our visualization purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.drop(columns=['LATITUDE', 'LONGITUDE', 'ELEVATION'], inplace=True)\n",
    "\n",
    "cols = list(weather.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "weather = weather[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have *LOCATION*, we don't need *STATION* code or *NAME*.\n",
    "\n",
    "-- yo no los quitaria aun, porque si queremos hacer un mapa de estaciones, necesitamos el codigo de estacion y el nombre de la estacion. Si no, no sabemos a que estacion corresponde cada punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.drop(columns=['STATION', 'NAME'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observational attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are analyzing the summer periods of 2018 and 2020, it is unlikely to have observations of snow in the records. Under this assumption we can drop the **SNOW** and **SNWD** attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0., 127.,  25.,  13.,  nan, 178.,  51.,  38.,  89.,  10., 152.,\n",
       "          5.,  18.,   8.,   3.,  64.,  91., 175., 188.,  30.,  15.,  99.,\n",
       "         43., 221.,  23., 140., 119.,  36.,  97.,  58.,  48., 142., 114.,\n",
       "        203., 213.,  71., 117., 201., 163.,  69.,  20.,  79.,  33.,  53.,\n",
       "         46., 150., 198., 147., 165.,  61.,  41., 333.,  84., 320., 102.,\n",
       "        381., 191.,  81.,  86.,  28., 229.,  76., 107., 208., 561., 122.,\n",
       "        231., 246., 251., 116., 338., 130., 135., 155., 132., 279.,  56.,\n",
       "        157., 406., 183.,  94., 224., 109., 297., 145., 104., 137., 216.,\n",
       "         66., 622., 160., 267., 254., 356., 180., 442., 173., 457.,   1.,\n",
       "        483., 274., 168., 330., 307., 193., 318., 302., 211., 170., 236.,\n",
       "        185., 146.,   6., 452., 234., 124.,  74., 531., 112., 305., 343.,\n",
       "         57., 133., 184., 121., 241.,   7., 264., 249., 312.]),\n",
       " array([0.000e+00, 1.270e+02,       nan, 2.500e+01, 5.100e+01, 1.780e+02,\n",
       "        7.600e+01, 3.050e+02, 2.290e+02, 2.030e+02, 1.020e+02, 1.520e+02,\n",
       "        1.300e+01, 2.000e+01, 3.000e+01, 1.800e+02, 1.000e+02, 8.000e+01,\n",
       "        5.000e+01, 2.000e+02, 2.300e+02, 1.500e+02, 1.300e+02, 2.800e+02,\n",
       "        8.000e+00, 2.300e+01, 1.500e+01, 1.140e+02, 1.000e+01, 1.980e+02,\n",
       "        1.420e+02, 1.470e+02, 1.650e+02, 3.000e+00, 5.300e+01, 9.900e+01,\n",
       "        5.800e+01, 1.750e+02, 6.400e+01, 5.000e+00, 4.100e+01, 3.330e+02,\n",
       "        8.400e+01, 3.200e+02, 1.400e+02, 3.800e+01, 4.060e+02, 3.560e+02,\n",
       "        2.160e+02, 2.790e+02, 4.600e+01, 3.600e+01, 8.900e+01, 3.300e+01,\n",
       "        4.300e+01, 1.800e+01, 2.540e+02, 2.800e+01, 9.700e+01, 6.900e+01,\n",
       "        1.320e+02, 2.515e+03, 7.100e+01, 5.600e+01, 2.340e+02, 5.720e+02,\n",
       "        4.320e+02, 3.430e+02, 1.910e+02, 1.600e+02, 1.880e+02, 3.300e+02,\n",
       "        4.570e+02, 3.680e+02, 6.600e+01, 2.080e+02, 1.630e+02, 1.370e+02,\n",
       "        1.040e+02, 6.100e+01, 7.900e+01, 1.170e+02, 2.360e+02, 2.210e+02,\n",
       "        1.960e+02, 1.830e+02, 1.550e+02, 8.100e+01, 1.000e+00, 1.570e+02,\n",
       "        1.070e+02, 2.670e+02, 8.600e+01, 1.680e+02, 1.450e+02, 1.220e+02,\n",
       "        3.070e+02, 1.930e+02, 3.180e+02, 4.800e+01, 2.110e+02, 1.850e+02,\n",
       "        1.350e+02, 1.190e+02, 9.100e+01, 1.460e+02, 1.700e+02, 6.000e+00,\n",
       "        7.400e+01, 4.830e+02, 2.410e+02, 1.120e+02, 2.920e+02, 2.640e+02,\n",
       "        7.000e+00, 1.090e+02, 3.400e+02, 2.950e+02, 3.810e+02]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather['SNOW'].unique(), weather['SNWD'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we supposed, the only observations registred of **SNOW** and **SNWD** are null values or 0. Therefore, we can drop these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.drop(columns=['SNOW', 'SNWD', 'SNOW_ATTRIBUTES', 'SNWD_ATTRIBUTES'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data exploration done in the previous section, we can remove the following attributes: **DARP**, **DASF**, **MDPR**, **MDSF**, **PSUN**, **WDF**, **WESD**, **WESF** and their respective flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LOCATION', 'DATE', 'AWND', 'AWND_ATTRIBUTES', 'PGTM',\n",
       "       'PGTM_ATTRIBUTES', 'PRCP', 'PRCP_ATTRIBUTES', 'TAVG', 'TAVG_ATTRIBUTES',\n",
       "       'TMAX', 'TMAX_ATTRIBUTES', 'TMIN', 'TMIN_ATTRIBUTES', 'TOBS',\n",
       "       'TOBS_ATTRIBUTES', 'TSUN', 'TSUN_ATTRIBUTES', 'WT01', 'WT01_ATTRIBUTES',\n",
       "       'WT02', 'WT02_ATTRIBUTES', 'WT03', 'WT03_ATTRIBUTES', 'WT04',\n",
       "       'WT04_ATTRIBUTES', 'WT05', 'WT05_ATTRIBUTES', 'WT06', 'WT06_ATTRIBUTES',\n",
       "       'WT08', 'WT08_ATTRIBUTES', 'WT09', 'WT09_ATTRIBUTES', 'WT11',\n",
       "       'WT11_ATTRIBUTES'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.drop(columns=['DAPR',\n",
    "                        'DASF',\n",
    "                        'MDPR',\n",
    "                        'MDSF',\n",
    "                        'PSUN',\n",
    "                        'WDF2',\n",
    "                        'WDF5',\n",
    "                        'WESD',\n",
    "                        'WESF',\n",
    "                        'WSF2',\n",
    "                        'WSF5',\n",
    "                        'DAPR_ATTRIBUTES',\n",
    "                        'DASF_ATTRIBUTES',\n",
    "                        'MDPR_ATTRIBUTES',\n",
    "                        'MDSF_ATTRIBUTES',\n",
    "                        'PSUN_ATTRIBUTES',\n",
    "                        'WDF2_ATTRIBUTES',\n",
    "                        'WDF5_ATTRIBUTES',\n",
    "                        'WESD_ATTRIBUTES',\n",
    "                        'WESF_ATTRIBUTES',\n",
    "                        'WSF2_ATTRIBUTES',\n",
    "                        'WSF5_ATTRIBUTES'\n",
    "                        ], inplace=True)\n",
    "\n",
    "weather.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the **WT*** columns, they all describe a specific weather condition that could be referred as *adverse condition* given the descriptions from the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Attribute | Description |\n",
    "| --- | --- |\n",
    "| *WT02* | Heavy fog or heaving freezing fog (not always distinguished from fog) |\n",
    "| *WT03* | Thunder |\n",
    "| *WT04* | Ice pellets, sleet, snow pellets, or small hail\" |\n",
    "| *WT05* | Hail (may include small hail) |\n",
    "| *WT06* | Glaze or rime |\n",
    "| *WT08* | Smoke or haze |\n",
    "| *WT09* | Blowing or drifting snow |\n",
    "| *WT11* | High or damaging winds |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As checked, they all have the null values in the same rows, which could indicate that the ``nan`` value could significate a ``False`` value for all the adverse type of weather conditions and meaning that the corresponding record refers to a *normal* weather day. Therefore, we will replace the ``nan`` values with ``0``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87501, 36)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather[weather['WT01'].isnull() & weather['WT02'].isnull() & weather['WT03'].isnull() & weather['WT04'].isnull() & weather['WT05'].isnull() & weather['WT06'].isnull() & weather['WT08'].isnull() & weather['WT09'].isnull() & weather['WT11'].isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([nan,  1.]),\n",
       " array([nan,  1.]),\n",
       " array([nan,  1.]),\n",
       " array([nan,  1.]),\n",
       " array([nan,  1.]),\n",
       " array([nan,  1.]),\n",
       " array([nan,  1.]),\n",
       " array([nan,  1.]),\n",
       " array([nan,  1.]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather['WT01'].unique(), weather['WT02'].unique(), weather['WT03'].unique(), weather['WT04'].unique(), weather['WT05'].unique(), weather['WT06'].unique(), weather['WT08'].unique(), weather['WT09'].unique(), weather['WT11'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By knowing this, the final decision was to merge all the **WT*** columns into a single one called **ADVERSE CONDITION**, which would have boolean values (0 or 1) indicating if the day was normal or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADVERSE_CONDITIONS\n",
       "0    87501\n",
       "1     3090\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_columns = ['WT01', 'WT02', 'WT03', 'WT04', 'WT05', 'WT06', 'WT08', 'WT09', 'WT11']\n",
    "\n",
    "weather['ADVERSE_CONDITIONS'] = weather[wt_columns].isnull().all(axis=1).astype(int)\n",
    "weather['ADVERSE_CONDITIONS'] = 1 - weather['ADVERSE_CONDITIONS']\n",
    "\n",
    "weather['ADVERSE_CONDITIONS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LOCATION', 'DATE', 'AWND', 'AWND_ATTRIBUTES', 'PGTM',\n",
       "       'PGTM_ATTRIBUTES', 'PRCP', 'PRCP_ATTRIBUTES', 'TAVG', 'TAVG_ATTRIBUTES',\n",
       "       'TMAX', 'TMAX_ATTRIBUTES', 'TMIN', 'TMIN_ATTRIBUTES', 'TOBS',\n",
       "       'TOBS_ATTRIBUTES', 'TSUN', 'TSUN_ATTRIBUTES', 'ADVERSE_CONDITIONS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_columns_att = [col + '_ATTRIBUTES' for col in wt_columns]\n",
    "\n",
    "weather.drop(columns=wt_columns, inplace=True)\n",
    "weather.drop(columns=wt_columns_att, inplace=True)\n",
    "\n",
    "weather.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flags attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ***_ATTRIBUTES** have not been commented yet. \n",
    "\n",
    "-- mdatios sobre sensores y otras mierdas que no interesan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWND_ATTRIBUTES:[nan ',,W']\n",
      "PGTM_ATTRIBUTES:[nan ',,W']\n",
      "PRCP_ATTRIBUTES:[',,7,0700' 'T,,7,0700' nan ',Z,7,0700' ',,Z,0700' ',,N' 'T,,N' ',,W,2400'\n",
      " 'T,,W,2400' ',L,N' ',,7,0800' ',,W' 'T,,W' ',Z,W' 'T,,Z' ',Z,W,2400'\n",
      " 'T,L,N' ',,N,0800' 'T,,N,0800' ',,N,' 'T,,N,' ',,7,' ',,7,0630'\n",
      " 'T,,7,0630' ',,Z,0630' 'T,,Z,0700' 'T,Z,W']\n",
      "TAVG_ATTRIBUTES:[nan 'H,,S']\n",
      "TMAX_ATTRIBUTES:[',,7' nan ',,W' ',,Z' ',S,W' ',Z,W']\n",
      "TMIN_ATTRIBUTES:[',,7' nan ',,W' ',G,7' ',,Z' ',S,W']\n",
      "TOBS_ATTRIBUTES:[',,7,0700' nan ',,7,0800' ',,7,' ',,7,0630']\n",
      "TSUN_ATTRIBUTES:[nan ',,W']\n"
     ]
    }
   ],
   "source": [
    "cols = weather.columns.tolist()\n",
    "\n",
    "for col in cols:\n",
    "    if '_ATTRIBUTES' in col:\n",
    "        print(col, weather[col].unique(), sep=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_columns_att = [col for col in weather.columns if '_ATTRIBUTES' in col]\n",
    "\n",
    "weather.drop(columns=wt_columns_att, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the sparseness described in teh data exploration, it is logical to check for columns with only missing values in order to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90591, 11)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coincidentally, the **TSUN** and therefore **TSUN_ATTRIBUTES** columns have only missing values. Therefore, we will remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOCATION                  0\n",
       "DATE                      0\n",
       "AWND                  82028\n",
       "PGTM                  86213\n",
       "PRCP                   1614\n",
       "TAVG                  87303\n",
       "TMAX                  75692\n",
       "TMIN                  75671\n",
       "TOBS                  84704\n",
       "TSUN                  90590\n",
       "ADVERSE_CONDITIONS        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.drop(columns=['TSUN', 'PGTM'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For *PRCP*, we will assume that the null values are 0, that is if there's no record of precipitation (the value is null), it's because there were no precipitations. We make this assumption because the number of null values represents around 10% of the dataset so it's not such a risk to make this assumption (and even less risk taking into account that the data is from Summer, when it's less likely to rain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['PRCP'].fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding temperature, the great number of missing values is a problem. We will impute the missing values with the avergae temperature per day of each attribute (*TMAX*, *TMIN*, *TOBS*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['TMAX'] = weather.groupby('DATE')['TMAX'].transform(lambda x: x.fillna(x.mean()))\n",
    "weather['TMIN'] = weather.groupby('DATE')['TMIN'].transform(lambda x: x.fillna(x.mean()))\n",
    "weather['TOBS'] = weather.groupby('DATE')['TOBS'].transform(lambda x: x.fillna(x.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.drop(columns=['TAVG'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOCATION                  0\n",
       "DATE                      0\n",
       "AWND                  82028\n",
       "PRCP                      0\n",
       "TMAX                      0\n",
       "TMIN                      0\n",
       "TOBS                      0\n",
       "ADVERSE_CONDITIONS        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply the same strategy on AWND to get rid of the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['AWND'] = weather.groupby('DATE')['AWND'].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOCATION              0\n",
       "DATE                  0\n",
       "AWND                  0\n",
       "PRCP                  0\n",
       "TMAX                  0\n",
       "TMIN                  0\n",
       "TOBS                  0\n",
       "ADVERSE_CONDITIONS    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos categorizar AWND con la Beaufort scale (https://en.wikipedia.org/wiki/Beaufort_scale)\n",
    "\n",
    "# Podemos categorizar PRCP con respecto a la World Meteorological Organization, 2018(https://www.researchgate.net/figure/Rain-intensity-classifications-according-to-the-World-Meteorological-Organization-2018_tbl1_353769617)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessed data saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.to_csv(f'{dir}/weather_clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
