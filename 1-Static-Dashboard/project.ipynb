{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAzmD69FzA1P"
      },
      "source": [
        "# Visualization Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp99rLV2zA1S"
      },
      "source": [
        "---\n",
        "**Authors**:\n",
        "-  *Juan P. Zaldivar E.*\n",
        "-  *Enrique MillÃ¡n X.*\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAAW9VoCzA1T"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMxwhVNKzA1T"
      },
      "source": [
        "In this project, the focus is on analyzing collision data in New York City during the summers of 2018 and 2020. The primary objective is to develop a comprehensive static visualization that can address several key questions regarding the nature and patterns of these collisions. With the use of datasets related to collisions, weather conditions, and the New York City map, we aim to explore various facets, including the frequency of accidents, vehicle types involved, time of day occurrences, geographical hotspots, and potential correlations with weather conditions.\n",
        "\n",
        "This file contains all the steps required to ensuring reproducibility of steps leading from raw data to a clean dataset is essential. The project is divided in three parts: the first part corresponds to the preprocessing of the data, the second part corresponds to the visualization desing process and the third part corresponds to the implementation of the visualization in the streamlit app to answer the questions.\n",
        "\n",
        "The datasets are as follows:\n",
        "\n",
        "- Collision Dataset: Extracting and filtering collision data specifically from June to September of 2018 and 2020. This involves selecting relevant columns, handling missing or inconsistent data, and ensuring data quality.\n",
        "\n",
        "- Weather Dataset: Locating and incorporating weather data corresponding to the time frames and areas of interest.\n",
        "- New York City Map: Acquiring a suitable map of New York City to overlay geographical information related to collision locations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tHFJ_26zA1T"
      },
      "source": [
        "### Dataset obtention and description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKWCqMLjzA1U"
      },
      "source": [
        "The [*Collisions*](https://data.cityofnewyork.us/Public-Safety/Motor-Vehicle-Collisions-Crashes/h9gi-nx95) dataset was already given by the instructors of the project. The Motor Vehicle Collisions crash table contains details on the crash event. Each row represents a crash event. The Motor Vehicle Collisions data tables contain information from all police reported motor vehicle collisions in NYC.\n",
        "\n",
        "The *weather* dataset was obtained following the next steps:\n",
        "\n",
        "- Visit the [NOAA Climate Data Online Search](https://www.ncdc.noaa.gov/cdo-web/search) web page.\n",
        "\n",
        "- Select the following options:\n",
        "  - `Weather Observation Type/Dataset -> Daily Summaries, Date Range -> 2018-01-01 to 2020-12-31, Search For -> Cities, Search Term -> New York City.`\n",
        "\n",
        "- Look for \"*New York, NY US*\" and click in ADD TO CART. Now, click the cart in the top right corner.\n",
        "\n",
        "- Select \"*Custom GHCN-Daily CSV*\", and the date previously selected (2018-01-01 to 2020-12-31). We are selecting more information than needed (to avoid disjoint downloads), but we will later filter it with ``Pandas`` and ``Open Refine``. Click continue.\n",
        "\n",
        "- Fill the three options, and select \"*metric units*\".\n",
        "\n",
        "- Fill all the options remaining and click continue. There are some options that will be probably not needed, but we will further analyze this when cleaning the datasets.\n",
        "\n",
        "- Type the email where you want to receive the data so the order can start.\n",
        "\n",
        "\n",
        "The *map* dataset was obtained from this [cartography web page](https://cartographyvectors.com/map/508-new-york-city-boroughs-ny).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUYC3CK6zA1U"
      },
      "source": [
        "The datasets are located in the folder `Data/` and the results are saved in the folder `Data/Preprocessed/`. Following are the loading of each dataset and the import of the required libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwULlpFYzA1U"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-sCrTrlC7E7"
      },
      "outputs": [],
      "source": [
        "pip install altair==5.1.2 pandas==1.5.3 numpy==1.23.5 altair==5.1.2 h3pandas==0.2.5 geopandas==0.13.2 vegafusion[embed]>=1.4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRSAgV75zA1V"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import altair as alt\n",
        "import h3pandas as h3\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "from Modules import preprocessing as pre"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqaihQRyzA1W"
      },
      "source": [
        "## Dataset preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfGLpXj0zA1W"
      },
      "source": [
        "The preprocessing of the files involved a collaborative effort using both OpenRefine and selected Python libraries. This strategic approach was adopted to take advantage of the unique strengths and capabilities offered by each tool. OpenRefine facilitated initial data cleaning and transformation tasks, with its user-friendly interface for effective manipulation of datasets. Simultaneously, Python libraries were utilized to perform more complex data operations and manipulations, with special emphasis on the extensive functionalities and flexibility they provide. This combination allowed for a comprehensive preprocessing workflow that maximized efficiency and accuracy in preparing the data for subsequent analyses and visualization tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KS7cMVnAzA1W",
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "dir = './Data'\n",
        "collision_exists = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8NZ9zkHzA1X"
      },
      "source": [
        "## Collision dataset preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PFZ6vTLzA1X"
      },
      "source": [
        "The initial step involved loading the original dataset into a `Pandas` dataframe, primarily to apply a date range filter efficiently. The rationale behind this approach was to optimize the data filtering process, considering the considerable size of the original dataset. The volume of data posed challenges within OpenRefine, leading to slow and inefficient computational processes. By filtering the dataset using `Pandas`, it allowed for a more streamlined and quicker selection of the desired date range. Following this initial filtering phase, the refined dataset was exported as a `.csv` file and subsequently imported into OpenRefine for further data processing and cleaning procedures. This sequential approach ensured a balance between computational efficiency and data handling capabilities across both `Pandas` and OpenRefine, resulting in a more effective preprocessing workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7p1Uo-4wzA1X"
      },
      "outputs": [],
      "source": [
        "if os.path.exists(f'{dir}/collisions_2018-2020.csv'):\n",
        "    collision = pd.read_csv(f'{dir}/collisions_2018-2020.csv')\n",
        "    colission_exists = True\n",
        "else:\n",
        "    try:\n",
        "        collision = pd.read_csv(f'{dir}/collisions.csv')\n",
        "        collision.shape\n",
        "    except:\n",
        "        print('Raw data missing, please upload the data before continuing')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "hojWQqjBzA1X",
        "outputId": "3cf22828-031f-46d5-ab10-c99281642e56"
      },
      "outputs": [],
      "source": [
        "collision.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMztT1ZVzA1X"
      },
      "source": [
        "If the filtered version does not exist, we proceed with the filtering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JES8s4EhzA1X",
        "outputId": "fdf0d00f-b36e-466f-a402-ec3a87da567b"
      },
      "outputs": [],
      "source": [
        "if not colission_exists:\n",
        "    collision = pre.time_filter(collision, 'CRASH DATE')\n",
        "    collision.to_csv(f'{dir}/collisions_2018-2020.csv', index=False)\n",
        "\n",
        "collision.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRkMx5EVzA1Y"
      },
      "source": [
        "Following the initial filtering process, the refined dataset was exported as a `.csv` file and then imported into OpenRefine. The approach taken in OpenRefine for data manipulation and cleaning will be thoroughly explained, providing reasoning and justifications for the specific procedures employed. This section aims to outline the methods used in OpenRefine to ensure transparency and clarity regarding the data processing steps, offering insights into why certain actions were taken to achieve the desired clean and structured dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hC23imzzzA1Y"
      },
      "source": [
        "### Data type conversion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOCxPWS0zA1Y"
      },
      "source": [
        "In OpenRefine, the data conversion process involved several attribute adjustments. The **CRASH DATE** attribute underwent a conversion to a date type for enhanced consistency and data clarity. Meanwhile, both **COLLISION ID** and **CRASH TIME** were temporarily set as string types.\n",
        "\n",
        "Attributes pertaining to the geographical location of the collisions were modified to strings, accompanied by specific notations. As part of this process, all values were standardized to uppercase, and any extra spaces were removed where applicable. This standardization was implemented to facilitate the effectiveness of the clustering method utilized for collectively inspecting and modifying cells. The objective was to streamline the identification and correction of any inconsistencies or inaccuracies within the data, ensuring a more uniform and reliable dataset for subsequent analyses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejwGaWlmzA1Y"
      },
      "source": [
        "The attributes pertaining to the number of persons involved in the collision underwent a data type conversion to integers within the dataset. This decision was driven by the discrete nature of these values and the expectation that these numerical counts wouldn't contain negative values.\n",
        "\n",
        "Conversely, the attributes related to vehicles and factors involved in the collisions were retained as strings temporarily. This choice was made to maintain flexibility in handling these attributes during subsequent data processing and analysis phases, ensuring that any necessary modifications or categorizations could be applied effectively as the analysis progressed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seKD_sGWzA1Y"
      },
      "source": [
        "### Data selection and transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8t7dRJVzA1Y"
      },
      "source": [
        "All of the following transformations were applied with OpenRefine. However, certain validations and checks to substantiate and validate these transformations are conducted within this specific section of the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgZNWWYRzA1Y"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    precollision = pd.read_csv(f'{dir}/collisions_2018-2020_prepro_v1.csv')\n",
        "except:\n",
        "    print('Preprocessed data from Openrefine missing, please upload the data before continuing')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGM0O3RnzA1Y"
      },
      "source": [
        "#### Time attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6viQ5k2I4xGd"
      },
      "source": [
        "Convertion of **CRASH DATE** column in the precollision DataFrame into a pandas datetime format, allowing for easier handling and manipulation of date-related operations. The next operations and column were made:\n",
        "\n",
        "- Creation of a new column named **YEAR** in the precollision DataFrame.\n",
        "\n",
        "- Creation of a new column named **DAY NAME** in the precollision DataFrame. This operation helps categorize each entry by the specific day of the week on which the collision occurred.\n",
        "\n",
        "- Creation of a new column called **TYPE OF DAY** in the precollision DataFrame, it assigns the corresponding row in the \"TYPE OF DAY\" column as \"Weekend\". Otherwise, it assigns \"Weekday\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "id": "yPXOn1qSzA1Y",
        "outputId": "58520d2f-4bf8-4190-b5c9-89960118ea29"
      },
      "outputs": [],
      "source": [
        "precollision[\"CRASH DATE\"] = pd.to_datetime(precollision[\"CRASH DATE\"])\n",
        "precollision['YEAR'] = precollision['CRASH DATE'].astype(str).str[:4]\n",
        "precollision[\"DAY NAME\"] = precollision[\"CRASH DATE\"].dt.day_name()\n",
        "precollision[\"TYPE OF DAY\"] = np.where(precollision[\"DAY NAME\"].isin([\"Saturday\", \"Sunday\"]), \"Weekend\", \"Weekday\")\n",
        "\n",
        "for _ in range(3):\n",
        "    cols = precollision.columns.tolist()\n",
        "    cols = cols[:1] + cols[-1:] + cols[1:-1]\n",
        "    precollision = precollision[cols]\n",
        "\n",
        "precollision.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2VNMxmf5siR"
      },
      "source": [
        "Additionally, a new column named **CRASH TIME INTERVAL** is created in the precollision DataFrame, that formats **CRASH TIME** as a two-digit string representation to isolate the hour."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13kKvKMHzA1Y"
      },
      "outputs": [],
      "source": [
        "precollision['CRASH TIME'] = pd.to_datetime(precollision['CRASH TIME'], format='%H:%M').dt.time\n",
        "precollision['CRASH TIME INTERVAL'] = precollision['CRASH TIME'].apply(lambda x: f\"{x.hour:02}\")\n",
        "precollision.drop(columns=['CRASH TIME'], inplace=True)\n",
        "\n",
        "precollision['CRASH MOMENT'] = precollision['CRASH TIME INTERVAL'].apply(pre.categorize_moment)\n",
        "\n",
        "# move TIME INTERVAL to the fourth column\n",
        "cols = precollision.columns.tolist()\n",
        "cols = cols[:3] + cols[-1:] + cols[3:-1]\n",
        "precollision = precollision[cols]\n",
        "\n",
        "# move CRASH MOMENT to the fifth column\n",
        "cols = precollision.columns.tolist()\n",
        "cols = cols[:4] + cols[-1:] + cols[4:-1]\n",
        "precollision = precollision[cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "id": "mqHmMS1lzA1Z",
        "outputId": "57ce3f2b-c40d-43a3-e852-8e44fbbc5440"
      },
      "outputs": [],
      "source": [
        "precollision.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blHnEfSDzA1Z"
      },
      "source": [
        "#### Geographical attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTlI-coxzA1Z"
      },
      "source": [
        "At first glance, **ON STREET NAME** and **OFF STREET NAME** seem to be the same attribute, but with different names. The web site of the dataset cointains the following descriptions:\n",
        "\n",
        "- **ON STREET NAME**: *Street on which the collision occurred*.\n",
        "- **OFF STREET NAME**: *Street address if known*.\n",
        "\n",
        "This gives the idea that both attributes probably contain the same information. Furthermore, there are no rows with both attributes filled, which makes the idea of merging both attributes plausible and would consolidate information without redundancy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5w5C7qD6dp4"
      },
      "source": [
        "**Note**: *The utilization of the `collision` dataframe instead of the `precollision` dataframe is due to the distinction in their contents and alterations within the OpenRefine interface. Specifically, the `collision` DataFrame account for the actions carried out in the OpenRefine interface, illustrating the sequence of transformations and modifications made to the dataset.*\n",
        "\n",
        "*In contrast, the `precollision` DataFrame encapsulates the actual changes implemented within OpenRefine. This differentiation is crucial to clarify that the `collision` DataFrame primarily functions as an illustrative tool for explicating certain actions executed within the OpenRefine environment.*\n",
        "\n",
        "*Therefore, `collision` is used solely for explanatory purposes, offering insight into the sequence of actions performed during the data manipulation process within OpenRefine, while the actual modifications and alterations reside within the `precollision` DataFrame.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz7hvWXWzA1Z",
        "outputId": "fea45d35-68e2-4e9d-8b4b-3e2872a4e2d1"
      },
      "outputs": [],
      "source": [
        "collision[(collision['ON STREET NAME'].notnull()) & (collision['OFF STREET NAME'].notnull())].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT6EgbiOzA1Z",
        "outputId": "5d976c1a-44bb-4295-cea7-0bf3c7a01eda"
      },
      "outputs": [],
      "source": [
        "collision[(collision['ON STREET NAME'].notnull()) | (collision['OFF STREET NAME'].notnull())].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISHqC26ezA1Z"
      },
      "source": [
        "The resulting attribute after merging both columns is called **STREET NAME** and contains the street name/address where the collision occurred, with no missing values. Some rows will have a more detailed description of the street, while others will only have the name of the street."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKANbfF0zA1Z"
      },
      "source": [
        "**CROSS STREET**, which is the third attribute related to the street enviroment, and represents the name of the closest street crossing the street of the crash. Upon analysis, it has been determined that this attribute does not hold relevance or utility for the intended analysis objectives. Therefore, in the interest of streamlining the dataset and focusing on pertinent factors, the CROSS STREET attribute is considered non-essential and will be dropped from the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH1J3fpOzA1Z"
      },
      "source": [
        "Similarly, **LOCATION** seems to contain the tuple (**LATITUDE**, **LONGITUDE**), so we could, a priori, remove the two extra attributes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a2tXk2RzA1Z",
        "outputId": "ff5d308f-6e30-4e29-b560-43508e6e4fc9"
      },
      "outputs": [],
      "source": [
        "collision[(collision['LOCATION'].notnull()) & (collision['LATITUDE'].notnull()) & (collision['LONGITUDE'].notnull())].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB1jcbk-zA1e"
      },
      "source": [
        "The number of rows where the three attributes are not missing does not cover the total number of rows, but there are no rows where the **LOCATION** attribute is missing and at least one of the other two attributes is not missing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dSFAnAFzA1e",
        "outputId": "138e07d2-5110-48af-c21a-142567982b74"
      },
      "outputs": [],
      "source": [
        "collision[(collision['LOCATION'].isnull()) & (collision['LATITUDE'].isnull()) & (collision['LONGITUDE'].notnull()) | (collision['LATITUDE'].notnull()) & (collision['LONGITUDE'].isnull())].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5AzDXkszA1e",
        "outputId": "3eaf73bb-dec6-40f7-af8e-d5ead0255741"
      },
      "outputs": [],
      "source": [
        "collision[(collision['LOCATION'].isnull())].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKD6CQKlzA1f"
      },
      "source": [
        "Which makes the rest of the rows (7667) with missing values in the three attributes. This means that the **LATITUDE** and **LONGITUDE** attributes can be removed, since the **LOCATION** attribute contains the same information. With this transformation, the number of attributes is reduced by two."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16fqkbfZzA1f"
      },
      "source": [
        "The clustering process utilized the key collision method in conjunction with the fingerprint keying function, applied separately to each individual geographical attribute. After a couple of iterations, no substantial alterations in attribute values were identified. However, during this process, misspellings were detected and rectified to ensure data accuracy.\n",
        "\n",
        "The misspellings were corrected and the clusterization was done again. The results were the same, which means that the values were already consistent. To verify the result, a Neares Neighbours analysis was done as well but without finding any significant variation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5logvcvzA1f"
      },
      "source": [
        "#### Vehicle attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaDMh9fCzA1f"
      },
      "source": [
        "Regarding vehicle information, the statement of the project specifies that only the **VEHICLE CODE TYPE 1** is of interest to the visualization, leaving the remaining vehicle codes (2-5) irrelevant. Consequently, the associated contributing factors linked to these other vehicle types can also be excluded from the analysis.\n",
        "\n",
        "We have seen already that there are many classes of the **VEHICLE CODE TYPE 1** values. To simplify this complexity, we opted to reduce the diversity of classes by employing a clustering technique. This clustering methodology allowed us to condense the multitude of classes within **VEHICLE CODE TYPE 1** into a more manageable set of clusters, facilitating a more comprehensible and concise representation for subsequent visualization and analysis purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lccl8I3qzA1f",
        "outputId": "e1cc28e9-1cbf-4328-f841-2936ba8c9aa6"
      },
      "outputs": [],
      "source": [
        "len(collision['VEHICLE TYPE CODE 1'].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhD2iE4YzA1f"
      },
      "source": [
        "With the clusterization (key collision and fingerprint keying function) of the **VEHICLE TYPE CODE 1** attribute we found a lot of misspellings and inconsistencies. The clusterization was done iteratively, correcting the misspellings and inconsistencies found in each iteration.\n",
        "\n",
        "After several iterative steps, wherein numerous subclasses were consolidated into similar types of vehicles, resulting in a more aggregated dataset, the count of distinct classes decreased significantly. This reduction allowed for the remaining subclasses to be manually merged together, given their similarity or shared characteristics.\n",
        "\n",
        "For this manual clusterization, the `clusterize_vehicle_type` function was defined that aims to categorize or group different types of vehicles within a given DataFrame based on specific criteria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuZHtOwfzA1f"
      },
      "outputs": [],
      "source": [
        "precollision = pre.clusterize_vehicle_type(precollision, 'VEHICLE TYPE CODE 1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfgX3k7M9z-J"
      },
      "source": [
        "For example, certain types like 'SUV', 'FLAT', '3-DOOR', etc., are replaced with a common category name 'CAR'. Similarly, other types like 'BULK AGRICULTURE', 'PK', 'TANK', etc., are grouped under 'OTHERS'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfO7HaouzA1g"
      },
      "source": [
        "The resulting classes of the **VEHICLE CODE TYPE 1** attribute are:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm3Pnw8ZzA1g",
        "outputId": "6a38aac3-07e9-4888-ea00-2333325140c8"
      },
      "outputs": [],
      "source": [
        "len(precollision['VEHICLE TYPE CODE 1'].unique()), precollision['VEHICLE TYPE CODE 1'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8RTl21jzA1g"
      },
      "source": [
        "The chosen vehicle types were selected deliberately to strike a balance between having an excessive number of classes and too few to provide meaningful insights in the analysis. This selection aimed to offer the user a manageable yet comprehensive view of vehicle categories, ensuring that the analysis remains insightful without overwhelming the dataset with excessive vehicle classifications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhvaU_NWzA1g",
        "outputId": "f1cc3b12-100d-4b57-c0da-f160bb339907"
      },
      "outputs": [],
      "source": [
        "precollision['VEHICLE TYPE CODE 1'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGyhR4MlzA1g"
      },
      "source": [
        "Similar strategy was done with the **CONTRIBUTING FACTOR VEHICLE 1** attribute. However, the aggregation was not so exhaustive since this attribute wasn't needed a priori for the main questions that the visualizations should answer. For this attribute basic merge transformations were applied in OpenRefine until no \"strange\" or \"uninformative\" nor repeated classes remained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QNmXEp3zA1h",
        "outputId": "fdffd606-ff86-445d-871d-36409c562869"
      },
      "outputs": [],
      "source": [
        "len(precollision['CONTRIBUTING FACTOR VEHICLE 1'].unique()), precollision['CONTRIBUTING FACTOR VEHICLE 1'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "va1j4ehszA1h"
      },
      "source": [
        "#### Number of persons attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TADxT-6VzA1h"
      },
      "source": [
        "For the visualization purposes, the differentantion of **PERSONS**, **PEDESTRIANS**, **CYCLISTS** and **MOTORISTS** (**INJURED/KILLED**) is irrelevant. A more useful attribute would be the total number of persons involved in the collision. This can be obtained by summing the four attributes under the assumption that the **PERSONS** attribute is not the sum of the other three attributes.\n",
        "\n",
        "This condition was needed to be checked because the documentation of the dataset was not precise enough to determinate if **NUMBER OF PERSON INJURED/KILLED** was an aggregate from the other three columns or not.\n",
        "\n",
        "*Note: The metadata information available in the web of the dataset was: \"Number of persons injured/killed\" regarding the **NUMBER OF PERSONS INJURED/KILLED**.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P80N_rLSzA1i",
        "outputId": "8ea590ca-d161-4758-e4fa-077ffd92027c"
      },
      "outputs": [],
      "source": [
        "collision['NUMBER OF PERSONS INJURED'].equals(collision['NUMBER OF PEDESTRIANS INJURED'] + collision['NUMBER OF CYCLIST INJURED'] + collision['NUMBER OF MOTORIST INJURED'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xjj3r7vzA1i",
        "outputId": "05091d61-fbf4-4a50-995d-2f3ca8b4f509"
      },
      "outputs": [],
      "source": [
        "collision['NUMBER OF PERSONS INJURED'].equals(collision['NUMBER OF PEDESTRIANS INJURED'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7OqkiqR-q7p",
        "outputId": "2127a0de-5605-4c43-c8bb-43b787516f5c"
      },
      "outputs": [],
      "source": [
        "collision['NUMBER OF PERSONS KILLED'].equals(collision['NUMBER OF PEDESTRIANS KILLED'] + collision['NUMBER OF CYCLIST KILLED'] + collision['NUMBER OF MOTORIST KILLED'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpxzxWp1-qGB",
        "outputId": "ebbebff6-54e0-43c8-a92a-764b6d941ff3"
      },
      "outputs": [],
      "source": [
        "collision['NUMBER OF PERSONS KILLED'].equals(collision['NUMBER OF PEDESTRIANS KILLED'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0IFK4MmzA1i"
      },
      "source": [
        "As seen by the logical comprobations, the **NUMBER OF PERSONS INJURED/KILLED** is not the sum of the other three attributes. Furthermore, the terms persons and pedestrians are not equal, as one could have thought that the term persons was used to refer to pedestrians.\n",
        "\n",
        "Based on this, the discrete attributes refering to the injured people were summed to obtain **NUMBER OF INJURED** and the discrete attributes refering to the killed people were summed to obtain **NUMBER OF KILLED**. The **NUMBER OF INJURED/KILLED** attributes were removed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hxqx6fSzA1i"
      },
      "source": [
        "#### OpenRefine results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "id": "YbVW0ahdzA1i",
        "outputId": "b82fd2f0-cca3-499f-fd8d-588dc39bfb66"
      },
      "outputs": [],
      "source": [
        "precollision.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgzIN0LLzA1j"
      },
      "source": [
        "At this point, the dataset contains the attributes needed (with the *weather* attributes as an exception) for the analysis and some extra attributes that were considered interesting for some possible extra analysis or insights that we could think about."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Gvxz6SyzA1j"
      },
      "source": [
        "### Missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSx4mV5SzA1j"
      },
      "source": [
        "It has already been mentioned the existence of some missing values. In the previous section, the verification of missing values was done with the ``.isnull()`` method of ``Pandas``. However, this method does not take into account the ``NaN`` values. In order to check the existence of ``NaN`` values, the ``.isna()`` method was used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaP5-mvBzA1j",
        "outputId": "c24abc2f-08be-4cd6-ad33-bf5b4e79aa53"
      },
      "outputs": [],
      "source": [
        "comp = (precollision.isnull().sum() == precollision.isna().sum())\n",
        "comp[comp == False]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YOHLKVDzA1j"
      },
      "source": [
        "As seen previously, all the missing values of the dataset are detected both with ``.isnull()`` and ``.isna()``. After this check, we could group the attributes with missign values in three separeted clusters:\n",
        "- Geographical attributes\n",
        "- Injured/Killed attributes\n",
        "- Vehicle attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmiclSbZzA1j",
        "outputId": "96ab664e-1898-4320-ff64-4d9b9019e04f"
      },
      "outputs": [],
      "source": [
        "precollision.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuDh8Kx2zA1k"
      },
      "source": [
        "#### Imputation of geographic attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuZbRjQBzA1k"
      },
      "source": [
        "The first cluster is formed with reference to the geographicals attributes. The attributes in this cluster are:\n",
        "- **BOROUGH**\n",
        "- **ZIP CODE**\n",
        "- **LOCATION**\n",
        "- **STREET NAME**\n",
        "- **CROSS STREET NAME**\n",
        "\n",
        "Notice that the attributes with the less missing values is **STREET NAME** with only a $0.20\\%$ of the entire dataset, partially thanks to the merge of **ON STREET** and **OFF STREET** attributes in the previous sections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSQT0x2nzA1k",
        "outputId": "3398c418-2018-41ea-a56f-2f416fac2c65"
      },
      "outputs": [],
      "source": [
        "precollision['LOCATION'].isnull().sum(), precollision['STREET NAME'].isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DI1pZq_Bn9B"
      },
      "source": [
        "As the usage of the **STREET NAME** attribute remains uncertain for analysis, we have opted to retain the missing values within this attribute. Instead, our focus will be on removing rows with missing values in the **LOCATION** attribute. This decision is motivated by the small proportion of missing values in the **LOCATION** attribute relative to the entire dataset of `precollision`. Specifically, the missing values in **LOCATION** account for only $6.6\\%$ of the total rows within the dataset. This strategy aims to ensure data completeness in crucial fields while acknowledging the relatively minor impact of missing **LOCATION** data compared to the entire dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVIUwPiB_KdA"
      },
      "source": [
        "Based on reviews, it has come to our attention that merging the **LONGITUDE** and **LATITUDE** columns into a singular **LOCATION** attribute was an error. Several operations require distinct handling of each geometric attribute independently. Consequently, we have reversed this consolidation by dividing the **LOCATION** attribute back into its original two separate attributes: **LONGITUDE** and **LATITUDE**. This restoration will allow us to conduct specific operations and analyses on each geographical coordinate individually, ensuring accuracy and facilitating targeted manipulations or computations as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHhCMutKzA1k",
        "outputId": "49850d6f-b2c8-4d47-8063-038b6ba8ca1f"
      },
      "outputs": [],
      "source": [
        "precollision[['LATITUDE', 'LONGITUDE']] = precollision['LOCATION'].str.split(', ', expand=True)\n",
        "precollision['LATITUDE'] = precollision['LATITUDE'].str.replace('(', '')\n",
        "precollision['LONGITUDE'] = precollision['LONGITUDE'].str.replace(')', '')\n",
        "\n",
        "precollision['LATITUDE'] = precollision['LATITUDE'].astype(float)\n",
        "precollision['LONGITUDE'] = precollision['LONGITUDE'].astype(float)\n",
        "\n",
        "precollision.drop(columns=['LOCATION'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rs3boUPo_7gn"
      },
      "source": [
        "A simpler method for value imputation, as an alternative to directly imputing from the **STREET NAME** attribute, involves checking if a point specified by its coordinates (**LONGITUDE**, **LATITUDE**) falls within the boundary polygon of different boroughs. If the original attribute value is null, this method aims to assign the specific borough corresponding to the geographic location of the provided coordinates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5W4VtBpzA1k"
      },
      "outputs": [],
      "source": [
        "nyc_map = gpd.read_file('Data/new-york-city-boroughs-ny_.geojson')\n",
        "\n",
        "boroughs = ['Bronx', 'Brooklyn', 'Manhattan', 'Queens', 'Staten Island']\n",
        "\n",
        "# Extraction of the borough polygon\n",
        "borough_poly = {}\n",
        "for b in boroughs:\n",
        "    poly = nyc_map[nyc_map['name'] == b]['geometry']\n",
        "    borough_poly[b] = poly.values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ft838zyzA1k"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(f'{dir}/precollision_2018-2020_prepro_v2.csv'):\n",
        "    for idx, row in precollision.iterrows():\n",
        "        if row['BOROUGH'] is not None:\n",
        "            lon = row['LONGITUDE']\n",
        "            lat = row['LATITUDE']\n",
        "\n",
        "            if lat is not None and lon is not None:\n",
        "                p = Point(lon, lat)\n",
        "                for b, poly in borough_poly.items():\n",
        "                    if p.within(poly):\n",
        "                        precollision.loc[idx, 'BOROUGH'] = b.upper()\n",
        "                        break\n",
        "\n",
        "    precollision.to_csv(f'{dir}/precollision_2018-2020_prepro_v2.csv', index=False)\n",
        "else:\n",
        "    precollision = pd.read_csv(f'{dir}/precollision_2018-2020_prepro_v2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr5mkPNZzA1l",
        "outputId": "42fda35f-af8e-4349-a803-d32b13a4a057"
      },
      "outputs": [],
      "source": [
        "precollision['LATITUDE'].isna().sum(), precollision['BOROUGH'].isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sE2IcpFwFCjq"
      },
      "source": [
        "We observe a considerably lower number of missing values in the **BOROUGH** attribute compared to the missing values in the coordinates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd62ReZ3zA1l"
      },
      "source": [
        "#### Imputation of vehicle attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjFHf0AKzA1l"
      },
      "source": [
        "In some rows of the dataset, the **CONTRIBUTING FACTOR VEHICLE** is missing but the **VEHICLE TYPE CODE** is not. This suggests that the vehicle type is known, but the factor that contributed to the collision is not. In order to fill this missing values, the factor was set as *unespecified*. This was done for all the rows and columns where the **CONTRIBUTING FACTOR VEHICLE** was missing with the above condition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEniSo8BzA1m"
      },
      "outputs": [],
      "source": [
        "pre.imputation_with_ref_col(precollision, 'CONTRIBUTING FACTOR VEHICLE 1', 'VEHICLE TYPE CODE 1', 'Unspecified')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MMG-e8qzA1m"
      },
      "source": [
        "Likewise, in some rows of the dataset, the **VEHICLE TYPE CODE** is missing but the **CONTRIBUTING FACTOR VEHICLE** is not. This suggests that the factor that contributed to the collision is known, but the vehicle type is not. In order to fill this missing values, the vehicle type was set as *unknown*. This was done for all the rows and columns where the **VEHICLE TYPE CODE** was missing with the above condition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjpNB5c4zA1m"
      },
      "outputs": [],
      "source": [
        "pre.imputation_with_ref_col(precollision, 'VEHICLE TYPE CODE 1', 'CONTRIBUTING FACTOR VEHICLE 1', 'UNKNOWN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DcCW1dizA1m",
        "outputId": "c1ba0a77-09fa-4b4c-8d0b-e2f3297e31ff"
      },
      "outputs": [],
      "source": [
        "precollision.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vvSDVBuzA1n"
      },
      "source": [
        "#### Imputation of number of person attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "0UXni3skzA1n",
        "outputId": "efcb818f-7e3a-41bb-b71f-81e278c5b503"
      },
      "outputs": [],
      "source": [
        "precollision[precollision['NUMBER OF INJURED'].isnull() | precollision['NUMBER OF KILLED'].isnull()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXMRL7DCzA1n"
      },
      "source": [
        "Since the proportion of resulting rows with missing values in the count of persons involved in the collision is relatively minor compared to the entire dataset, the decision was made to impute these missing values by setting them to 0. This assumption is based on the premise that in these cases, no individuals were involved in the collision events where the data for this attribute was absent.\n",
        "\n",
        "Given the small percentage of the rows $0.01\\%$, it was considered that there would not be a significant impact in the final visualization whether the missing values were set to 0 or the rows with missing values were dropped. However, we decided to set the missing values to 0 in order to keep the rows and not lose some of its information. This was done also because **NUMBER OF INJURED** and  **NUMBER OF KILLED** were attributes that are not necessary for the main visualizations and we were only keeping them in case we found an intereseting extra visualization with them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxX9mqWNzA1n"
      },
      "outputs": [],
      "source": [
        "precollision['NUMBER OF INJURED'].fillna(0, inplace=True)\n",
        "precollision['NUMBER OF KILLED'].fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icjhVDhdzA1n",
        "outputId": "1a7c6daa-29ff-4f24-90ca-cbfd567f8b58"
      },
      "outputs": [],
      "source": [
        "precollision.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzhXBCLVJgKi"
      },
      "source": [
        "Considering the extent of missing data in the columns mentioned above and the fact that the **ZIP CODE** and **STREET NAME** columns are deemed irrelevant for the analysis, it may be reasonable to contemplate deleting rows with missing values. However, the decision to remove rows with missing values should be made cautiously, taking into account the impact on the overall analysis and the importance of the information contained in each column.\n",
        "\n",
        "Since the missing values in **BOROUGH**, **LATITUDE**, and **LONGITUDE** columns are relatively small in comparison to the total dataset size and the analysis does not heavily rely on these specific columns, removing rows with missing values could be a viable option. Nonetheless, it's crucial to assess the potential loss of valuable information and the significance of these columns in the context of the analysis before proceeding with the deletion of rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vo1qt_GxJq6Y",
        "outputId": "d146f1b4-373a-437d-cbe1-57b5a070fc91"
      },
      "outputs": [],
      "source": [
        "precollision[(precollision['BOROUGH'].isnull()) | (precollision['LONGITUDE'].isnull())].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXFu52oRJ6hx",
        "outputId": "b745e215-e195-4071-d632-9ced504216e6"
      },
      "outputs": [],
      "source": [
        "8820*100/115740"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEnRMncwzA1o"
      },
      "source": [
        "### Save the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jqlCgjzzA1o"
      },
      "outputs": [],
      "source": [
        "precollision.to_csv(f'{dir}/collisions_clean.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND0fW4QkzA1o",
        "outputId": "bca2e3cc-cef4-47b9-da82-47ed1749faf4"
      },
      "outputs": [],
      "source": [
        "precollision.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUIRTj8czA1o"
      },
      "source": [
        "## Weather dataset preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojFypXymzA1o"
      },
      "source": [
        "During the initial data download phase, all available attributes were selected. Subsequently, we intend to dive into the dataset to identify and select specific attributes that align with our project objectives. Our aim is to explore the entirety of the dataset comprehensively, evaluating each attribute's relevance and usefulness towards fulfilling our intended goals. This exploration will involve careful consideration of the attributes' significance in addressing our project's specific inquiries. Attributes consoidered pertinent and conducive to addressing our objectives will be retained for further analysis, while those less relevant or unrelated will be excluded from subsequent stages of our analysis and visualization process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHDOABG3zA1o",
        "outputId": "ebf7555f-a876-4fef-f3fb-af1d098b6628"
      },
      "outputs": [],
      "source": [
        "weather = pd.read_csv(f'{dir}/weather.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUWWz2X9zA1o"
      },
      "source": [
        "### Data exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-Jx0WOszA1o",
        "outputId": "d9c1e7f5-5703-41b7-df4b-bb62185d3836"
      },
      "outputs": [],
      "source": [
        "weather.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwiGHIrZzA1p"
      },
      "source": [
        "Since we are only interested in the rows where the date is inside the timeranges of 01/06/2018 - 31/09/2018 and 01/06/2020 - 31/09/2020, we will filter the data to only include those rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaCGdq2wzA1p",
        "outputId": "f59d09eb-fa1d-4f7a-bc80-e5834643cb8b"
      },
      "outputs": [],
      "source": [
        "if os.path.exists(f'{dir}/weather_2018-2020.csv'):\n",
        "    weather = pd.read_csv(f'{dir}/weather_2018-2020.csv')\n",
        "else:\n",
        "    weather = pre.time_filter(weather, 'DATE')\n",
        "    weather.to_csv(f'{dir}/weather_2018-2020.csv', index=False)\n",
        "\n",
        "weather.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PStK90LvzA1p",
        "outputId": "675d4875-5040-4652-9413-b1ac10766ec9"
      },
      "outputs": [],
      "source": [
        "weather.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXtG7OeMzA1p"
      },
      "source": [
        "By looking at the documentation of the weather datatset and the attributes present, each row represents some selected observations (values) available for a given **STATION** and **DATE**. Neither the **STATION** nor the **DATE** are unique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VInAs0ivzA1p",
        "outputId": "21347707-e041-40c0-8418-62f73375765d"
      },
      "outputs": [],
      "source": [
        "len(weather['STATION'].unique()), len(weather['DATE'].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rZt_xntzA1p"
      },
      "source": [
        "Apart from the first 6 columns (**SATTION**, **NAME**, **LATITUDE**, **LONGITUDE**, **ELEVATION** and **DATE**), the rest of the attributes correspond to optional flags and their respective attributes (definded by the weather documentation *Note: The 4 flags listed [...] are optional on the Custom GHCN-Daily ASCII Form*) and therefore can contain several null values. That is the reason for the large quantity of sparse attributes detected. We will explore the data to see which attributes are useful for our purpose.\n",
        "\n",
        "All these atributes correspond to the Table 4. A brief description is collected in the following table:\n",
        "\n",
        "| Attribute | Description |\n",
        "| --- | --- |\n",
        "| *PRCP* | Precipitation (mm) |\n",
        "| *SNOW* | Snowfall (mm) |\n",
        "| *SNWD* | Snow depth (mm) |\n",
        "| *TSUN* | Daily total sunshine (minutes) |\n",
        "| *TMAX* | Maximum temperature (Celsius) |\n",
        "| *TMIN* | Minimum temperature (Celsius) |\n",
        "| *TAVG* | Average temperature (Celsius) |\n",
        "| *TOBS* | Temperature at the time of observation |\n",
        "| *AWND* | Average daily wind speed (meters per second) |\n",
        "| *WT** | Weather type * |\n",
        "\n",
        "\n",
        "The next table contains the attributes that we considered that are not useful for the visualization purpose:\n",
        "\n",
        "| Attribute | Description |\n",
        "| --- | --- |\n",
        "| *PGTM* | Peak gust time (hours and minutes, i.e., HHMM) |\n",
        "| *DARP* | Number of days included in the multiday precipitation total (MDPR) |\n",
        "| *DASF* | Number of days included in the multiday snowfall total (MDSF) |\n",
        "| *MDPR* | Multiday precipitation total (mm; use with DAPR and DWPR, if available) |\n",
        "| *MDSF* | Multiday snowfall total (mm; use with DASF and DWSF, if available) |\n",
        "| *PSUN* | Daily percent of possible sunshine (percent; use with TSUN, if available) |\n",
        "| *WSF** | Fastest *-minute wind speed (meters per second) |\n",
        "| *WDF** | Direction of fastest *-second wind (degrees) |\n",
        "| *WESD* | Water equivalent of snow on the ground (decimal mm) |\n",
        "| *WESF* | Water equivalent of snowfall (decimal mm) |\n",
        "\n",
        "\n",
        "Both **DARP** and **DASF** don't directly measure specific weather conditions. They are more of an aggregate measure of precipitation/snowfall over multiple days, which is not useful for our purpose. The same applies to **MDPR**, **MDSF** and **PSUN** that are also not useful for our purpose since they are not specific weather conditions.\n",
        "Other attributes such as **WDF**, **WSF**, **WESD**, **WESF** or **PGTM** (among others) give data that is diffuclt to collect, therefore having a lot of null values, and is too specific to be useful for our analysis. For instance, all wind related attributes are not really useful for our analysis, and a simple and general attribute such as **AWND** is much more useful for our task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DVDFZvNzA1p"
      },
      "source": [
        "The ***_ATTRIBUTES** columns refer to the rest of the tables in the documentation (Table 1, 2, 3). These tables serve as flags for the measurement, quality and source of the data respectively. The values available for these attributes cover a wide range. In the data selection process we will analyze the subset of those values that are present in the data and discuss if they are useful for our purpose."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shFdKi5mzA1q"
      },
      "source": [
        "### Data selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CuCe6OVzA1q"
      },
      "source": [
        "#### Geographical attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu7w2WcYzA1q"
      },
      "source": [
        "We are planning to remove the **ELEVATION** column from our dataset. This column doesn't bear any apparent correlation or relevance to the existing dataset, and the information it provides isn't conducive to our visualization objectives. As such, eliminating this column will streamline the dataset for our specific analytical and visualization purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dj_wc3HVzA1q"
      },
      "outputs": [],
      "source": [
        "weather.drop(columns=['ELEVATION'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tluw6UY0zA1r"
      },
      "source": [
        "Given the presence of the coordinates attributes, the necessity of utilizing the **STATION** code or **NAME** seems redundant or unnecessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0i3oERZzA1r"
      },
      "outputs": [],
      "source": [
        "weather.drop(columns=['STATION', 'NAME'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl6hpT8mzA1r"
      },
      "source": [
        "#### Observational attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nsXej4ozA1r"
      },
      "source": [
        "Since we are analyzing the summer periods of 2018 and 2020, it is highly unlikely to have observations of snow in the records. Under this assumption we can drop the **SNOW** and **SNWD** attributes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlK9cKfszA1r",
        "outputId": "286d82fd-84b4-4b9d-e66a-b142c925eb41"
      },
      "outputs": [],
      "source": [
        "weather['SNOW'].unique(), weather['SNWD'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okddpz97zA1r"
      },
      "source": [
        "As we supposed, the only observations registred of **SNOW** and **SNWD** are null values or 0. Therefore, we can drop these columns and their respective flags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tO8tdX4zA1r"
      },
      "outputs": [],
      "source": [
        "weather.drop(columns=['SNOW', 'SNWD', 'SNOW_ATTRIBUTES', 'SNWD_ATTRIBUTES'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86hyUA9qzA1r"
      },
      "source": [
        "From the data exploration done in the previous section, we can remove the following attributes and their respective flags since we concluded their utility is really limited for our purpose: **DARP**, **DASF**, **MDPR**, **MDSF**, **PSUN**, **WDF**, **WESD**, **WESF** ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdZchGyDzA1s",
        "outputId": "6e3bca3c-a770-487d-f834-a7caeb9f5fb5"
      },
      "outputs": [],
      "source": [
        "weather.drop(columns=['DAPR',\n",
        "                        'DASF',\n",
        "                        'PGTM',\n",
        "                        'MDPR',\n",
        "                        'MDSF',\n",
        "                        'PSUN',\n",
        "                        'WDF2',\n",
        "                        'WDF5',\n",
        "                        'WESD',\n",
        "                        'WESF',\n",
        "                        'WSF2',\n",
        "                        'WSF5',\n",
        "                        'DAPR_ATTRIBUTES',\n",
        "                        'DASF_ATTRIBUTES',\n",
        "                        'MDPR_ATTRIBUTES',\n",
        "                        'MDSF_ATTRIBUTES',\n",
        "                        'PSUN_ATTRIBUTES',\n",
        "                        'WDF2_ATTRIBUTES',\n",
        "                        'WDF5_ATTRIBUTES',\n",
        "                        'WESD_ATTRIBUTES',\n",
        "                        'WESF_ATTRIBUTES',\n",
        "                        'WSF2_ATTRIBUTES',\n",
        "                        'WSF5_ATTRIBUTES'\n",
        "                        ], inplace=True)\n",
        "\n",
        "weather.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9io-xefWzA1s"
      },
      "source": [
        "Regarding the **WT*** columns, they all describe a specific weather condition that could be referred as *adverse condition* given the descriptions from the documentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX7CDPmPzA1t"
      },
      "source": [
        "\n",
        "| Attribute | Description |\n",
        "| --- | --- |\n",
        "| *WT02* | Heavy fog or heaving freezing fog (not always distinguished from fog) |\n",
        "| *WT03* | Thunder |\n",
        "| *WT04* | Ice pellets, sleet, snow pellets, or small hail\" |\n",
        "| *WT05* | Hail (may include small hail) |\n",
        "| *WT06* | Glaze or rime |\n",
        "| *WT08* | Smoke or haze |\n",
        "| *WT09* | Blowing or drifting snow |\n",
        "| *WT11* | High or damaging winds |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl2xr3J6zA1t"
      },
      "source": [
        "As checked, they all have the null values in the same rows, which could indicate that the ``nan`` value could mean a ``False`` value for all the adverse type of weather conditions, that is the corresponding record refers to a *normal* weather day. Therefore, we will replace the ``nan`` values with ``0``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iasXHSItzA1t",
        "outputId": "a8835521-dfbb-4e40-ad63-602634ccf1cf"
      },
      "outputs": [],
      "source": [
        "weather[weather['WT01'].isnull() & weather['WT02'].isnull() & weather['WT03'].isnull() & weather['WT04'].isnull() & weather['WT05'].isnull() & weather['WT06'].isnull() & weather['WT08'].isnull() & weather['WT09'].isnull() & weather['WT11'].isnull()].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_zTlHgszA1u",
        "outputId": "3c47ab20-0892-4b32-8270-6ec9bb943b96"
      },
      "outputs": [],
      "source": [
        "weather['WT01'].unique(), weather['WT02'].unique(), weather['WT03'].unique(), weather['WT04'].unique(), weather['WT05'].unique(), weather['WT06'].unique(), weather['WT08'].unique(), weather['WT09'].unique(), weather['WT11'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cV-5VJ0ozA1u"
      },
      "source": [
        "With this knowledge, the final decision was to merge all the **WT*** columns into a single one called **ADVERSE CONDITION**, which would have boolean values (0 or 1) indicating if the day was normal or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd4lArZvzA1u",
        "outputId": "e6e44e89-6c91-417e-a502-e582b680023a"
      },
      "outputs": [],
      "source": [
        "wt_columns = ['WT01', 'WT02', 'WT03', 'WT04', 'WT05', 'WT06', 'WT08', 'WT09', 'WT11']\n",
        "\n",
        "weather['ADVERSE_CONDITIONS'] = weather[wt_columns].isnull().all(axis=1).astype(int)\n",
        "weather['ADVERSE_CONDITIONS'] = 1 - weather['ADVERSE_CONDITIONS']\n",
        "\n",
        "weather['ADVERSE_CONDITIONS'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMC-U0-BzA1u"
      },
      "source": [
        "The flag attributes of the **WT*** columns will be removed given that the weather conditions columns were aggregated into a single column and thus the flags are not meaningful anymore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCPPSsWDzA1u",
        "outputId": "296b19c2-f272-46da-c9ce-742b75eb5558"
      },
      "outputs": [],
      "source": [
        "wt_columns_att = [col + '_ATTRIBUTES' for col in wt_columns]\n",
        "\n",
        "weather.drop(columns=wt_columns, inplace=True)\n",
        "weather.drop(columns=wt_columns_att, inplace=True)\n",
        "\n",
        "weather.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ2TetSKzA1u"
      },
      "source": [
        "#### Flags attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD6mXAFEzA1u"
      },
      "source": [
        "As done in the previous section, the ***_ATTRIBUTES** contain specific and irrelevant information  for our task, so it was decided to remove them all."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTPx6P59zA1v",
        "outputId": "21dcdb8e-6554-4488-f2c8-17dd15522495"
      },
      "outputs": [],
      "source": [
        "cols = weather.columns.tolist()\n",
        "\n",
        "for col in cols:\n",
        "    if '_ATTRIBUTES' in col:\n",
        "        print(col, weather[col].unique(), sep=':')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKLwbZ-MzA1v"
      },
      "outputs": [],
      "source": [
        "wt_columns_att = [col for col in weather.columns if '_ATTRIBUTES' in col]\n",
        "\n",
        "weather.drop(columns=wt_columns_att, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w13qDyQgzA1v"
      },
      "source": [
        "### Missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzjDoEPIzA1v"
      },
      "source": [
        "Considering the sparsity observed during data exploration, it is prudent to identify columns primarily composed of missing values for potential removal from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3Ohvue4zA1v",
        "outputId": "233faec8-0f42-4c31-bea3-0948d6398e7f"
      },
      "outputs": [],
      "source": [
        "weather.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L9b_y-WzA1v"
      },
      "source": [
        "As can be seen, **TSUN** column contains only missing values. Therefore, we will remove the column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLkNqO4ezA1w",
        "outputId": "85cb34c0-4080-4824-d4b7-525262fc1e66"
      },
      "outputs": [],
      "source": [
        "weather.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5PVoMFpzA1w"
      },
      "outputs": [],
      "source": [
        "weather.drop(columns=['TSUN'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUTk3CDHzA1w"
      },
      "source": [
        "Regarding the **PRCP** attribute, we'll proceed under the assumption that null values equate to zero. This assumption is based on the premise that the absence of recorded precipitation (signified by null values) suggests no actual precipitation occurred. We justify this assumption due to null values constituting approximately 10% of the dataset, which is a relatively moderate proportion. Furthermore, considering the dataset pertains to the summer season, a period typically characterized by lower precipitation occurrences, this assumption appears to carry a lesser risk as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZANIkMdzA1w"
      },
      "outputs": [],
      "source": [
        "weather['PRCP'].fillna(0.0, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYWIzisGzA1w"
      },
      "source": [
        "Regarding temperature, the great number of missing values is a problem. We will impute the missing values with the avergae temperature per day of each attribute (*TMAX*, *TMIN*, *TOBS*)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DM75x_yWzA1w"
      },
      "outputs": [],
      "source": [
        "weather['TMAX'] = weather.groupby('DATE')['TMAX'].transform(lambda x: x.fillna(x.mean()))\n",
        "weather['TMIN'] = weather.groupby('DATE')['TMIN'].transform(lambda x: x.fillna(x.mean()))\n",
        "weather['TOBS'] = weather.groupby('DATE')['TOBS'].transform(lambda x: x.fillna(x.mean()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf180_rZzA1w"
      },
      "source": [
        "Since the three attributes from above have been imputed, and **TAVG** contains the most missing values, it was decided to remove this row. In case we need an average for temperature we can compute it with the previous attributes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrsCDX07zA1x"
      },
      "outputs": [],
      "source": [
        "weather.drop(columns=['TAVG'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkyeFHDwzA1x",
        "outputId": "6481eb8b-007c-4ef4-8c09-dcff1b28582e"
      },
      "outputs": [],
      "source": [
        "weather.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE7jC8ztzA1x"
      },
      "source": [
        "We will apply the same strategy on AWND to get rid of the missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuCE8QoqzA1x"
      },
      "outputs": [],
      "source": [
        "weather['AWND'] = weather.groupby('DATE')['AWND'].transform(lambda x: x.fillna(x.mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZ40QbiWzA1x",
        "outputId": "193ca38a-8105-42fb-e468-364be22dd3fb"
      },
      "outputs": [],
      "source": [
        "weather.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-v0bLKMzA1x"
      },
      "source": [
        "For possible future analysis we will categorize the **AWND** and **PRCP** with the following scales:\n",
        "\n",
        "- **AWND** with Beaufort scale\n",
        "\n",
        "- **PRCP**  following the classification of the World Meteorological Organization, 2018(https://www.researchgate.net/figure/Rain-intensity-classifications-according-to-the-World-Meteorological-Organization-2018_tbl1_353769617)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pxeh54l9zA1x"
      },
      "source": [
        "### Data transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppUmDr3XNelY"
      },
      "source": [
        "It has been recognized that addressing the final question regarding the correlation between weather conditions and accidents necessitates the aggregation of weather measurements on a daily basis. This makes the coordinate attributes irrelevant as they pertain to specific measurement locations.\n",
        "\n",
        "However, rather than replacing the original dataset with an aggregated version, the decision has been made to generate a duplicate dataset named `weather_aggregated`. This duplicate dataset will serve as a copy where the necessary transformations and aggregations can be conducted while retaining the integrity of the original dataset for reference and comparative analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4M2KQSNjzA1x"
      },
      "outputs": [],
      "source": [
        "weather_aggregated = weather.copy()\n",
        "weather_aggregated.drop(columns=['LONGITUDE', 'LATITUDE', 'ADVERSE_CONDITIONS'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hJ6d_BaAzA1y",
        "outputId": "a1fdbb67-34dd-4027-9445-de533b4c6a1b"
      },
      "outputs": [],
      "source": [
        "weather_aggregated = weather_aggregated.groupby('DATE').mean().reset_index()\n",
        "weather_aggregated.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDqGWJo0PP3Q"
      },
      "source": [
        "Categorizing the Average Wind Speed (AWND) attribute with reference to the [Beaufort scale](https://en.wikipedia.org/wiki/Beaufort_scale) can provide several advantages for visualization and analysis purposes:\n",
        "\n",
        "1. **Standardization:** Allows for a standardized representation of wind intensity. This categorization simplifies the interpretation of wind speed data, making it more intuitive and comprehensible.\n",
        "\n",
        "2. **Visualization Clarity:** By mapping AWND values to the Beaufort scale categories, it facilitates clearer visualizations.\n",
        "\n",
        "4. **Enhanced Interpretation:** The descriptive labels (e.g., calm, moderate breeze, strong gale), enable an easier interpretation for individuals less familiar with raw wind speed values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGLKuUQbzA1y",
        "outputId": "33dbe45c-b7ad-4c1c-87c7-55de64967637"
      },
      "outputs": [],
      "source": [
        "weather_aggregated['BEAUFORT_SCALE'] = weather_aggregated['AWND'].apply(pre.beaufort_scale)\n",
        "weather_aggregated['BEAUFORT_SCALE'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkzjncBRRIj_"
      },
      "source": [
        "As well, categorizing precipitation levels **PRCP** using this scale simplifies the interpretation of rain intensity patterns, aiding in visualizations by offering descriptive categories that represent different levels of precipitation intensity, from slight to violent. These categories can enhance the understanding of the relationship between precipitation levels and other variables, facilitating the exploration and analysis of weather impact on collision occurrences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vieR2FOazA1y",
        "outputId": "beef08ae-d73a-41d6-f1be-1d99a837bfde"
      },
      "outputs": [],
      "source": [
        "weather_aggregated['PRCP_SCALE'] = weather_aggregated['PRCP'].apply(pre.rain_intensity_scale)\n",
        "weather_aggregated['PRCP_SCALE'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGVsGhyVzA1y"
      },
      "outputs": [],
      "source": [
        "weather_aggregated['MEAN_TEMP'] = weather_aggregated[['TMAX', 'TMIN', 'TOBS']].mean(axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRCGG2lnzA1y"
      },
      "source": [
        "### Save the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0TnTDv2zA1y"
      },
      "outputs": [],
      "source": [
        "weather.to_csv(f'{dir}/weather_clean.csv', index=False)\n",
        "weather_aggregated.to_csv(f'{dir}/weather_aggregated.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58w8K0-pzA1z"
      },
      "source": [
        "## Visualization creation process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ3qmC48jZRg"
      },
      "source": [
        "In all visualizations we have chosen color palettes suitable for color blindness, following the [Colorblind Safe Color Schemes](https://www.nceas.ucsb.edu/sites/default/files/2022-06/Colorblind%20Safe%20Color%20Schemes.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EAkXCJwzA1z"
      },
      "outputs": [],
      "source": [
        "weather = pd.read_csv(f'{dir}/weather_clean.csv')\n",
        "collisions = pd.read_csv(f'{dir}/collisions_clean.csv')\n",
        "nyc_map = gpd.read_file(f'{dir}/new-york-city-boroughs-ny_.geojson')\n",
        "weather_aggregated = pd.read_csv(f'{dir}/weather_aggregated.csv')\n",
        "\n",
        "\n",
        "collisions['YEAR'] = collisions['YEAR'].astype(str)\n",
        "\n",
        "alt.data_transformers.enable(\"default\")\n",
        "\n",
        "colores_hex = [\n",
        "    '#a3ffd6',  # Verde agua intenso\n",
        "    '#d69bf5',  # PÃºrpura intenso\n",
        "    '#ff8080',  # Rojo intenso\n",
        "    '#80ff80',  # Verde intenso\n",
        "    '#80bfff',  # Azul intenso\n",
        "    '#ffff66',  # Amarillo intenso\n",
        "    '#ffcc66',  # Naranja intenso\n",
        "    '#c9cba3',  # PÃºrpura intenso\n",
        "    '#66cccc',  # Verde azulado intenso\n",
        "    '#ff66b3',  # Rosa intenso\n",
        "    '#ffb056',  # Verde claro intenso\n",
        "    '#98c1d9',  # Rojo anaranjado intenso\n",
        "    '#ffafcc'   # Verde intenso\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeX2n-1wEw33"
      },
      "outputs": [],
      "source": [
        "collisions.drop(columns=['ZIP CODE', 'STREET NAME'])\n",
        "collisions.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7Mw_VuBzA10"
      },
      "source": [
        "### Are accidents more frequent during weekdays or weekends? Is there any difference between before COVID-19 and after?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TveGwLbQzA10"
      },
      "source": [
        "To answer the question in a pretty straightforward way, we decided that a slope chart would be a really good option since we first intend to show the difference between the average of weekdays and weekends for both years, so using a barchart would probably not be optimal. We consider that the results allow to answer the question pretty easily, however we want to explore some options that give the user more detail showing, for instance, all the days of the week."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2DSbpGhzA10",
        "outputId": "8f841239-5d84-4e4c-e36d-6cc082ffdb65"
      },
      "outputs": [],
      "source": [
        "collisions['TYPE OF DAY'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "Z3pw7nZJzA10",
        "outputId": "d5b8ae14-dfdf-4b6a-bf3c-20c72c97b09e"
      },
      "outputs": [],
      "source": [
        "df = collisions.loc[:, ['YEAR', 'DAY NAME', 'TYPE OF DAY']]\n",
        "df.insert(0, 'COUNT', 1)\n",
        "\n",
        "df = df.groupby(['YEAR', 'TYPE OF DAY']).count().reset_index()\n",
        "# divide count by 5 if it is a weekday\n",
        "df['COUNT'] = df.apply(lambda x: x['COUNT']/5 if x['TYPE OF DAY'] == 'Weekday' else x['COUNT']/2, axis=1)\n",
        "\n",
        "\n",
        "slope = alt.Chart(df).mark_line().encode(\n",
        "    x=alt.X('YEAR:N', title='Year', axis=alt.Axis(labelAngle=0)),\n",
        "    y=alt.Y('COUNT:Q', title='Collisions per Day'),\n",
        "    color=alt.Color('TYPE OF DAY:N', legend=alt.Legend(title='Day Type'))\n",
        ")\n",
        "\n",
        "pts = alt.Chart(df).mark_point(\n",
        "    filled=True,\n",
        "    opacity=1\n",
        ").encode(\n",
        "    x=alt.X('YEAR:N', title='Year', axis=alt.Axis(labelAngle=0)),\n",
        "    y=alt.Y('COUNT:Q', title='Collisions per Day'),\n",
        "    color=alt.Color('TYPE OF DAY:N',\n",
        "                    scale=alt.Scale(range=['#B3E9C7', '#8367C7']),\n",
        "                    legend=None)\n",
        ")\n",
        "alt.layer(slope, pts).properties(width=100, height=300, title='Collisions per Day Type by Year')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jv9_0ivtzA10"
      },
      "outputs": [],
      "source": [
        "df = collisions.groupby('YEAR')[['NUMBER OF INJURED']].sum().reset_index()\n",
        "\n",
        "df2 = collisions.groupby('YEAR')[['COLLISION_ID']].count()\n",
        "df = df.merge(df2, on='YEAR')\n",
        "\n",
        "df['TOTAL PER 10'] = 10 * df['NUMBER OF INJURED'] / df['COLLISION_ID']\n",
        "df = df.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FR_Yd2CWzA10"
      },
      "outputs": [],
      "source": [
        "car = (\"M640 320V368C640 385.7 625.7 400 608 400H574.7C567.1 445.4 527.6 480 480 480C432.4 480 392.9 445.4 385.3 400H254.7C247.1 445.4 207.6 480 160 480C112.4 480 72.94 445.4 65.33 400H32C14.33 400 0 385.7 0 368V256C0 228.9 16.81 205.8 40.56 196.4L82.2 92.35C96.78 55.9 132.1 32 171.3 32H353.2C382.4 32 409.1 45.26 428.2 68.03L528.2 193C591.2 200.1 640 254.8 640 319.1V320zM171.3 96C158.2 96 146.5 103.1 141.6 116.1L111.3 192H224V96H171.3zM272 192H445.4L378.2 108C372.2 100.4 362.1 96 353.2 96H272V192zM525.3 400C527 394.1 528 389.6 528 384C528 357.5 506.5 336 480 336C453.5 336 432 357.5 432 384C432 389.6 432.1 394.1 434.7 400C441.3 418.6 459.1 432 480 432C500.9 432 518.7 418.6 525.3 400zM205.3 400C207 394.1 208 389.6 208 384C208 357.5 186.5 336 160 336C133.5 336 112 357.5 112 384C112 389.6 112.1 394.1 114.7 400C121.3 418.6 139.1 432 160 432C180.9 432 198.7 418.6 205.3 400z\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "vj4XxrXxzA11",
        "outputId": "0af5125f-ab4e-42bd-aca7-66c089311407"
      },
      "outputs": [],
      "source": [
        "data = pd.DataFrame([dict(id=i) for i in range(1, 11)])\n",
        "\n",
        "data['color'] = ['kill/injured' if i < 6 else 'non' for i in range(1, 11)]\n",
        "\n",
        "data['year'] = ['2018'] * 10\n",
        "\n",
        "alt.Chart(data).transform_calculate(\n",
        "    row=\"ceil(datum.id/10)\"\n",
        ").transform_calculate(\n",
        "    col=\"datum.id - datum.row*10\"\n",
        ").mark_point(\n",
        "    filled=True,\n",
        "    size=0.04\n",
        ").encode(\n",
        "    alt.X(\"col:O\", axis=None),\n",
        "    alt.Y(\"row:O\", axis=None),\n",
        "    alt.ShapeValue(car),\n",
        "    color=alt.Color('color:N',\n",
        "                    scale=alt.Scale(domain=['kill/injured', 'non'],range=['#5603ad', '#9BA8C7']),\n",
        "                    legend=None)\n",
        ").properties(\n",
        "    width=900,\n",
        "    height=130\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "mHJhEn5TzA11",
        "outputId": "1cf3353e-43b3-4fd8-d93d-3ff383e4d9e1"
      },
      "outputs": [],
      "source": [
        "data = pd.DataFrame([dict(id=i) for i in range(1, 11)])\n",
        "\n",
        "data['color'] = ['kill/injured' if i < 10 else 'non' for i in range(1, 11)]\n",
        "\n",
        "data['year'] = ['2020'] * 10\n",
        "\n",
        "alt.Chart(data).transform_calculate(\n",
        "    row=\"ceil(datum.id/10)\"\n",
        ").transform_calculate(\n",
        "    col=\"datum.id - datum.row*10\"\n",
        ").mark_point(\n",
        "    filled=True,\n",
        "    size=0.04\n",
        ").encode(\n",
        "    alt.X(\"col:O\", axis=None),\n",
        "    alt.Y(\"row:O\", axis=None),\n",
        "    alt.ShapeValue(car),\n",
        "    color=alt.Color('color:N',\n",
        "                    scale=alt.Scale(domain=['kill/injured', 'non'],range=['#5603ad', '#9BA8C7']),\n",
        "                    legend=None)\n",
        ").properties(\n",
        "    width=900,\n",
        "    height=130\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4si9IOYGzA11"
      },
      "source": [
        "The first and simpler option to give more detail than in the previous chart is to make a barplot. With just to options it wasn't such a good idea, but if we show all the days of the week it makes much more sense. Since we want the names of the days to be legible the idea is to make an horizontal bar chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79wXZWiaD-Ba",
        "outputId": "e4c63614-66c6-42f3-cc8a-1528cbad92e3"
      },
      "outputs": [],
      "source": [
        "alt.data_transformers.enable(\"vegafusion\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "KJgnMwjXzA11",
        "outputId": "a7500f30-3c5a-4772-bc01-eb823a5b8f92"
      },
      "outputs": [],
      "source": [
        "df = collisions[['DAY NAME']]\n",
        "\n",
        "alt.Chart(df).mark_bar().encode(\n",
        "    x=alt.X('count():Q',\n",
        "            title='Number of Collisions'),\n",
        "    y=alt.Y('DAY NAME:O',\n",
        "            sort=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'],\n",
        "            title='Day of the Week'),\n",
        "    color=alt.Color('DAY NAME:O',\n",
        "                    scale=alt.Scale(domain=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'],\n",
        "                                    range=['#B3E9C7', '#B3E9C7', '#B3E9C7', '#B3E9C7', '#B3E9C7', '#8367C7', '#8367C7']),\n",
        "                                    legend=None)\n",
        ").properties(\n",
        "    width=500,\n",
        "    height=200,\n",
        "    title='Number of Collisions by Day of the Week'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBGjWK6kzA11"
      },
      "source": [
        "As mentioned, this option is simple but effective in its task. However, we are also asked to show if there is a difference between before and after COVID-19 (that is between 2018 and 2020), so in future iterations of the visualization we should take this into account.\n",
        "\n",
        "The next visualizaiton intends to answer the same question, but also tries to show if there is a time period of the day (morning, afternoon, night) that has more crashes than others. Nevertheless, the outcome is not really useful since the comparison between bars and inside bars is pretty diffuclt, moreover, the colors catch the attention so it's also more difficult (it takes longer since there are more variables encoded) than in the previous visualization to identify the days with more crashes. Again, it fails to show a differentiation between years so we shall look for other options."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "qoTUn1MjzA11",
        "outputId": "031290a3-a40f-4f42-d831-80f5f615b52c"
      },
      "outputs": [],
      "source": [
        "df = collisions[['DAY NAME', 'CRASH MOMENT']]\n",
        "\n",
        "bars = alt.Chart(df).mark_bar().transform_calculate(\n",
        "    order=\"{'Morning': 1, 'Afternoon': 2, 'Night': 3}[datum['CRASH MOMENT']]\"\n",
        ").encode(\n",
        "    x=alt.X('count():Q',\n",
        "            title='Number of Collisions',\n",
        "            stack='zero'),\n",
        "    y=alt.Y('DAY NAME:N',\n",
        "            sort=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'],\n",
        "            title='Day of the Week'),\n",
        "    color=alt.Color('CRASH MOMENT:N',\n",
        "                    title='Moment of the Day',\n",
        "                    scale=alt.Scale(domain=['Morning', 'Afternoon', 'Night'],\n",
        "                                    range=['#B3E9C7', '#9BA8C7', '#8367C7'])),\n",
        "    order=alt.Order('order:O')\n",
        ").properties(\n",
        "    width=500,\n",
        "    height=200,\n",
        "    title='Number of Collisions by Day of the Week'\n",
        ")\n",
        "\n",
        "text = alt.Chart(collisions[['DAY NAME', 'CRASH MOMENT']]).mark_text(\n",
        "    align='right',\n",
        "    color='black',\n",
        "    baseline='middle'\n",
        ").transform_calculate(\n",
        "    order=\"{'Morning': 1, 'Afternoon': 2, 'Night': 3}[datum['CRASH MOMENT']]\"\n",
        ").encode(\n",
        "   x=alt.X('count():Q',\n",
        "            title='Number of Collisions',\n",
        "            stack='zero'),\n",
        "    y=alt.Y('DAY NAME:N',\n",
        "            sort=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'],\n",
        "            title='Day of the Week'),\n",
        "    detail=alt.Detail('CRASH MOMENT:N'),\n",
        "    text=alt.Text('count():Q'),\n",
        "    order=alt.Order('order:O')\n",
        ")\n",
        "\n",
        "bars + text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyMbZ8YAzA12"
      },
      "source": [
        "To deal with the differentiation between 2018 and 2020, in which the previous visualizations fail, an interesting option is to do a paired horizontal bar chart. Since there is only two classes inside every row, (theoretically) the comaprison between instances from different rows is not as difficult as it would be if there were more categories. Therefore, we consider this visualization to accomplish its objectives, but we will keep iterating to see if a better result can be found. Therefore, we consider that this visualization should accomplish its objectives and be useful t answer the questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "X56HkvMmzA12",
        "outputId": "078cb982-3427-43a4-c8d4-bdd9037d60bf"
      },
      "outputs": [],
      "source": [
        "df = collisions[['YEAR', 'DAY NAME']]\n",
        "\n",
        "alt.Chart(df).transform_aggregate(\n",
        "    count='count()',\n",
        "    groupby=['DAY NAME', 'YEAR']\n",
        ").mark_bar().encode(\n",
        "    x=alt.X('count:Q',\n",
        "            title='Number of Collisions'),\n",
        "    y=alt.Y('YEAR:O',\n",
        "            axis=alt.Axis(grid=False, ticks=False, labels=False),\n",
        "            title=''),\n",
        "    color=alt.Color('YEAR:N',\n",
        "                    scale=alt.Scale(domain=['2018', '2020'],\n",
        "                                    range=['#B3E9C7', '#8367C7']),\n",
        "                    legend=alt.Legend(title='Year')),\n",
        "    row=alt.Row('DAY NAME:O',\n",
        "                      header=alt.Header(title='Day of the Week'),\n",
        "                      sort=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'],\n",
        "                      title='Day of the Week')\n",
        ").properties(\n",
        "    title='Number of Collisions by Day of the Week and Year'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkunNactzA12"
      },
      "source": [
        "Contrary to what we thought, the result is not as good as expected. Because of the separation per days, the comparison between days is not so easy, and this problem is accentuated for the 2020 instances which vary less and because of this and the separation the differences are more difficult to notice. Moreover, the names of the days are in vertical which makes them diffuclt to read; this problem can be solved easily but teh previously mentioned ones will still be there."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ma9CA0XCzA12"
      },
      "source": [
        "Trying to ease the comparison between instances, an option we considered useful was a small multiples of the initial barchart, one for each year. At first this may not seem a great option if we are trying to enhance the comparison, but we consider that the fact of only havig two barcharts that share indexes and are aligned makes the comparison between instances of the different charts pretty easy and, of course, the comparison between instances of the same chart is as good as for the initial plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "PqLEdnIMzA12",
        "outputId": "4deb60c7-0ba6-4c95-ebe7-a607759ce56a"
      },
      "outputs": [],
      "source": [
        "df = collisions[['YEAR', 'DAY NAME']]\n",
        "\n",
        "alt.Chart(df).mark_bar().encode(\n",
        "    x=alt.X('count():Q'),\n",
        "    y=alt.Y('DAY NAME:O',\n",
        "            title='Day of the Week',\n",
        "            sort=alt.SortField(field='DAY NAME', order='ascending')),\n",
        "    color=alt.Color('YEAR:O',\n",
        "                    scale=alt.Scale(domain=['2018', '2020'], range=['#C2F8CB', '#8367C7']),\n",
        "                    legend=None),\n",
        "    column=alt.Column('YEAR:O', title='Year')\n",
        ").properties(\n",
        "    width=200,\n",
        "    height=200,\n",
        "    title='Number of Collisions by Day of the Week (2018 vs. 2020)'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuCPQK-qzA12"
      },
      "source": [
        "The main flaw of this plot is that it may be \"wasting some space\" and it may not be the best option to see the general trend.\n",
        "\n",
        "Since we will be showing more detail of the days of the week in the visualization for the third question, we finally decided to use the slope chart for this question. As mentioned earlier, we consider that it is really useful to answer the question posed. Moreover it is simple and does not occupy as much space as the other options. The main flaw of this plot, even if the question doesn't ask explicitly for it, is that some detail is lost when aggregating all days in weekday or weekend."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5SgyogDzA13"
      },
      "source": [
        "### Is there any type of vehicle more prone to participate in accidents?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXkwXoppzA13"
      },
      "outputs": [],
      "source": [
        "collisions['YEAR'] = collisions['YEAR'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buSK6TqyzA13",
        "outputId": "d692db80-951f-4e3a-db2d-cbb7d8d7b664"
      },
      "outputs": [],
      "source": [
        "collisions[\"VEHICLE TYPE CODE 1\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJCA7L7azA13"
      },
      "source": [
        "Given that we aggregated the type of vehicles to a total of just 13 classes, the bar chart is the first option that comes to our mind."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "CYCL-I0DzA13",
        "outputId": "5eb6d6bd-b6a7-4d2a-c082-31cd79b8dc63"
      },
      "outputs": [],
      "source": [
        "df = collisions[['VEHICLE TYPE CODE 1']]\n",
        "\n",
        "alt.Chart(df).mark_bar().encode(\n",
        "    x=alt.X('VEHICLE TYPE CODE 1:N', title='Vehicle Type', axis=alt.Axis(labelAngle=-45)),\n",
        "    y=alt.Y('count():Q', title='Number of Collisions')\n",
        ").properties(\n",
        "    width=500,\n",
        "    height=200,\n",
        "    title='Number of Collisions by Vehicle Type'\n",
        ").configure_mark(\n",
        "    color='#6D35BA'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_OyjwhWzA13"
      },
      "source": [
        "The result is decent but at the same time there are some classes barely noticeable. We want to clarify that the answer of this question is impossible with the available data, since we would need the traffic percenatge or proportion of every type of vehicle to determine if there is a vehicle more prone to have crashes than others. This happens because, for example, there are much more cars than ambulances, so the number of total car crashes is much bigger than the numbe of total ambulance crashes, and without the traffic proportions we can't really say if one of the vehicles is more prone to have an accident than the others.\n",
        "\n",
        "Having stated this, we thought that polar area charts could be a good option to make the classes with less crashes more noticeable. We are aware that the comparison between areas is more difficult, however we believe that the main (erroneous for the reasons previously explained) conclusions for the question are still clear enough and pretty understandable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "LlROd5D4zA14",
        "outputId": "5be64cd7-5403-4b11-c3dd-0312b68700a3"
      },
      "outputs": [],
      "source": [
        "alt.Chart(collisions).encode(\n",
        "    alt.Theta(\"VEHICLE TYPE CODE 1:N\",\n",
        "              stack = True,\n",
        "              sort=alt.EncodingSortField(field=\"count\", op=\"count\", order='descending')),\n",
        "    alt.Radius(\"count()\",\n",
        "               scale=alt.Scale(type=\"sqrt\", zero=True, rangeMin=20)),\n",
        "    color=alt.Color(\"VEHICLE TYPE CODE 1:N\",\n",
        "                    sort=alt.EncodingSortField(field=\"count\", op=\"count\", order='descending'),\n",
        "                    scale=alt.Scale(range=colores_hex),\n",
        "                    legend=alt.Legend(title=\"Vehicle Type\")),\n",
        ").mark_arc(\n",
        "    innerRadius=5, stroke=\"#fff\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4fFeDX2zA14"
      },
      "source": [
        "The choice of this palette with no colors being extremely similar or much more appealing than others allows for a good idenftification of the thirteen instances. The strength of the chart is taht allows to see the groups with less total crashes, so the user can compare the smaller classes aswell as the bigger ones. However, the problem is, as explained previously, that areas are much more difficult to compare than lenghts, so although the user can say which are bigger than others (since its ordered by size), he can't really quantify how much bigger are ones from others."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po2AMXTLzA14"
      },
      "source": [
        "To solve this problem, we determined that the solution would be to aggregate the numbers with the actual counts of crashes to each of the instances. Which resulted in the following plot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "IW1Fel2uzA14",
        "outputId": "6b7dbf94-ada9-49be-a1b9-86c72a47c279"
      },
      "outputs": [],
      "source": [
        "c1 = alt.Chart(collisions).encode(\n",
        "    alt.Theta(\"VEHICLE TYPE CODE 1:N\",\n",
        "              stack = True,\n",
        "              sort=alt.EncodingSortField(field=\"count\", op=\"count\", order='descending')),\n",
        "    alt.Radius(\"count()\",\n",
        "               scale=alt.Scale(type=\"sqrt\", zero=True, rangeMin=20)),\n",
        "    color=alt.Color(\"VEHICLE TYPE CODE 1:N\",\n",
        "                    sort=alt.EncodingSortField(field=\"count\", op=\"count\", order='descending'),\n",
        "                    scale=alt.Scale(range=colores_hex),\n",
        "                    legend=alt.Legend(title=\"Vehicle Type\")),\n",
        ").mark_arc(\n",
        "    innerRadius=5, stroke=\"#fff\"\n",
        ")\n",
        "\n",
        "text = c1.mark_text(\n",
        "    align='center',\n",
        "    baseline='middle',\n",
        "    radiusOffset=20,\n",
        "    fontSize=12.5,\n",
        ").encode(\n",
        "    text='count()'\n",
        ")\n",
        "\n",
        "alt.layer(c1 + text).properties(\n",
        "    title='Number of Collisions by Vehicle Type'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4nFhunuzA15"
      },
      "outputs": [],
      "source": [
        "# create a new column that sums NUMBER OF PERSONS INJURED and NUMBER OF PERSONS KILLED\n",
        "collisions['TOTAL INJURED/KILLED'] = collisions['NUMBER OF INJURED'] + collisions['NUMBER OF KILLED']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2TikLv6zA15"
      },
      "source": [
        "The last option we considered is a lollipop chart since it allows an easy comparison of several instances. The result is the following and it is similar to the one of a typical barchart. Simple and effective, but with the same problem of some types of vehicle being unnoticeable and impossible to differentiate (the ones with the lowest counts of crashes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "6TVcukeBzA15",
        "outputId": "32c324ee-3b36-4ea1-9685-a308514f6dc2"
      },
      "outputs": [],
      "source": [
        "df = collisions[['VEHICLE TYPE CODE 1', 'TOTAL INJURED/KILLED']]\n",
        "\n",
        "df1 = df.groupby('VEHICLE TYPE CODE 1').sum(\"TOTAL INJURED/KILLED\").reset_index()\n",
        "df2 = df.groupby('VEHICLE TYPE CODE 1').count().reset_index()\n",
        "\n",
        "df2.columns = ['VEHICLE TYPE CODE 1', 'TOTAL COLLISIONS']\n",
        "\n",
        "df = pd.merge(df1, df2, on='VEHICLE TYPE CODE 1')\n",
        "\n",
        "\n",
        "lolli = alt.Chart(df).mark_bar(\n",
        "    size=3\n",
        ").encode(\n",
        "    x=alt.X('TOTAL COLLISIONS:Q',\n",
        "            title='Total Collisions'),\n",
        "    y=alt.Y('VEHICLE TYPE CODE 1:N',\n",
        "            title='Vehicle Type',\n",
        "            sort=alt.EncodingSortField(field=\"TOTAL COLLISIONS\", order=\"descending\"),\n",
        "            axis=alt.Axis(labelAngle=0, grid=True)),\n",
        "    color=alt.Color('VEHICLE TYPE CODE 1:N',\n",
        "                    title='Vehicle Type',\n",
        "                    legend=None),\n",
        ")\n",
        "\n",
        "pop = alt.Chart(df).mark_circle(\n",
        "    tooltip=True,\n",
        "    size=80,\n",
        "    opacity=1\n",
        ").encode(\n",
        "    x=alt.X('TOTAL COLLISIONS:Q',\n",
        "            title='Total Collisions'),\n",
        "    y=alt.Y('VEHICLE TYPE CODE 1:N',\n",
        "            title='Vehicle Type',\n",
        "            sort=alt.EncodingSortField(\n",
        "                field=\"TOTAL COLLISIONS\",\n",
        "                order=\"descending\"),\n",
        "            axis=alt.Axis(labelAngle=0, grid=True)),\n",
        "    color=alt.Color('VEHICLE TYPE CODE 1:N',\n",
        "                    title='Vehicle Type',\n",
        "                    legend=None),\n",
        "    tooltip=['VEHICLE TYPE CODE 1:N', 'TOTAL COLLISIONS:Q', 'TOTAL INJURED/KILLED:Q']\n",
        ").properties(\n",
        "    title='Lollipop Plot of Collisions by Vehicle Type and Contributing Factor'\n",
        ")\n",
        "\n",
        "lolli + pop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Uww2G1ZzA15"
      },
      "source": [
        "We decided that the best option in this case is the last iteration of the polar area chart. It solves the problem of less common classes being really difficult to differentiate and offers the actual count values so that the user can get an idea of how much difference is between the number of accidents of the different vehicle types. A possible problem is that for this type of chart so many instances could be difficult to interpret at first glance, but since we have chosen a proper palette, ordered the instances by value and written their values, we consider this is just a minor problem that should not affect much the aim of the visualization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rDVzpMXzA16"
      },
      "source": [
        "### At what time of the day are accidents more common?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzqDLeCtzA16"
      },
      "outputs": [],
      "source": [
        "collisions['YEAR'] = collisions['CRASH DATE'].astype(str).str[:4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcnFs0plzA16"
      },
      "source": [
        "Since we aggregated the count accidents by time of the day in hours, we consider that a line chart is a great option to represent the evolution of total car crashes per hours. Also, this type of chart allows to separate the data by years (2018, 2020) very easlily to add extra information. As we can see the result clearly shows the top hours with more crashes and allows an easy comparison between hours and years."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "jWdyWDBGzA16",
        "outputId": "1a1da1b3-f57e-439a-f626-745a46992859"
      },
      "outputs": [],
      "source": [
        "df = collisions[['COLLISION_ID', 'CRASH TIME INTERVAL', 'YEAR']]\n",
        "\n",
        "alt.Chart(df).mark_area(\n",
        "    point=True,\n",
        "    fillOpacity=0.8,\n",
        "    line=True,\n",
        "    tooltip=True\n",
        "    # interpolate='monotone'\n",
        ").transform_aggregate(\n",
        "    count='count()',\n",
        "    groupby=['YEAR', 'CRASH TIME INTERVAL']\n",
        ").encode(\n",
        "    x=alt.X('CRASH TIME INTERVAL:O', title='Hour of the Day', axis=alt.Axis(labelAngle=0)),\n",
        "    y=alt.Y('count:Q', title='Number of Collisions', stack=None),\n",
        "    color=alt.Color('YEAR:N', title='Year', scale=alt.Scale(domain=['2018', '2020'], range=['lightblue', 'lightgreen'])),\n",
        "    tooltip=['count:Q', 'CRASH TIME INTERVAL:O']\n",
        ").properties(\n",
        "    title='Number of Collisions by Hour of the Day'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Vicuqc-zA16"
      },
      "source": [
        "Another option we considered is a heatmap. This time we also add the day of the week and not only the time of the day, so this visualization not only helps knowing in which time of the day there are more crashes but also allows us to answer the question that asks us to analyze if there are more crashes in weekends or in weekdays, giving more detail and context to the first question. We consider the result to be pretty useful and clear. The only issue is that this visualization does not allow to compare between years, however this is not an important problem since, as mentioned, there is a specific visualization for that task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "id": "939f-OykzA16",
        "outputId": "c6c28e47-b6de-4676-e6f7-15676fd86396"
      },
      "outputs": [],
      "source": [
        "collisions.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "7gaJZBnFzA16",
        "outputId": "82d2913b-be6c-4584-a458-b0c51fd9f294"
      },
      "outputs": [],
      "source": [
        "c1 = alt.Chart(collisions[['CRASH TIME INTERVAL', 'DAY NAME', 'YEAR']]).mark_rect(\n",
        "    tooltip=True\n",
        ").encode(\n",
        "    x=alt.X('CRASH TIME INTERVAL:N',\n",
        "            title='Hour of the Day',\n",
        "            axis=alt.Axis(labelAngle=0)),\n",
        "    y=alt.Y('DAY NAME:N',\n",
        "            sort=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'],\n",
        "            title='Day of the Week'),\n",
        "    color=alt.Color('count():Q',\n",
        "                    title='Number of Collisions',\n",
        "                    scale=alt.Scale(range=['#f0fff1', '#5603ad'])),\n",
        "    tooltip=['count()']\n",
        ").properties(\n",
        "    title='Number of Collisions by Hour of the Day and Day of the Week'\n",
        ")\n",
        "\n",
        "c1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2sZYCYZzA17"
      },
      "source": [
        "While the line chart is a great option, we concluded that the best option for this case is the heatmap. This is mainly because it gives an extra layer of detail and this detail complements the visualization for the first question. The color palette chosen also allows people affected by color blindness to be able to draw conclusions without any difficulties."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgPzLgFVzA17"
      },
      "source": [
        "### Are there any areas with a larger number of accidents?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xabSEp9TzA17"
      },
      "source": [
        "This is the map of New York City diveded in boroughs, we first thought about using a dot map. However, the great amount of instances, the limited space for the visualizations and the restriction of not using interactive plots, made us change our mind after some simple tries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "PEY7FpIzzA17",
        "outputId": "4673e747-5b32-485a-e75c-6e0c945adf1d"
      },
      "outputs": [],
      "source": [
        "nyc = alt.Chart(nyc_map).mark_geoshape(\n",
        "    stroke='white',\n",
        "    strokeWidth=1,\n",
        "    filled=True\n",
        ").encode(\n",
        "    color=alt.Color('name',\n",
        "                    scale=alt.Scale(scheme='greys'),\n",
        "                    title='Borough'),\n",
        ").project(\n",
        "    type='identity', reflectY=True\n",
        ")\n",
        "nyc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBjnnlVlzA17"
      },
      "source": [
        "We decided to do a choropleth map, but dividing the main regions into smaller geometrical forms (hexagons), so the areas would be easier to compare. We use a sequential palette that represents the quantites aggrupated in every hexagon, so the user can see in which areas there is a larger concentration of accidents. We decided to keep the shape of the original map to make orientation easier for the user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_-gMP64zA18"
      },
      "outputs": [],
      "source": [
        "# df = nyc_map_hex[['h3_polyfill', 'name', 'geometry']]\n",
        "nyc_map_hex = nyc_map.h3.polyfill_resample(8)\n",
        "nyc_map_hex = nyc_map_hex.reset_index()\n",
        "nyc_map_hex = nyc_map_hex[['h3_polyfill', 'name', 'geometry']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIFjNwQ7ozeJ"
      },
      "outputs": [],
      "source": [
        "collisions_geo = gpd.GeoDataFrame(collisions[['COLLISION_ID']],\n",
        "                                  geometry=gpd.points_from_xy(collisions['LONGITUDE'], collisions['LATITUDE']))\n",
        "\n",
        "collisions_geo.crs = nyc_map_hex.crs\n",
        "df = collisions_geo.sjoin(nyc_map_hex, how='right')\n",
        "\n",
        "tmp = df.groupby(['h3_polyfill', 'name']).count().reset_index()\n",
        "tmp = tmp[['h3_polyfill', 'name', 'COLLISION_ID']]\n",
        "tmp.columns = ['h3_polyfill', 'name', 'count']\n",
        "\n",
        "df = df.merge(tmp, on=['h3_polyfill', 'name'], how='left')\n",
        "df = df[['h3_polyfill', 'name', 'geometry', 'count']]\n",
        "df = df.drop_duplicates(subset=['h3_polyfill', 'name'])\n",
        "\n",
        "if not os.path.exists(f'{dir}/new-york-city-boroughs-ny_hex.geojson'):\n",
        "    df.to_file(f'{dir}/new-york-city-boroughs-ny_hex.geojson', driver='GeoJSON')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "BN9dsTDlzA18",
        "outputId": "4a12acf6-98b9-4643-cf67-1c4813177a6e"
      },
      "outputs": [],
      "source": [
        "c1 = alt.Chart(df).mark_geoshape(\n",
        "    stroke='white',\n",
        "    strokeWidth=1,\n",
        "    filled=True\n",
        ").encode(\n",
        "    color=alt.Color('count:Q',\n",
        "                    # scale=alt.Scale(scheme='greys'),\n",
        "                    # scale=alt.Scale(scheme='tealblues'),\n",
        "                    scale=alt.Scale(range=['#B3E9C7', '#5603ad']),\n",
        "                    title='Borough'),\n",
        ").project(\n",
        "    type='identity', reflectY=True\n",
        ").properties(\n",
        "    width=500,\n",
        "    height=500\n",
        ")\n",
        "\n",
        "c2 = alt.Chart(nyc_map).mark_geoshape(\n",
        "    stroke='#1d3557',\n",
        "    strokeWidth=1,\n",
        "    filled=False\n",
        ").project(\n",
        "    type='identity', reflectY=True\n",
        ").properties(\n",
        "    width=500,\n",
        "    height=500\n",
        ")\n",
        "\n",
        "c1 + c2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqUPVBetpHzJ"
      },
      "source": [
        "For the final visualization, the addition of the borough labels was introduced to ease the distinction of boroughs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aougWoStpHe2",
        "outputId": "3ea6ce7f-e78c-42f4-b87a-f98d5264305d"
      },
      "outputs": [],
      "source": [
        "# get centroid of each borough\n",
        "boroughs = nyc_map[['name', 'geometry']]\n",
        "boroughs['centroid'] = boroughs['geometry'].centroid\n",
        "boroughs = boroughs.set_geometry('centroid')\n",
        "boroughs['lat'] = boroughs['centroid'].apply(lambda p: p.y)\n",
        "boroughs['lon'] = boroughs['centroid'].apply(lambda p: p.x)\n",
        "boroughs = boroughs.drop(['centroid', 'geometry'], axis=1)\n",
        "\n",
        "if not os.path.exists(f'{dir}/new-york-city-boroughs-names.csv'):\n",
        "    boroughs.to_csv(f'{dir}/new-york-city-boroughs-names.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JdfeQc9zA18",
        "outputId": "3d11c0b1-d40b-4231-9e77-e54337d9324e"
      },
      "outputs": [],
      "source": [
        "nyc_map_hex.crs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PerB-bxzA18",
        "outputId": "d782d711-b40c-441f-ef36-44d758fbabb5"
      },
      "outputs": [],
      "source": [
        "nyc_map.crs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0GajosUzA18",
        "outputId": "64d347aa-6297-4814-b465-1ac4bcccaebe"
      },
      "outputs": [],
      "source": [
        "# select LATITUDE and LONGITUDE columns and convert them to a GeoDataFrame\n",
        "collisions_geo = gpd.GeoDataFrame(collisions[['LATITUDE', 'LONGITUDE', 'BOROUGH', 'ZIP CODE', 'TOTAL INJURED/KILLED']], geometry=gpd.points_from_xy(collisions.LONGITUDE, collisions.LATITUDE))\n",
        "\n",
        "collisions_geo.crs = \"EPSG:4326\"\n",
        "collisions_geo.crs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TYQ7IfcQzA19",
        "outputId": "f59f0e0a-b5ea-4db3-c9ee-5077b9070eab"
      },
      "outputs": [],
      "source": [
        "population = pd.DataFrame({\n",
        "    'BOROUGH': ['BRONX', 'BROOKLYN', 'MANHATTAN', 'QUEENS', 'STATEN ISLAND'],\n",
        "    'POPULATION_2018': [1438000000, 2601000000, 1632000000, 2299000000, 474101],\n",
        "    'POPULATION_2020': [1427000000, 2577000000, 1629000000, 2271000000, 475596],\n",
        "    'CAR OWNERSHIP': [0.40, 0.44, 0.22, 0.62, 0.83]\n",
        "})\n",
        "\n",
        "population['MEAN POPULATION'] = population[['POPULATION_2018', 'POPULATION_2020']].mean(axis=1)\n",
        "\n",
        "population"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "ANYgNS84zA19",
        "outputId": "57c9e727-626b-45c2-aec1-faf947d87103"
      },
      "outputs": [],
      "source": [
        "total_population = population['MEAN POPULATION'].sum()\n",
        "\n",
        "df = collisions[['BOROUGH', 'CRASH TIME INTERVAL']]\n",
        "df.insert(0, 'COUNT', 1)\n",
        "\n",
        "df = df.groupby(['BOROUGH', 'CRASH TIME INTERVAL']).count().reset_index()\n",
        "df = df.merge(population[['BOROUGH', 'MEAN POPULATION', 'CAR OWNERSHIP']], on='BOROUGH', how='left')\n",
        "\n",
        "df['NORMALIZED COUNT'] = df['COUNT'] * df['CAR OWNERSHIP']\n",
        "\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCUnwuJizA19"
      },
      "source": [
        "Although we consider the map to be a pretty good option, we also thought that a line chart representing the normalized count of accidents along the day hours for each borough could also be a good option to answer the proposed question. We normalized the count of accidents with the information of the follwoing [article](https://edc.nyc/article/new-yorkers-and-their-cars), which specifies the percentage of people in every borough who owns a car. This also helps to give an extra view on the most common hour of the day were accidents occur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "bjXzyGsezA1-",
        "outputId": "6e7be040-098a-4745-ddd0-bef7e1ed1ac3"
      },
      "outputs": [],
      "source": [
        "alt.Chart(df).mark_line(\n",
        "    tooltip=True,\n",
        "    size=2\n",
        ").encode(\n",
        "    x=alt.X('CRASH TIME INTERVAL:N',\n",
        "            title='Crash Time Interval',\n",
        "            axis=alt.Axis(labelAngle=0)),\n",
        "    y=alt.Y('NORMALIZED COUNT:Q',\n",
        "            title='Number of Collisions normalized by Car Ownership Data'),\n",
        "    color=alt.Color('BOROUGH:N',\n",
        "                    scale=alt.Scale(range=['#a3ffd6', '#d69bf5', '#ff8080', '#80ff80', '#80bfff']),\n",
        "                    title='Borough')\n",
        ").properties(\n",
        "    title='Normalized Number of Collisions by Time Interval'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LmrbZtUzA1-"
      },
      "source": [
        "Finally, we have decided to use both visualizations, since by combining them the user can get a detailed view with the map and a general view with the line chart, allowing the user to draw conclusions in a pretty easy way. We consider that the main problem of this choice is that we will be occupying more space than with a single chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3aMYJqBzA1-"
      },
      "source": [
        "### Is there a correlation between weather conditions and accidents?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JWfvocfqzA1-",
        "outputId": "2f6b33a4-7807-4bbe-c0ba-d81174ed3a04"
      },
      "outputs": [],
      "source": [
        "weather_aggregated['DATE'] = pd.to_datetime(weather_aggregated['DATE']).dt.strftime('%Y-%m-%d')\n",
        "weather_aggregated.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vUWxPOmSzA1-",
        "outputId": "0d09faa0-ee41-4267-adb0-1a945b3ca2cd"
      },
      "outputs": [],
      "source": [
        "collisions['CRASH DATE'] = pd.to_datetime(collisions['CRASH DATE']).dt.strftime('%Y-%m-%d')\n",
        "\n",
        "collisions_by_day = collisions[['CRASH DATE', 'COLLISION_ID']].groupby(['CRASH DATE']).count().reset_index()\n",
        "collisions_by_day.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "dzuD-aidzA1-",
        "outputId": "1a9d5beb-d3c9-46a7-a30a-ac535a32ff15"
      },
      "outputs": [],
      "source": [
        "merged_data = pd.merge(weather_aggregated, collisions_by_day, left_on='DATE', right_on='CRASH DATE')\n",
        "merged_data.drop(columns=['CRASH DATE'], inplace=True)\n",
        "merged_data.rename(columns={'COLLISION_ID': 'COLLISION COUNT'}, inplace=True)\n",
        "merged_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbHhyobSzA1-"
      },
      "outputs": [],
      "source": [
        "merged_data['BEAUFORT_SCALE'] = merged_data['BEAUFORT_SCALE'].astype('category')\n",
        "merged_data['PRCP_SCALE'] = merged_data['PRCP_SCALE'].astype('category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVR5W2q-qM5W"
      },
      "outputs": [],
      "source": [
        "# Categorization of TEMPERATURE in bins of 2 Celsius degrees: min temperature is 11, max temperature is 29\n",
        "bin_edges = list(range(10, 30, 2))\n",
        "merged_data['TEMP_SCALE'] = pd.cut(merged_data['MEAN_TEMP'], bins=bin_edges, right=False)\n",
        "merged_data['CASES_COUNT'] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJQdyo-rqq0A"
      },
      "source": [
        "The normalization of the number of collisions by wind scale and temperature scale was done by divinding the total count of accidents by the number of instances of each possible combination of wind-temperature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ID39jHKszA1-",
        "outputId": "3d6f0e0d-6cc7-449c-8594-28cc978959dd"
      },
      "outputs": [],
      "source": [
        "agg_data = merged_data.groupby(['BEAUFORT_SCALE', 'TEMP_SCALE']).agg({'COLLISION COUNT': 'sum', 'CASES_COUNT': 'sum'}).reset_index()\n",
        "\n",
        "agg_data['BEAUFORT_SCALE'] = agg_data['BEAUFORT_SCALE'].astype('category')\n",
        "agg_data['TEMP_SCALE'] = agg_data['TEMP_SCALE'].astype('str')\n",
        "\n",
        "agg_data['NORMALIZED_COLLISION_COUNT'] = agg_data['COLLISION COUNT'] / agg_data['CASES_COUNT']\n",
        "\n",
        "agg_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWi8L3iOzA1_"
      },
      "source": [
        "Given that in summer time there is nearly no rain, we decided for this first visualization to only analyze the data given the categorized average daily speed of wind and the average daily temperature. Since we want to encode two keys; wind and temperature, a value; number of crashes, a heatmap seems to be a good option.\n",
        "\n",
        "To do so we also categorized the temperature taking into account the maximum and minimum temperatures registered. The result is correct and relatively easy to interpret, but at the same time there are values missing for some combinations, which is expectable since the climate does not usually vary much in the same season."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "BH1VHfUSzA1_",
        "outputId": "e9540676-7648-44fa-8954-07e958070756"
      },
      "outputs": [],
      "source": [
        "alt.Chart(agg_data).mark_rect().encode(\n",
        "    x=alt.X('TEMP_SCALE:O',\n",
        "            title='Temperature Scale',\n",
        "            axis=alt.Axis(labelAngle=0)),\n",
        "    y=alt.Y('BEAUFORT_SCALE:N',\n",
        "\n",
        "            title='Beaufort Scale'),\n",
        "    color=alt.Color('NORMALIZED_COLLISION_COUNT:Q',\n",
        "                    scale=alt.Scale(range=['#f0fff1', '#5603ad']),\n",
        "                    title='Collision Count')\n",
        ").properties(\n",
        "    width=500,\n",
        "    height=300,\n",
        "    title='Collision Count by Beaufort Scale and Precipitation Scale'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cHtWGUxzA1_"
      },
      "outputs": [],
      "source": [
        "# save the file if it doesn't exist\n",
        "if not os.path.exists(f'{dir}/merged_data.csv'):\n",
        "    merged_data.to_csv(f'{dir}/merged_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBVtazKZzA1_"
      },
      "source": [
        "The other option we consider to be useful is a small multiples of the scatterplots of collisions versus the three weather variables (precipitation, temperature and wind speed). This visualization is simple and clear to show if there is any correlation between the number of accidents and this meterological factors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "5sWMefgDzA1_",
        "outputId": "457308bd-41e6-41c0-895e-e1053a23c635"
      },
      "outputs": [],
      "source": [
        "t1 = alt.Chart(merged_data).mark_point(\n",
        "    filled=True,\n",
        "    size=100,\n",
        "    opacity=0.5\n",
        ").encode(\n",
        "    x=alt.X('MEAN_TEMP:Q',\n",
        "            title='Mean Temperature',\n",
        "            scale=alt.Scale(domain=[10, 30])),\n",
        "    y=alt.Y('COLLISION COUNT:Q',\n",
        "            title='Number of Collisions'),\n",
        "    color=alt.Color('year(DATE):N',\n",
        "                    title='Year')\n",
        ").properties(\n",
        "    title='Number of Collisions by Mean Temperature'\n",
        ")\n",
        "\n",
        "t2 = alt.Chart(merged_data).mark_point(\n",
        "    filled=True,\n",
        "    size=100,\n",
        "    opacity=0.5\n",
        ").encode(\n",
        "    x=alt.X('PRCP:Q',\n",
        "            title='Mean Precipitation'),\n",
        "    y=alt.Y('COLLISION COUNT:Q',\n",
        "            title='Number of Collisions'),\n",
        "    color=alt.Color('year(DATE):N',\n",
        "                    title='Year'),\n",
        ").properties(\n",
        "    title='Number of Collisions by Precipitation'\n",
        ")\n",
        "\n",
        "t3 = alt.Chart(merged_data).mark_point(\n",
        "    filled=True,\n",
        "    size=100,\n",
        "    opacity=0.5\n",
        ").encode(\n",
        "    x=alt.X('AWND:Q',\n",
        "            scale=alt.Scale(domain=[1, 6.5]),\n",
        "            title='Mean Wind Speed'),\n",
        "    y=alt.Y('COLLISION COUNT:Q',\n",
        "            title='Number of Collisions'),\n",
        "    color=alt.Color('year(DATE):N',\n",
        "                    scale=alt.Scale(range=['#A7C9C7', '#8367C7']),\n",
        "                    title='Year'),\n",
        ").properties(\n",
        "    title='Number of Collisions by Wind Speed'\n",
        ")\n",
        "\n",
        "t1 | t2 | t3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAmUAYjezA1_"
      },
      "source": [
        "Since we are already using a heatmap for another question, we decided to use the small multiples for the scatterplots. As mentioned, this option is effective and really allows the user to see if there is any clear correlation. The main disadvantage of this plot is that it may occupy more space than other options."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oaupkMJdKfs"
      },
      "source": [
        "### Extra Visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn1aKGwAYH0i"
      },
      "source": [
        "The first extra visualization we have chosen to create is a isotype plot, showing the proportion of injured people in 2018 and 2020 with car shapes representing this information. We also calculate some KPI's we thought interesting to show in the final visualization, like the number of deaths in each year, the total amount of collisions each year, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "kvJg4fbzeh_z",
        "outputId": "0f9e3dad-6311-4c0c-bcdf-d40ff7d467fd"
      },
      "outputs": [],
      "source": [
        "df = collisions.groupby('YEAR')[['NUMBER OF INJURED', 'NUMBER OF KILLED']].sum().reset_index()\n",
        "\n",
        "df2 = collisions.groupby('YEAR')[['COLLISION_ID']].count()\n",
        "df = df.merge(df2, on='YEAR')\n",
        "\n",
        "df['TOTAL PER 10'] = 10 * df['NUMBER OF INJURED'] / df['COLLISION_ID']\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "id": "eahaeJ9kep5C",
        "outputId": "d469008d-82b5-48e4-ca6a-c43414d226a0"
      },
      "outputs": [],
      "source": [
        "car = (\"M640 320V368C640 385.7 625.7 400 608 400H574.7C567.1 445.4 527.6 480 480 480C432.4 480 392.9 445.4 385.3 400H254.7C247.1 445.4 207.6 480 160 480C112.4 480 72.94 445.4 65.33 400H32C14.33 400 0 385.7 0 368V256C0 228.9 16.81 205.8 40.56 196.4L82.2 92.35C96.78 55.9 132.1 32 171.3 32H353.2C382.4 32 409.1 45.26 428.2 68.03L528.2 193C591.2 200.1 640 254.8 640 319.1V320zM171.3 96C158.2 96 146.5 103.1 141.6 116.1L111.3 192H224V96H171.3zM272 192H445.4L378.2 108C372.2 100.4 362.1 96 353.2 96H272V192zM525.3 400C527 394.1 528 389.6 528 384C528 357.5 506.5 336 480 336C453.5 336 432 357.5 432 384C432 389.6 432.1 394.1 434.7 400C441.3 418.6 459.1 432 480 432C500.9 432 518.7 418.6 525.3 400zM205.3 400C207 394.1 208 389.6 208 384C208 357.5 186.5 336 160 336C133.5 336 112 357.5 112 384C112 389.6 112.1 394.1 114.7 400C121.3 418.6 139.1 432 160 432C180.9 432 198.7 418.6 205.3 400z\"\n",
        ")\n",
        "\n",
        "idx = 6\n",
        "# idx = 10\n",
        "\n",
        "data = pd.DataFrame([dict(id=i) for i in range(1, 11)])\n",
        "data['color'] = ['kill/injured' if i <= idx else 'non' for i in range(1, 11)]\n",
        "data['year'] = ['2018'] * 10\n",
        "\n",
        "alt.Chart(data).transform_calculate(\n",
        "    row=\"ceil(datum.id/10)\"\n",
        ").transform_calculate(\n",
        "    col=\"datum.id - datum.row*10\"\n",
        ").mark_point(\n",
        "    filled=True,\n",
        "    size=0.03,\n",
        "    tooltip=False\n",
        ").encode(\n",
        "    alt.X(\"col:O\", axis=None),\n",
        "    alt.Y(\"row:O\", axis=None),\n",
        "    alt.ShapeValue(car),\n",
        "    color=alt.Color('color:N',\n",
        "                    scale=alt.Scale(domain=['kill/injured', 'non'],range=['#5603ad', '#9BA8C7']),\n",
        "                    legend=None)\n",
        ").properties(\n",
        "    width=800,\n",
        "    title=f'In \"year\", in average, around {idx} out of 10 Collisions involve injured'\n",
        ").configure_axis(\n",
        "    grid=False,\n",
        "    domain=False,\n",
        "    ticks=False\n",
        ").configure_view(\n",
        "    strokeWidth=0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM8FV84LajQa"
      },
      "source": [
        "The second extra visualization consists of a bar plot with the top 5 factors that contributed to accidents, with the number of accidents caused by every factor. Since a lot of instances were undefined in this attribute, we removed the factor 'Undefined' that doesn't apport any information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "mD7Ekm3mdOcK",
        "outputId": "fd4825a0-b2fe-4c0a-9ef0-94fd988e70c8"
      },
      "outputs": [],
      "source": [
        "df = collisions[['CONTRIBUTING FACTOR VEHICLE 1', 'COLLISION_ID']]\n",
        "\n",
        "df = df.groupby('CONTRIBUTING FACTOR VEHICLE 1').count().reset_index()\n",
        "\n",
        "df = df.sort_values(by='COLLISION_ID', ascending=False)\n",
        "\n",
        "df = df[df['CONTRIBUTING FACTOR VEHICLE 1'] != 'Unspecified']\n",
        "\n",
        "df.columns = ['CONTRIBUTING FACTOR VEHICLE 1', 'COUNT']\n",
        "df = df.head(5)\n",
        "\n",
        "alt.Chart(df).mark_bar(\n",
        "    tooltip=True\n",
        ").encode(\n",
        "    x=alt.X('CONTRIBUTING FACTOR VEHICLE 1:N',\n",
        "            title='Contributing Factor',\n",
        "            sort=alt.EncodingSortField(field=\"COUNT\", order=\"descending\"),\n",
        "            axis=alt.Axis(labelAngle=-45)),\n",
        "    y=alt.Y('COUNT:Q',\n",
        "            title='Number of Collisions'),\n",
        "    tooltip=['CONTRIBUTING FACTOR VEHICLE 1:N', 'COUNT:Q']\n",
        ").properties(\n",
        "    title='Number of Collisions by Contributing Factor'\n",
        ").configure_mark(\n",
        "    color='#ff8080'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "54jSfogHVtNb",
        "outputId": "a10789e8-752f-4864-f8ae-257f2ed6876b"
      },
      "outputs": [],
      "source": [
        "df = collisions.groupby('YEAR')[['NUMBER OF INJURED', 'NUMBER OF KILLED']].sum().reset_index()\n",
        "\n",
        "df2 = collisions.groupby('YEAR')[['COLLISION_ID']].count()\n",
        "df = df.merge(df2, on='YEAR')\n",
        "\n",
        "df['TOTAL PER 10'] = 10 * df['NUMBER OF INJURED'] / df['COLLISION_ID']\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vh_Va7-GfTt"
      },
      "source": [
        "## Answers to the Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym-A9yZ9cvFF"
      },
      "source": [
        "### Question 1: Are accidents more frequent during weekdays or weekends? Is there any difference between before COVID-19 and after?\n",
        "\n",
        "As we can see in the third row of plots, the slope chart shows that in both years accidents were more common during weekdays than during weekends. This is can also be seen in detail in the adjacent heatmap, where, in average, there were more crashes during weekdays than during weekends. However, the slope chart also shows that in 2020 the difference is reduced considerably, porbably due to the massive adoption of teleworking after COVID-19."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJEZzes0cx8M"
      },
      "source": [
        "### Question 2: Is there any type of vehicle more prone to participate in accidents?\n",
        "\n",
        "As explained in the generation of the plots, this can't really be answered with the data given. Nevertheless, the polar area chart in the top left corner, just under the title, clearly shows that the vehicles with a higher amount of accidents are cars and vans, considering them as very general categories. With a massive difference, they are followed by trucks and taxis (a very common vehicle in NYC)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8gE7hSAc0GZ"
      },
      "source": [
        "### Question 3: At what time of the day are accidents more common?\n",
        "\n",
        "In the third row, looking again at the previously mentioned heatmap, we observe that the highest number of crashes occur during the most common work schedules: between 8 AM and 6 PM. The peak of crashes takes place at 4 PM. It is interesting to see than in weekends, although the previous analysis sort of maintains, the number of crashes in the early past midnight hours is higher than in weekdays, probably because during weekends people tend to hang out until late hours of the night."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJnay_Azc2VB"
      },
      "source": [
        "### Question 4: Are there any areas with a larger number of accidents?\n",
        "\n",
        "Looking at the line chart next to the polar area chart, we observe that for any time of the day, there are much more accidents in Queens, followed pretty closely by Brooklyn. However, if we look to small zones with a major concentration of accidents in the map under the previous plot, we see that Manhattan has a larger concentration of accidents in a smaller area."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYd6sn2KGeCS"
      },
      "source": [
        "### Question 5: Is there a correlation between weather conditions and accidents?\n",
        "\n",
        "The three scatterplots under the heatmap show that there is not any type of correlation between the meteorological conditions considered and the number of crashes. Neither temperature, nor precipitation, nor wind speed seem to show any type of trend with the amount of crashes. It is also true, that since we are only treating data from summer time, this analysis can't be done as well as it should, since meterorological conditions tend to vary very slightly during a season. This remains the same for both 2018 and 2020."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6CFdvEic4ba"
      },
      "source": [
        "\n",
        "### Extra Visualization 1\n",
        "\n",
        "The visualization under the just analyzed scatterplots shows the proportion of injured people of the total number of crashes for both years, also showing the deaths and the total crashes. It clearly shows that although the number of crashes reduced considerably after COVID-19, the dangerousness of them increased considerably, since the proportion of injured people is much bigger, and the number of deaths increased a lot proportionally."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqNBEjCuc9Ki"
      },
      "source": [
        "\n",
        "### Extra Visualization 2\n",
        "\n",
        "Next to the map, we can observe a barplot showcasing the top 5 causes for accidents in the summer months of 2018 and 2020 from the registered data.\n",
        "The main factor with a big difference is \"Driver Inattention/Distraction\", follwed then by \"Following Too Closely\", making these two the main reasons of accidents in NYC during the summers of 2018 and 2020."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
