{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Authors**:\n",
    "-  *Juan P. Zaldivar E.*\n",
    "-  *Enrique Mill√°n X.*\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the preprocessing required for the datasets. The datasets are:\n",
    "- Colissions dataset.\n",
    "- Weather dataset.\n",
    "- New York Map.\n",
    "\n",
    "\n",
    "<!-- explicar que primer se hace una exploracion visual y luego el preprocesing? -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset obtention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [*collision*](https://data.cityofnewyork.us/Public-Safety/Motor-Vehicle-Collisions-Crashes/h9gi-nx95) dataset was already given by the instructors of the project.\n",
    "\n",
    "The *weather* dataset was obtained following the next steps:\n",
    "\n",
    "- Visit the [NOAA Climate Data Online Search](https://www.ncdc.noaa.gov/cdo-web/search) web page.\n",
    "\n",
    "- Select the following options:\n",
    "  - `Weather Observation Type/Dataset -> Daily Summaries, Date Range -> 2018-01-01 to 2020-12-31, Search For -> Cities, Search Term -> New York City.`\n",
    "\n",
    "- Look for \"*New York, NY US*\" and click in ADD TO CART. Now, click the cart in the top right corner.\n",
    "\n",
    "- Select \"*Custom GHCN-Daily CSV*\", and the date previously selected (2018-01-01 to 2020-12-31). We are selecting more information than needed (to avoid disjoint downloads), but we will later filter it with ``Pandas`` and ``Open Refine``. Click continue.\n",
    "\n",
    "- Fill the three options, and select \"*metric units*\".\n",
    "\n",
    "- Fill all the options remaining and click continue. There are some options that will be probably not needed, but we will further analyze this when cleaning the datasets.\n",
    "\n",
    "- Type the email where you want to receive the data so the order can start.\n",
    "\n",
    "The *map* dataset was obtained following the next steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets are located in the folder `Data/` and the results are saved in the folder `Data/Preprocessed/`. Following are the loading of each dataset and the import of the required libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from Modules import collision_preprocessing as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# comentar las versiones de los paquetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessing of the files was done conjuntly with OpenRefine and the python libraries in order to be able to take advantages of both tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dir = './Data'\n",
    "colission_exists = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collision dataset preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original dataset was first loaded into a ``Pandas`` dataframe in order to filter the desired range of dates. The reason lays in a more efficient way to filter the data, taking the size of the original dataset into account. This volumn of data made the computational process in OpenRefine very slow and ineffcient. After this initial filtering, the dataset was exported to a ``.csv`` file and loaded into OpenRefine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115740, 29)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.exists(f'{dir}/collisions_2018-2020.csv'):\n",
    "    collision = pd.read_csv(f'{dir}/collisions_2018-2020.csv')\n",
    "    colission_exists = True\n",
    "else:\n",
    "    collision = pd.read_csv(f'{dir}/collisions.csv')\n",
    "\n",
    "collision.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRASH DATE</th>\n",
       "      <th>CRASH TIME</th>\n",
       "      <th>BOROUGH</th>\n",
       "      <th>ZIP CODE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>ON STREET NAME</th>\n",
       "      <th>CROSS STREET NAME</th>\n",
       "      <th>OFF STREET NAME</th>\n",
       "      <th>...</th>\n",
       "      <th>CONTRIBUTING FACTOR VEHICLE 2</th>\n",
       "      <th>CONTRIBUTING FACTOR VEHICLE 3</th>\n",
       "      <th>CONTRIBUTING FACTOR VEHICLE 4</th>\n",
       "      <th>CONTRIBUTING FACTOR VEHICLE 5</th>\n",
       "      <th>COLLISION_ID</th>\n",
       "      <th>VEHICLE TYPE CODE 1</th>\n",
       "      <th>VEHICLE TYPE CODE 2</th>\n",
       "      <th>VEHICLE TYPE CODE 3</th>\n",
       "      <th>VEHICLE TYPE CODE 4</th>\n",
       "      <th>VEHICLE TYPE CODE 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-06</td>\n",
       "      <td>18:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.771038</td>\n",
       "      <td>-73.83413</td>\n",
       "      <td>(40.771038, -73.83413)</td>\n",
       "      <td>WHITESTONE EXPRESSWAY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Following Too Closely</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4345591</td>\n",
       "      <td>Station Wagon/Sport Utility Vehicle</td>\n",
       "      <td>Motorcycle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-09-20</td>\n",
       "      <td>9:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.722095</td>\n",
       "      <td>-73.77772</td>\n",
       "      <td>(40.722095, -73.77772)</td>\n",
       "      <td>GRAND CENTRAL PKWY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4459141</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Pick-up Truck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-09-24</td>\n",
       "      <td>22:00</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10039.0</td>\n",
       "      <td>40.824757</td>\n",
       "      <td>-73.94052</td>\n",
       "      <td>(40.824757, -73.94052)</td>\n",
       "      <td>8 AVENUE</td>\n",
       "      <td>WEST 148 STREET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Driver Inattention/Distraction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4461437</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Motorscooter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>5:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120       Huge Grant Circle</td>\n",
       "      <td>...</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4336560</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Station Wagon/Sport Utility Vehicle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>17:16</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10462.0</td>\n",
       "      <td>40.840508</td>\n",
       "      <td>-73.85515</td>\n",
       "      <td>(40.840508, -73.85515)</td>\n",
       "      <td>METROPOLITAN AVENUE</td>\n",
       "      <td>LINDEN DRIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4334713</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>E-Bike</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRASH DATE CRASH TIME    BOROUGH  ZIP CODE   LATITUDE  LONGITUDE  \\\n",
       "0  2020-09-06      18:05        NaN       NaN  40.771038  -73.83413   \n",
       "1  2020-09-20       9:14        NaN       NaN  40.722095  -73.77772   \n",
       "2  2020-09-24      22:00  MANHATTAN   10039.0  40.824757  -73.94052   \n",
       "3  2020-08-06       5:30        NaN       NaN        NaN        NaN   \n",
       "4  2020-08-01      17:16      BRONX   10462.0  40.840508  -73.85515   \n",
       "\n",
       "                 LOCATION         ON STREET NAME CROSS STREET NAME  \\\n",
       "0  (40.771038, -73.83413)  WHITESTONE EXPRESSWAY               NaN   \n",
       "1  (40.722095, -73.77772)     GRAND CENTRAL PKWY               NaN   \n",
       "2  (40.824757, -73.94052)               8 AVENUE   WEST 148 STREET   \n",
       "3                     NaN                    NaN               NaN   \n",
       "4  (40.840508, -73.85515)    METROPOLITAN AVENUE      LINDEN DRIVE   \n",
       "\n",
       "               OFF STREET NAME  ...   CONTRIBUTING FACTOR VEHICLE 2  \\\n",
       "0                          NaN  ...           Following Too Closely   \n",
       "1                          NaN  ...                     Unspecified   \n",
       "2                          NaN  ...  Driver Inattention/Distraction   \n",
       "3  120       Huge Grant Circle  ...                     Unspecified   \n",
       "4                          NaN  ...                     Unspecified   \n",
       "\n",
       "   CONTRIBUTING FACTOR VEHICLE 3  CONTRIBUTING FACTOR VEHICLE 4  \\\n",
       "0                            NaN                            NaN   \n",
       "1                            NaN                            NaN   \n",
       "2                            NaN                            NaN   \n",
       "3                            NaN                            NaN   \n",
       "4                            NaN                            NaN   \n",
       "\n",
       "   CONTRIBUTING FACTOR VEHICLE 5  COLLISION_ID  \\\n",
       "0                            NaN       4345591   \n",
       "1                            NaN       4459141   \n",
       "2                            NaN       4461437   \n",
       "3                            NaN       4336560   \n",
       "4                            NaN       4334713   \n",
       "\n",
       "                   VEHICLE TYPE CODE 1                  VEHICLE TYPE CODE 2  \\\n",
       "0  Station Wagon/Sport Utility Vehicle                           Motorcycle   \n",
       "1                                Sedan                        Pick-up Truck   \n",
       "2                                Sedan                         Motorscooter   \n",
       "3                                Sedan  Station Wagon/Sport Utility Vehicle   \n",
       "4                                Sedan                               E-Bike   \n",
       "\n",
       "   VEHICLE TYPE CODE 3 VEHICLE TYPE CODE 4 VEHICLE TYPE CODE 5  \n",
       "0                  NaN                 NaN                 NaN  \n",
       "1                  NaN                 NaN                 NaN  \n",
       "2                  NaN                 NaN                 NaN  \n",
       "3                  NaN                 NaN                 NaN  \n",
       "4                  NaN                 NaN                 NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collision.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the filtered version does not exist, we proceed with the filtering. To filter the data to the summer of 2018 and 2020, the first step is to change the data type of the **CRASH DATE** attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115740, 29)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not colission_exists:\n",
    "    collision['CRASH DATE'] = pd.to_datetime(collision['CRASH DATE'])\n",
    "\n",
    "    collision = collision[((collision['CRASH DATE'] >= '2018-06-01') & (collision['CRASH DATE'] <= '2018-09-30')) | ((collision['CRASH DATE'] >= '2020-06-01') & (collision['CRASH DATE'] <= '2020-09-30'))]\n",
    "    collision.to_csv(f'{dir}/collisions_2018-2020.csv', index=False)\n",
    "\n",
    "collision.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration?\n",
    "\n",
    "The collision table incorporates information pertaining to individual crash events, with each row representing a distinct collision incident. The dataframe compile details from all police reported motor vehicle collisions in NYC. \n",
    "\n",
    "<!-- ...se hace una breve descripcion de la exploracion? -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the filtering, the dataset was exported to a ``.csv`` file and loaded into OpenRefine. The procedure and reasoning taken in OpenRefine will be explained and justified in the present section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, **ON STREET NAME** and **OFF STREET NAME** seem to be the same attribute, but with different names. After looking at the description of the attributes in the web site of the dataset, the following descriptions:\n",
    "\n",
    "- **ON STREET NAME**: *Street on which the collision occurred*.\n",
    "- **OFF STREET NAME**: *Street address if known*.\n",
    "\n",
    "Which gives the idea that both attributes contain approximatelly the same information. Furthermore, there are no rows with both attributes filled, which makes the idea of merging both attributes plausible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 29)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collision[(collision['ON STREET NAME'].notnull()) & (collision['OFF STREET NAME'].notnull())].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115514, 29)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collision[(collision['ON STREET NAME'].notnull()) | (collision['OFF STREET NAME'].notnull())].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting attribute after merging both columns is called **STREET NAME** and contains the street name/address where the collision occurred, with no missing values. Some rows will have a more detail description of the street, while others will only have the name of the street. \n",
    "\n",
    "<!-- This is not a problem, since the attribute will be used to join the dataset with the weather dataset, and the weather dataset only contains the name of the street. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CROSS STREET**, which was the third attribute related to the street enviroment could be dropped since at first glance does not seem to be useful for the analysis. However, we have decided to keep the attribute for teh time being since it could can contribute some extra information to the final visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, **LOCATION** seems to contain the tuple (**LATITUDE**, **LONGITUDE**), so we could, a priori, remove the two extra attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108073, 29)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collision[(collision['LOCATION'].notnull()) & (collision['LATITUDE'].notnull()) & (collision['LONGITUDE'].notnull())].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of rows where the three attributes are not missing does not cover the total number of rows, but there are no rows where the **LOCATION** attribute is missing and at least one of the other two attributes is not missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 29)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collision[(collision['LOCATION'].isnull()) & (collision['LATITUDE'].isnull()) & (collision['LONGITUDE'].notnull()) | (collision['LATITUDE'].notnull()) & (collision['LONGITUDE'].isnull())].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7667, 29)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collision[(collision['LOCATION'].isnull())].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which makes the rest of the rows (7667) with missing values in the three attributes. This means that the **LATITUDE** and **LONGITUDE** attributes can be removed, since the **LOCATION** attribute contains the same information. By this the number of attributes is reduced by two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data type conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se ha realizado un cluster (con el metodo *key collision* y funcion de keying *fingerprint*) de STREET NAME y se han unido las celdas con nombres semejantes.\n",
    "\n",
    "Luego se han eliminado los espacios sobrantes de la columna STREET NAME."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COLLISION_ID</th>\n",
       "      <th>CRASH DATE</th>\n",
       "      <th>CRASH TIME</th>\n",
       "      <th>BOROUGH</th>\n",
       "      <th>ZIP CODE</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>STREET NAME</th>\n",
       "      <th>CROSS STREET NAME</th>\n",
       "      <th>NUMBER OF PERSONS INJURED</th>\n",
       "      <th>NUMBER OF PERSONS KILLED</th>\n",
       "      <th>...</th>\n",
       "      <th>CONTRIBUTING FACTOR VEHICLE 1</th>\n",
       "      <th>CONTRIBUTING FACTOR VEHICLE 2</th>\n",
       "      <th>CONTRIBUTING FACTOR VEHICLE 3</th>\n",
       "      <th>CONTRIBUTING FACTOR VEHICLE 4</th>\n",
       "      <th>CONTRIBUTING FACTOR VEHICLE 5</th>\n",
       "      <th>VEHICLE TYPE CODE 1</th>\n",
       "      <th>VEHICLE TYPE CODE 2</th>\n",
       "      <th>VEHICLE TYPE CODE 3</th>\n",
       "      <th>VEHICLE TYPE CODE 4</th>\n",
       "      <th>VEHICLE TYPE CODE 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4345591</td>\n",
       "      <td>2020-09-06T00:00:00Z</td>\n",
       "      <td>18:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(40.771038, -73.83413)</td>\n",
       "      <td>WHITESTONE EXPRESSWAY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Unsafe Lane Changing</td>\n",
       "      <td>Following Too Closely</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STATION WAGON/SPORT UTILITY VEHICLE</td>\n",
       "      <td>MOTORCYCLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4459141</td>\n",
       "      <td>2020-09-20T00:00:00Z</td>\n",
       "      <td>9:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(40.722095, -73.77772)</td>\n",
       "      <td>GRAND CENTRAL PKWY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Driver Inattention/Distraction</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEDAN</td>\n",
       "      <td>PICK-UP TRUCK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4461437</td>\n",
       "      <td>2020-09-24T00:00:00Z</td>\n",
       "      <td>22:00</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10039.0</td>\n",
       "      <td>(40.824757, -73.94052)</td>\n",
       "      <td>8 AVENUE</td>\n",
       "      <td>WEST 148 STREET</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Pedestrian/Bicyclist/Other Pedestrian Error/Co...</td>\n",
       "      <td>Driver Inattention/Distraction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEDAN</td>\n",
       "      <td>MOTORSCOOTER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4336560</td>\n",
       "      <td>2020-08-06T00:00:00Z</td>\n",
       "      <td>5:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120 HUGE GRANT CIRCLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEDAN</td>\n",
       "      <td>STATION WAGON/SPORT UTILITY VEHICLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4334713</td>\n",
       "      <td>2020-08-01T00:00:00Z</td>\n",
       "      <td>17:16</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10462.0</td>\n",
       "      <td>(40.840508, -73.85515)</td>\n",
       "      <td>METROPOLITAN AVENUE</td>\n",
       "      <td>LINDEN DRIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Failure to Yield Right-of-Way</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEDAN</td>\n",
       "      <td>E-BIKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   COLLISION_ID            CRASH DATE CRASH TIME    BOROUGH  ZIP CODE  \\\n",
       "0       4345591  2020-09-06T00:00:00Z      18:05        NaN       NaN   \n",
       "1       4459141  2020-09-20T00:00:00Z       9:14        NaN       NaN   \n",
       "2       4461437  2020-09-24T00:00:00Z      22:00  MANHATTAN   10039.0   \n",
       "3       4336560  2020-08-06T00:00:00Z       5:30        NaN       NaN   \n",
       "4       4334713  2020-08-01T00:00:00Z      17:16      BRONX   10462.0   \n",
       "\n",
       "                 LOCATION            STREET NAME CROSS STREET NAME  \\\n",
       "0  (40.771038, -73.83413)  WHITESTONE EXPRESSWAY               NaN   \n",
       "1  (40.722095, -73.77772)     GRAND CENTRAL PKWY               NaN   \n",
       "2  (40.824757, -73.94052)               8 AVENUE   WEST 148 STREET   \n",
       "3                     NaN  120 HUGE GRANT CIRCLE               NaN   \n",
       "4  (40.840508, -73.85515)    METROPOLITAN AVENUE      LINDEN DRIVE   \n",
       "\n",
       "   NUMBER OF PERSONS INJURED  NUMBER OF PERSONS KILLED  ...  \\\n",
       "0                        0.0                       1.0  ...   \n",
       "1                        0.0                       0.0  ...   \n",
       "2                        0.0                       0.0  ...   \n",
       "3                        1.0                       0.0  ...   \n",
       "4                        0.0                       1.0  ...   \n",
       "\n",
       "                       CONTRIBUTING FACTOR VEHICLE 1  \\\n",
       "0                               Unsafe Lane Changing   \n",
       "1                     Driver Inattention/Distraction   \n",
       "2  Pedestrian/Bicyclist/Other Pedestrian Error/Co...   \n",
       "3                                        Unspecified   \n",
       "4                      Failure to Yield Right-of-Way   \n",
       "\n",
       "    CONTRIBUTING FACTOR VEHICLE 2  CONTRIBUTING FACTOR VEHICLE 3  \\\n",
       "0           Following Too Closely                            NaN   \n",
       "1                     Unspecified                            NaN   \n",
       "2  Driver Inattention/Distraction                            NaN   \n",
       "3                     Unspecified                            NaN   \n",
       "4                     Unspecified                            NaN   \n",
       "\n",
       "   CONTRIBUTING FACTOR VEHICLE 4  CONTRIBUTING FACTOR VEHICLE 5  \\\n",
       "0                            NaN                            NaN   \n",
       "1                            NaN                            NaN   \n",
       "2                            NaN                            NaN   \n",
       "3                            NaN                            NaN   \n",
       "4                            NaN                            NaN   \n",
       "\n",
       "                   VEHICLE TYPE CODE 1                  VEHICLE TYPE CODE 2  \\\n",
       "0  STATION WAGON/SPORT UTILITY VEHICLE                           MOTORCYCLE   \n",
       "1                                SEDAN                        PICK-UP TRUCK   \n",
       "2                                SEDAN                         MOTORSCOOTER   \n",
       "3                                SEDAN  STATION WAGON/SPORT UTILITY VEHICLE   \n",
       "4                                SEDAN                               E-BIKE   \n",
       "\n",
       "  VEHICLE TYPE CODE 3 VEHICLE TYPE CODE 4 VEHICLE TYPE CODE 5  \n",
       "0                 NaN                 NaN                 NaN  \n",
       "1                 NaN                 NaN                 NaN  \n",
       "2                 NaN                 NaN                 NaN  \n",
       "3                 NaN                 NaN                 NaN  \n",
       "4                 NaN                 NaN                 NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precollision = pd.read_csv(f'{dir}/collisions_2018-2020_prepro_v1.csv')\n",
    "precollision.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has already been mentioned the existence of some missing values. In the previous section, the verification of missing values was done with the ``.isnull()`` method of ``Pandas``. However, this method does not take into account the ``NaN`` values. In order to check the existence of ``NaN`` values, the ``.isna()`` method was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\USUARIOS\\Enric-UPC\\Documents\\GitHub\\VI\\preprocessing.ipynb Cell 44\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/USUARIOS/Enric-UPC/Documents/GitHub/VI/preprocessing.ipynb#X61sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m comp \u001b[39m=\u001b[39m (precollision\u001b[39m.\u001b[39;49misnull()\u001b[39m.\u001b[39msum() \u001b[39m==\u001b[39m precollision\u001b[39m.\u001b[39misna()\u001b[39m.\u001b[39msum())\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/USUARIOS/Enric-UPC/Documents/GitHub/VI/preprocessing.ipynb#X61sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m comp[comp \u001b[39m==\u001b[39m \u001b[39mFalse\u001b[39;00m]\n",
      "File \u001b[1;32md:\\USUARIOS\\Enric-UPC\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6235\u001b[0m, in \u001b[0;36mDataFrame.isnull\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   6230\u001b[0m \u001b[39m@doc\u001b[39m(NDFrame\u001b[39m.\u001b[39misna, klass\u001b[39m=\u001b[39m_shared_doc_kwargs[\u001b[39m\"\u001b[39m\u001b[39mklass\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   6231\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39misnull\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m   6232\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   6233\u001b[0m \u001b[39m    DataFrame.isnull is an alias for DataFrame.isna.\u001b[39;00m\n\u001b[0;32m   6234\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 6235\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49misna()\n",
      "File \u001b[1;32md:\\USUARIOS\\Enric-UPC\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6227\u001b[0m, in \u001b[0;36mDataFrame.isna\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   6225\u001b[0m \u001b[39m@doc\u001b[39m(NDFrame\u001b[39m.\u001b[39misna, klass\u001b[39m=\u001b[39m_shared_doc_kwargs[\u001b[39m\"\u001b[39m\u001b[39mklass\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   6226\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39misna\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m-> 6227\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49misna(func\u001b[39m=\u001b[39;49misna))\n\u001b[0;32m   6228\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39misna\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\USUARIOS\\Enric-UPC\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\base.py:142\u001b[0m, in \u001b[0;36mDataManager.isna\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39misna\u001b[39m(\u001b[39mself\u001b[39m: T, func) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\u001b[39m\"\u001b[39;49m\u001b[39mapply\u001b[39;49m\u001b[39m\"\u001b[39;49m, func\u001b[39m=\u001b[39;49mfunc)\n",
      "File \u001b[1;32md:\\USUARIOS\\Enric-UPC\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(b, f)(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     result_blocks \u001b[39m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    355\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mfrom_blocks(result_blocks, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n",
      "File \u001b[1;32md:\\USUARIOS\\Enric-UPC\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:329\u001b[0m, in \u001b[0;36mBlock.apply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m    324\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mself\u001b[39m, func, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[Block]:\n\u001b[0;32m    325\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[39m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[39m    one\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    331\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[1;32md:\\USUARIOS\\Enric-UPC\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\missing.py:183\u001b[0m, in \u001b[0;36misna\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39misna\u001b[39m(obj: \u001b[39mobject\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m \u001b[39m|\u001b[39m npt\u001b[39m.\u001b[39mNDArray[np\u001b[39m.\u001b[39mbool_] \u001b[39m|\u001b[39m NDFrame:\n\u001b[0;32m    107\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[39m    Detect missing values for an array-like object.\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[39m    Name: 1, dtype: bool\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 183\u001b[0m     \u001b[39mreturn\u001b[39;00m _isna(obj)\n",
      "File \u001b[1;32md:\\USUARIOS\\Enric-UPC\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\missing.py:212\u001b[0m, in \u001b[0;36m_isna\u001b[1;34m(obj, inf_as_na)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, (np\u001b[39m.\u001b[39mndarray, ABCExtensionArray)):\n\u001b[1;32m--> 212\u001b[0m     \u001b[39mreturn\u001b[39;00m _isna_array(obj, inf_as_na\u001b[39m=\u001b[39;49minf_as_na)\n\u001b[0;32m    213\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, ABCIndex):\n\u001b[0;32m    214\u001b[0m     \u001b[39m# Try to use cached isna, which also short-circuits for integer dtypes\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m#  and avoids materializing RangeIndex._values\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m obj\u001b[39m.\u001b[39m_can_hold_na:\n",
      "File \u001b[1;32md:\\USUARIOS\\Enric-UPC\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\missing.py:294\u001b[0m, in \u001b[0;36m_isna_array\u001b[1;34m(values, inf_as_na)\u001b[0m\n\u001b[0;32m    292\u001b[0m         result \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39misna()  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[39melif\u001b[39;00m is_string_or_object_np_dtype(values\u001b[39m.\u001b[39mdtype):\n\u001b[1;32m--> 294\u001b[0m     result \u001b[39m=\u001b[39m _isna_string_dtype(values, inf_as_na\u001b[39m=\u001b[39;49minf_as_na)\n\u001b[0;32m    295\u001b[0m \u001b[39melif\u001b[39;00m needs_i8_conversion(dtype):\n\u001b[0;32m    296\u001b[0m     \u001b[39m# this is the NaT pattern\u001b[39;00m\n\u001b[0;32m    297\u001b[0m     result \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mview(\u001b[39m\"\u001b[39m\u001b[39mi8\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m==\u001b[39m iNaT\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "comp = (precollision.isnull().sum() == precollision.isna().sum())\n",
    "comp[comp == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COLLISION_ID                          0\n",
       "CRASH DATE                            0\n",
       "CRASH TIME                            0\n",
       "BOROUGH                           40671\n",
       "ZIP CODE                          40686\n",
       "LOCATION                           7667\n",
       "STREET NAME                         226\n",
       "CROSS STREET NAME                 60179\n",
       "NUMBER OF PERSONS INJURED             2\n",
       "NUMBER OF PERSONS KILLED              4\n",
       "NUMBER OF PEDESTRIANS INJURED         0\n",
       "NUMBER OF PEDESTRIANS KILLED          0\n",
       "NUMBER OF CYCLIST INJURED             0\n",
       "NUMBER OF CYCLIST KILLED              0\n",
       "NUMBER OF MOTORIST INJURED            0\n",
       "NUMBER OF MOTORIST KILLED             0\n",
       "CONTRIBUTING FACTOR VEHICLE 1       351\n",
       "CONTRIBUTING FACTOR VEHICLE 2     19593\n",
       "CONTRIBUTING FACTOR VEHICLE 3    106611\n",
       "CONTRIBUTING FACTOR VEHICLE 4    113552\n",
       "CONTRIBUTING FACTOR VEHICLE 5    115126\n",
       "VEHICLE TYPE CODE 1                 730\n",
       "VEHICLE TYPE CODE 2               27447\n",
       "VEHICLE TYPE CODE 3              107096\n",
       "VEHICLE TYPE CODE 4              113658\n",
       "VEHICLE TYPE CODE 5              115154\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precollision.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derivation of geographic attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derivation of vehicle attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poner unespecified en factor $i$ si el vehiculo $i$ es null y factor $i$ no es null\n",
    "# o\n",
    "# poner unknown en vehiculo $i$ si el vehiculo $i$ es null y factor $i$ no es null\n",
    "\n",
    "# son disjuntas estas operaciones?????????????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some rows of the dataset, the **CONTRIBUTING FACTOR VEHICLE** is missing but the **VEHICLE TYPE CODE** is not. This suggests that the vehicle type is known, but the factor that contributed to the collision is not. In order to fill this missing values, the factor was set as *unespecified*. This was done for all the rows and columns where the **CONTRIBUTING FACTOR VEHICLE** was missing with the above condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp.imputation_with_ref_col(precollision, 'CONTRIBUTING FACTOR VEHICLE', 'VEHICLE TYPE CODE', 'Unspecified', 1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, in some rows of the dataset, the **VEHICLE TYPE CODE** is missing but the **CONTRIBUTING FACTOR VEHICLE** is not. This suggests that the factor that contributed to the collision is known, but the vehicle type is not. In order to fill this missing values, the vehicle type was set as *unknown*. This was done for all the rows and columns where the **VEHICLE TYPE CODE** was missing with the above condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp.imputation_with_ref_col(precollision, 'VEHICLE TYPE CODE', 'CONTRIBUTING FACTOR VEHICLE', 'UNKNOWN', 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COLLISION_ID                          0\n",
       "CRASH DATE                            0\n",
       "CRASH TIME                            0\n",
       "BOROUGH                           40671\n",
       "ZIP CODE                          40686\n",
       "LOCATION                           7667\n",
       "STREET NAME                         226\n",
       "CROSS STREET NAME                 60179\n",
       "NUMBER OF PERSONS INJURED             2\n",
       "NUMBER OF PERSONS KILLED              4\n",
       "NUMBER OF PEDESTRIANS INJURED         0\n",
       "NUMBER OF PEDESTRIANS KILLED          0\n",
       "NUMBER OF CYCLIST INJURED             0\n",
       "NUMBER OF CYCLIST KILLED              0\n",
       "NUMBER OF MOTORIST INJURED            0\n",
       "NUMBER OF MOTORIST KILLED             0\n",
       "CONTRIBUTING FACTOR VEHICLE 1       288\n",
       "CONTRIBUTING FACTOR VEHICLE 2     18852\n",
       "CONTRIBUTING FACTOR VEHICLE 3    106550\n",
       "CONTRIBUTING FACTOR VEHICLE 4    113540\n",
       "CONTRIBUTING FACTOR VEHICLE 5    115123\n",
       "VEHICLE TYPE CODE 1                 288\n",
       "VEHICLE TYPE CODE 2               18852\n",
       "VEHICLE TYPE CODE 3              106550\n",
       "VEHICLE TYPE CODE 4              113540\n",
       "VEHICLE TYPE CODE 5              115123\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precollision.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- comentar la reduccion de missing values -->\n",
    "\n",
    "Notice that the only missing values in the **CONTRIBUTING FACTOR VEHICLE** attribute and **VEHICLE TYPE CODE** attribute are in the same rows. This means that the number of missing values in the **CONTRIBUTING FACTOR VEHICLE** attribute and **VEHICLE TYPE CODE** attribute is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# como se hace para imputar los missing de los dos campos a la vez?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derivation of number of person attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# como se hace para imputar los missing del numero de personas? o mejor se elimina?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather dataset preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since in the process of gathering the data we selected all possible attributes, now it's time to delete the ones that are completely empty or are not useful for our purpose. Then, other preprocessing steps will be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\USUARIOS\\Enric-UPC\\AppData\\Local\\Temp\\ipykernel_15012\\941678255.py:1: DtypeWarning: Columns (7,9,13,17,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  weather = pd.read_csv(f'{dir}/weather.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(90591, 66)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = pd.read_csv(f'{dir}/weather.csv')\n",
    "weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>AWND</th>\n",
       "      <th>AWND_ATTRIBUTES</th>\n",
       "      <th>DAPR</th>\n",
       "      <th>DAPR_ATTRIBUTES</th>\n",
       "      <th>...</th>\n",
       "      <th>WT05</th>\n",
       "      <th>WT05_ATTRIBUTES</th>\n",
       "      <th>WT06</th>\n",
       "      <th>WT06_ATTRIBUTES</th>\n",
       "      <th>WT08</th>\n",
       "      <th>WT08_ATTRIBUTES</th>\n",
       "      <th>WT09</th>\n",
       "      <th>WT09_ATTRIBUTES</th>\n",
       "      <th>WT11</th>\n",
       "      <th>WT11_ATTRIBUTES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USC00280907</td>\n",
       "      <td>BOONTON 1 SE, NJ US</td>\n",
       "      <td>40.89174</td>\n",
       "      <td>-74.39635</td>\n",
       "      <td>85.3</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USC00280907</td>\n",
       "      <td>BOONTON 1 SE, NJ US</td>\n",
       "      <td>40.89174</td>\n",
       "      <td>-74.39635</td>\n",
       "      <td>85.3</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USC00280907</td>\n",
       "      <td>BOONTON 1 SE, NJ US</td>\n",
       "      <td>40.89174</td>\n",
       "      <td>-74.39635</td>\n",
       "      <td>85.3</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USC00280907</td>\n",
       "      <td>BOONTON 1 SE, NJ US</td>\n",
       "      <td>40.89174</td>\n",
       "      <td>-74.39635</td>\n",
       "      <td>85.3</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USC00280907</td>\n",
       "      <td>BOONTON 1 SE, NJ US</td>\n",
       "      <td>40.89174</td>\n",
       "      <td>-74.39635</td>\n",
       "      <td>85.3</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATION                 NAME  LATITUDE  LONGITUDE  ELEVATION  \\\n",
       "0  USC00280907  BOONTON 1 SE, NJ US  40.89174  -74.39635       85.3   \n",
       "1  USC00280907  BOONTON 1 SE, NJ US  40.89174  -74.39635       85.3   \n",
       "2  USC00280907  BOONTON 1 SE, NJ US  40.89174  -74.39635       85.3   \n",
       "3  USC00280907  BOONTON 1 SE, NJ US  40.89174  -74.39635       85.3   \n",
       "4  USC00280907  BOONTON 1 SE, NJ US  40.89174  -74.39635       85.3   \n",
       "\n",
       "         DATE  AWND AWND_ATTRIBUTES  DAPR DAPR_ATTRIBUTES  ...  WT05  \\\n",
       "0  2018-01-01   NaN             NaN   NaN             NaN  ...   NaN   \n",
       "1  2018-01-02   NaN             NaN   NaN             NaN  ...   NaN   \n",
       "2  2018-01-03   NaN             NaN   NaN             NaN  ...   NaN   \n",
       "3  2018-01-04   NaN             NaN   NaN             NaN  ...   NaN   \n",
       "4  2018-01-05   NaN             NaN   NaN             NaN  ...   NaN   \n",
       "\n",
       "   WT05_ATTRIBUTES  WT06 WT06_ATTRIBUTES  WT08  WT08_ATTRIBUTES  WT09  \\\n",
       "0              NaN   NaN             NaN   NaN              NaN   NaN   \n",
       "1              NaN   NaN             NaN   NaN              NaN   NaN   \n",
       "2              NaN   NaN             NaN   NaN              NaN   NaN   \n",
       "3              NaN   NaN             NaN   NaN              NaN   NaN   \n",
       "4              NaN   NaN             NaN   NaN              NaN   NaN   \n",
       "\n",
       "  WT09_ATTRIBUTES  WT11 WT11_ATTRIBUTES  \n",
       "0             NaN   NaN             NaN  \n",
       "1             NaN   NaN             NaN  \n",
       "2             NaN   NaN             NaN  \n",
       "3             NaN   NaN             NaN  \n",
       "4             NaN   NaN             NaN  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a simple view we see a lot of very sparse attributes, and a lot of attributes taht are not really useful. To deal with these attributes, the best option is to define the useful ones and erase all the others.\n",
    "\n",
    "First of all, we will start by joining *LATITUDE* and *LONGITUDE* in a *LOCATION* attribute following the format of the previous dataset. We will delete the *ELEVATION* since it can't be related in any way with the previous dataset and the information it gives is not useful for our purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['LOCATION'] = '('+weather['LATITUDE'].astype(str) + ', ' + weather['LONGITUDE'].astype(str)+')'\n",
    "weather.drop(columns=['LATITUDE', 'LONGITUDE', 'ELEVATION'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have *LOCATION*, we don't need *STATION* code or *NAME*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.drop(columns=['STATION', 'NAME'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with regard to the other columns, let's follow the proposed startegy. We are interested in *LOCATION* so we can know about the weather condtitions of the zone where the collision was produced. Now, for the weather attributes, ollowing the *Documentation* of the weather datset, provided by the *NOAA* and available in the Data directory, we are (for now) interested in:\n",
    "\n",
    "- *PRCP* : Precipitation (mm)\n",
    "- *SNOW* : Snowfall (mm)\n",
    "- *SNWD* : Snow depth (mm)\n",
    "- *TMAX* : Maximum temperature (Celsius)\n",
    "- *TMIN* : Minimum temperature (Celsius)\n",
    "- *TOBS* : Temperature at the time of observation\n",
    "- *AWND* : Average daily wind speed (meters per second)\n",
    "- *FRTH* : Thickness of frozen ground layer (cm or inches as per user preference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE                object\n",
       "AWND               float64\n",
       "AWND_ATTRIBUTES     object\n",
       "DAPR               float64\n",
       "DAPR_ATTRIBUTES     object\n",
       "DASF               float64\n",
       "DASF_ATTRIBUTES    float64\n",
       "MDPR               float64\n",
       "MDPR_ATTRIBUTES     object\n",
       "MDSF               float64\n",
       "MDSF_ATTRIBUTES    float64\n",
       "PGTM               float64\n",
       "PGTM_ATTRIBUTES     object\n",
       "PRCP               float64\n",
       "PRCP_ATTRIBUTES     object\n",
       "PSUN               float64\n",
       "PSUN_ATTRIBUTES     object\n",
       "SNOW               float64\n",
       "SNOW_ATTRIBUTES     object\n",
       "SNWD               float64\n",
       "SNWD_ATTRIBUTES     object\n",
       "TAVG               float64\n",
       "TAVG_ATTRIBUTES     object\n",
       "TMAX               float64\n",
       "TMAX_ATTRIBUTES     object\n",
       "TMIN               float64\n",
       "TMIN_ATTRIBUTES     object\n",
       "TOBS               float64\n",
       "TOBS_ATTRIBUTES     object\n",
       "TSUN               float64\n",
       "TSUN_ATTRIBUTES     object\n",
       "WDF2               float64\n",
       "WDF2_ATTRIBUTES     object\n",
       "WDF5               float64\n",
       "WDF5_ATTRIBUTES     object\n",
       "WESD               float64\n",
       "WESD_ATTRIBUTES     object\n",
       "WESF               float64\n",
       "WESF_ATTRIBUTES     object\n",
       "WSF2               float64\n",
       "WSF2_ATTRIBUTES     object\n",
       "WSF5               float64\n",
       "WSF5_ATTRIBUTES     object\n",
       "WT01               float64\n",
       "WT01_ATTRIBUTES     object\n",
       "WT02               float64\n",
       "WT02_ATTRIBUTES     object\n",
       "WT03               float64\n",
       "WT03_ATTRIBUTES     object\n",
       "WT04               float64\n",
       "WT04_ATTRIBUTES     object\n",
       "WT05               float64\n",
       "WT05_ATTRIBUTES     object\n",
       "WT06               float64\n",
       "WT06_ATTRIBUTES     object\n",
       "WT08               float64\n",
       "WT08_ATTRIBUTES     object\n",
       "WT09               float64\n",
       "WT09_ATTRIBUTES     object\n",
       "WT11               float64\n",
       "WT11_ATTRIBUTES     object\n",
       "LOCATION            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
